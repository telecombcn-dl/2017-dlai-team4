{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# parameters #\n",
    "##############\n",
    "# dontFreezeLast = 0;\n",
    "\n",
    "# patience = 10;\n",
    "\n",
    "# gpuName = '/device:GPU:0'\n",
    "# workers = 2;\n",
    "# histogram_freq = 0;\n",
    "\n",
    "# epochs = 100;\n",
    "# validation_size=0.3;\n",
    "\n",
    "modelPath = '../models/VGG19_opt/run2.h5';\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the csv's so we can see some more information on the filenames and breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('../input/labels.csv')\n",
    "# df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "# print('Training images: ',df_train.shape[0])\n",
    "# print('Test images: ',df_test.shape[0])\n",
    "\n",
    "# reduce dimensionality\n",
    "#df_train = df_train.head(100)\n",
    "#df_test = df_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the breed needs to be one-hot encoded for the final submission, so we will now do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_series = pd.Series(df_train['breed'])\n",
    "# one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to, 90x90 px, you should play with this number to see how it affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 \n",
    "# for f, breed in tqdm(df_train.values[:10]):\n",
    "#     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "#     label = one_hot_labels[i]\n",
    "#     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "#     y_train.append(label)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in tqdm(df_test['id'].values):\n",
    "#     img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    "#     x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_raw = np.array(y_train, np.uint8)\n",
    "# x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "# x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shape of the outputs to make sure everyting went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train_raw.shape)\n",
    "# print(y_train_raw.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = y_train_raw.shape[1]\n",
    "# print('Number of classes: ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to create a validation set so that you can gauge the performance of your model on independent data, unseen to the model in training. We do this by splitting the current training set (x_train_raw) and the corresponding labels (y_train_raw) so that we set aside 30 % of the data at random and put these in validation sets (X_valid and Y_valid).\n",
    "\n",
    "* This split needs to be improved so that it contains images from every class, with 120 separate classes some can not be represented and so the validation score is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the CNN architecture. Here we are using a pre-trained model VGG19 which has already been trained to identify many different dog breeds (as well as a lot of other objects from the imagenet dataset see here for more information: http://image-net.org/about-overview). Unfortunately it doesn't seem possible to downlod the weights from within this kernel so make sure you set the weights argument to 'imagenet' and not None, as it currently is below.\n",
    "\n",
    "We then remove the final layer and instead replace it with a single dense layer with the number of nodes corresponding to the number of breed classes we have (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('Getting data')\n",
    "    df_train = pd.read_csv('../input/labels.csv')\n",
    "    df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "    \n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "    \n",
    "    im_size = 90\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "    \n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    print('Splitting into training/validation')\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and model for hyperas\n",
    "\n",
    "def model(X_train,Y_train,X_valid,Y_valid):\n",
    "    print('Creating model')\n",
    "    base_model = VGG19(weights = 'imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(im_size, im_size, 3))\n",
    "\n",
    "    dropout = {{uniform(0.5,1)}};\n",
    "    layers = {{choice([0,1,2])}};\n",
    "    dontFreeze = {{choice(list(range(5+1)))}};\n",
    "    batchSize = {{choice([16,64,256])}};\n",
    "    \n",
    "    print()\n",
    "    print('dropout=',dropout)\n",
    "    print('layers=',layers)\n",
    "    print('dontFreeze=',dontFreeze)\n",
    "    print('batchSize=',batchSize)\n",
    "    print()\n",
    "    \n",
    "    stepsPerEpoch = round( len(X_train)/batchSize );\n",
    "    \n",
    "    # Add a new top layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    if layers>=2:\n",
    "        x = Dense(1024,activation='relu')(x)\n",
    "    if layers>=1:\n",
    "        x = Dense(512,activation='relu')(x)\n",
    "    # in any case:\n",
    "    predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "    # This is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # First: train only the top layers (which were randomly initialized)\n",
    "    for i in range(len(base_model.layers)-dontFreeze):\n",
    "        base_model.layers[i].trainable = False\n",
    "\n",
    "    # predetermined optimizer\n",
    "    lr=0.00020389590556056983;\n",
    "    beta_1=0.9453158868247398;\n",
    "    beta_2=0.9925872692991417;\n",
    "    decay=0.000821336141287018;\n",
    "    adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks_list = [];\n",
    "    callbacks_list.append(keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=1));\n",
    "\n",
    "\n",
    "    # data augmentation & fitting\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True);\n",
    "    \n",
    "    model.fit_generator(\n",
    "        datagen.flow(X_train,Y_train,batch_size=batchSize),\n",
    "        steps_per_epoch=stepsPerEpoch,\n",
    "        epochs=150,\n",
    "        verbose=1,\n",
    "        validation_data=(X_valid,Y_valid),\n",
    "        workers=2,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks_list)\n",
    "#     model.fit(X_train, Y_train,\n",
    "#       epochs=100,\n",
    "#       batch_size = batchSize,\n",
    "#       validation_data=(X_valid, Y_valid),\n",
    "#       verbose=1,\n",
    "#       callbacks=callbacks_list)\n",
    "\n",
    "    score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.applications.vgg19 import VGG19\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from subprocess import check_output\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'dropout': hp.uniform('dropout', 0.5,1),\n",
      "        'layers': hp.choice('layers', [0,1,2]),\n",
      "        'dontFreeze': hp.choice('dontFreeze', list(range(5+1))),\n",
      "        'batchSize': hp.choice('batchSize', [16,64,256]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: print('Getting data')\n",
      "  3: df_train = pd.read_csv('../input/labels.csv')\n",
      "  4: df_test = pd.read_csv('../input/sample_submission.csv')\n",
      "  5: \n",
      "  6: targets_series = pd.Series(df_train['breed'])\n",
      "  7: one_hot = pd.get_dummies(targets_series, sparse = True)\n",
      "  8: one_hot_labels = np.asarray(one_hot)\n",
      "  9: \n",
      " 10: im_size = 90\n",
      " 11: x_train = []\n",
      " 12: y_train = []\n",
      " 13: x_test = []\n",
      " 14: \n",
      " 15: i = 0 \n",
      " 16: for f, breed in tqdm(df_train.values):\n",
      " 17:     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
      " 18:     label = one_hot_labels[i]\n",
      " 19:     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
      " 20:     y_train.append(label)\n",
      " 21:     i += 1\n",
      " 22: \n",
      " 23: y_train_raw = np.array(y_train, np.uint8)\n",
      " 24: x_train_raw = np.array(x_train, np.float32) / 255.\n",
      " 25: num_class = y_train_raw.shape[1]\n",
      " 26: \n",
      " 27: print('Splitting into training/validation')\n",
      " 28: X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
      " 29: \n",
      " 30: \n",
      " 31: \n",
      " 32: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print('Creating model')\n",
      "   4:     base_model = VGG19(weights = 'imagenet',\n",
      "   5:                        include_top=False,\n",
      "   6:                        input_shape=(im_size, im_size, 3))\n",
      "   7: \n",
      "   8:     dropout = space['dropout'];\n",
      "   9:     layers = space['layers'];\n",
      "  10:     dontFreeze = space['dontFreeze'];\n",
      "  11:     batchSize = space['batchSize'];\n",
      "  12:     \n",
      "  13:     print()\n",
      "  14:     print('dropout=',dropout)\n",
      "  15:     print('layers=',layers)\n",
      "  16:     print('dontFreeze=',dontFreeze)\n",
      "  17:     print('batchSize=',batchSize)\n",
      "  18:     print()\n",
      "  19:     \n",
      "  20:     stepsPerEpoch = round( len(X_train)/batchSize );\n",
      "  21:     \n",
      "  22:     # Add a new top layer\n",
      "  23:     x = base_model.output\n",
      "  24:     x = Flatten()(x)\n",
      "  25:     x = Dropout(dropout)(x)\n",
      "  26:     if layers>=2:\n",
      "  27:         x = Dense(1024,activation='relu')(x)\n",
      "  28:     if layers>=1:\n",
      "  29:         x = Dense(512,activation='relu')(x)\n",
      "  30:     # in any case:\n",
      "  31:     predictions = Dense(num_class, activation='softmax')(x)\n",
      "  32: \n",
      "  33:     # This is the model we will train\n",
      "  34:     model = Model(inputs=base_model.input, outputs=predictions)\n",
      "  35: \n",
      "  36:     # First: train only the top layers (which were randomly initialized)\n",
      "  37:     for i in range(len(base_model.layers)-dontFreeze):\n",
      "  38:         base_model.layers[i].trainable = False\n",
      "  39: \n",
      "  40:     # predetermined optimizer\n",
      "  41:     lr=0.00020389590556056983;\n",
      "  42:     beta_1=0.9453158868247398;\n",
      "  43:     beta_2=0.9925872692991417;\n",
      "  44:     decay=0.000821336141287018;\n",
      "  45:     adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
      "  46:     model.compile(loss='categorical_crossentropy', \n",
      "  47:                   optimizer=adam, \n",
      "  48:                   metrics=['accuracy'])\n",
      "  49: \n",
      "  50:     callbacks_list = [];\n",
      "  51:     callbacks_list.append(keras.callbacks.EarlyStopping(\n",
      "  52:         monitor='val_acc',\n",
      "  53:         patience=10,\n",
      "  54:         verbose=1));\n",
      "  55: \n",
      "  56: \n",
      "  57:     # data augmentation & fitting\n",
      "  58:     datagen = ImageDataGenerator(\n",
      "  59:         rotation_range=30,\n",
      "  60:         width_shift_range=0.1,\n",
      "  61:         height_shift_range=0.1,\n",
      "  62:         shear_range=0.5,\n",
      "  63:         zoom_range=0.5,\n",
      "  64:         horizontal_flip=True,\n",
      "  65:         vertical_flip=True);\n",
      "  66:     \n",
      "  67:     model.fit_generator(\n",
      "  68:         datagen.flow(X_train,Y_train,batch_size=batchSize),\n",
      "  69:         steps_per_epoch=stepsPerEpoch,\n",
      "  70:         epochs=150,\n",
      "  71:         verbose=1,\n",
      "  72:         validation_data=(X_valid,Y_valid),\n",
      "  73:         workers=2,\n",
      "  74:         shuffle=True,\n",
      "  75:         callbacks=callbacks_list)\n",
      "  76: #     model.fit(X_train, Y_train,\n",
      "  77: #       epochs=100,\n",
      "  78: #       batch_size = batchSize,\n",
      "  79: #       validation_data=(X_valid, Y_valid),\n",
      "  80: #       verbose=1,\n",
      "  81: #       callbacks=callbacks_list)\n",
      "  82: \n",
      "  83:     score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
      "  84:     print('Test accuracy:', acc)\n",
      "  85:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  86: \n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [01:07<00:00, 151.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "Creating model\n",
      "\n",
      "dropout= 0.6064002165637792\n",
      "layers= 2\n",
      "dontFreeze= 3\n",
      "batchSize= 64\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 4.8143 - acc: 0.0085 - val_loss: 4.7743 - val_acc: 0.0170\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 4.7729 - acc: 0.0114 - val_loss: 4.7211 - val_acc: 0.0192\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 4.7246 - acc: 0.0151 - val_loss: 4.6869 - val_acc: 0.0199\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.7050 - acc: 0.0163 - val_loss: 4.6554 - val_acc: 0.0274\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 4.6877 - acc: 0.0212 - val_loss: 4.6124 - val_acc: 0.0323\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 4.6618 - acc: 0.0215 - val_loss: 4.5934 - val_acc: 0.0287\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 4.6387 - acc: 0.0271 - val_loss: 4.5735 - val_acc: 0.0395\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 4.6225 - acc: 0.0240 - val_loss: 4.5384 - val_acc: 0.0362\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 4.6019 - acc: 0.0310 - val_loss: 4.4991 - val_acc: 0.0473\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 4.5673 - acc: 0.0327 - val_loss: 4.4707 - val_acc: 0.0404\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 4.5253 - acc: 0.0352 - val_loss: 4.4331 - val_acc: 0.0447\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 4.5010 - acc: 0.0348 - val_loss: 4.3912 - val_acc: 0.0476\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 4.4550 - acc: 0.0399 - val_loss: 4.3205 - val_acc: 0.0580\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 4.4232 - acc: 0.0429 - val_loss: 4.2847 - val_acc: 0.0597\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.4005 - acc: 0.0428 - val_loss: 4.2536 - val_acc: 0.0554\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 4.3704 - acc: 0.0452 - val_loss: 4.2252 - val_acc: 0.0636\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.3278 - acc: 0.0487 - val_loss: 4.1867 - val_acc: 0.0672\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.3165 - acc: 0.0474 - val_loss: 4.1743 - val_acc: 0.0681\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 4.2750 - acc: 0.0567 - val_loss: 4.1309 - val_acc: 0.0737\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 4.2608 - acc: 0.0599 - val_loss: 4.0952 - val_acc: 0.0734\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 4.2257 - acc: 0.0561 - val_loss: 4.0681 - val_acc: 0.0691\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 4.1916 - acc: 0.0618 - val_loss: 4.0578 - val_acc: 0.0763\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 4.1705 - acc: 0.0650 - val_loss: 4.0196 - val_acc: 0.0841\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.1576 - acc: 0.0675 - val_loss: 4.0093 - val_acc: 0.0861\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.1317 - acc: 0.0684 - val_loss: 3.9710 - val_acc: 0.0910\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 4.0972 - acc: 0.0753 - val_loss: 3.9519 - val_acc: 0.0877\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 4.0686 - acc: 0.0795 - val_loss: 3.9206 - val_acc: 0.0926\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.0579 - acc: 0.0832 - val_loss: 3.8961 - val_acc: 0.1050\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.0382 - acc: 0.0815 - val_loss: 3.9006 - val_acc: 0.1069\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 4.0133 - acc: 0.0864 - val_loss: 3.8760 - val_acc: 0.1135\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.0119 - acc: 0.0876 - val_loss: 3.8273 - val_acc: 0.1125\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.9843 - acc: 0.0951 - val_loss: 3.8232 - val_acc: 0.1180\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.9752 - acc: 0.0854 - val_loss: 3.8206 - val_acc: 0.1219\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 3.9404 - acc: 0.0948 - val_loss: 3.7949 - val_acc: 0.1174\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 3.9149 - acc: 0.0996 - val_loss: 3.7576 - val_acc: 0.1272\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.9141 - acc: 0.1047 - val_loss: 3.7379 - val_acc: 0.1285\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.8873 - acc: 0.1061 - val_loss: 3.7529 - val_acc: 0.1213\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.8922 - acc: 0.1056 - val_loss: 3.7486 - val_acc: 0.1268\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.8474 - acc: 0.1031 - val_loss: 3.7129 - val_acc: 0.1327\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.8525 - acc: 0.1111 - val_loss: 3.6964 - val_acc: 0.1376\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.8337 - acc: 0.1130 - val_loss: 3.6955 - val_acc: 0.1392\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.8060 - acc: 0.1183 - val_loss: 3.6990 - val_acc: 0.1461\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.8304 - acc: 0.1170 - val_loss: 3.6572 - val_acc: 0.1480\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.8046 - acc: 0.1179 - val_loss: 3.6658 - val_acc: 0.1448\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.7881 - acc: 0.1248 - val_loss: 3.6266 - val_acc: 0.1519\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.7722 - acc: 0.1252 - val_loss: 3.6282 - val_acc: 0.1506\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 31s 272ms/step - loss: 3.7559 - acc: 0.1274 - val_loss: 3.6323 - val_acc: 0.1500\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.7510 - acc: 0.1274 - val_loss: 3.6375 - val_acc: 0.1519\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.7462 - acc: 0.1329 - val_loss: 3.5962 - val_acc: 0.1532\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.7450 - acc: 0.1308 - val_loss: 3.6144 - val_acc: 0.1487\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.7171 - acc: 0.1333 - val_loss: 3.6133 - val_acc: 0.1470\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.7225 - acc: 0.1289 - val_loss: 3.5837 - val_acc: 0.1545\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.7001 - acc: 0.1321 - val_loss: 3.5963 - val_acc: 0.1539\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.6970 - acc: 0.1372 - val_loss: 3.5670 - val_acc: 0.1591\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.6674 - acc: 0.1372 - val_loss: 3.5611 - val_acc: 0.1640\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.6793 - acc: 0.1439 - val_loss: 3.5538 - val_acc: 0.1647\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.6295 - acc: 0.1468 - val_loss: 3.5607 - val_acc: 0.1591\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.6362 - acc: 0.1474 - val_loss: 3.5477 - val_acc: 0.1611\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.6353 - acc: 0.1458 - val_loss: 3.5783 - val_acc: 0.1578\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 30s 267ms/step - loss: 3.6300 - acc: 0.1475 - val_loss: 3.5773 - val_acc: 0.1647\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.6129 - acc: 0.1509 - val_loss: 3.5505 - val_acc: 0.1686\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.6383 - acc: 0.1443 - val_loss: 3.5262 - val_acc: 0.1699\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.6061 - acc: 0.1547 - val_loss: 3.5158 - val_acc: 0.1682\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.6075 - acc: 0.1488 - val_loss: 3.5224 - val_acc: 0.1673\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.5862 - acc: 0.1541 - val_loss: 3.5191 - val_acc: 0.1679\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.5619 - acc: 0.1568 - val_loss: 3.5017 - val_acc: 0.1728\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.5717 - acc: 0.1527 - val_loss: 3.5219 - val_acc: 0.1676\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 3.5698 - acc: 0.1575 - val_loss: 3.5149 - val_acc: 0.1725\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 3.5745 - acc: 0.1564 - val_loss: 3.5115 - val_acc: 0.1751\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.5542 - acc: 0.1531 - val_loss: 3.4972 - val_acc: 0.1777\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.5391 - acc: 0.1542 - val_loss: 3.5042 - val_acc: 0.1767\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.5527 - acc: 0.1603 - val_loss: 3.4717 - val_acc: 0.1754\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.5155 - acc: 0.1627 - val_loss: 3.4925 - val_acc: 0.1858\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.5051 - acc: 0.1666 - val_loss: 3.4829 - val_acc: 0.1845\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.5039 - acc: 0.1656 - val_loss: 3.4944 - val_acc: 0.1748\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 3.5068 - acc: 0.1671 - val_loss: 3.4695 - val_acc: 0.1816\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 3.4940 - acc: 0.1695 - val_loss: 3.4543 - val_acc: 0.1751\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 3.4823 - acc: 0.1702 - val_loss: 3.4501 - val_acc: 0.1839\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.4969 - acc: 0.1676 - val_loss: 3.4623 - val_acc: 0.1832\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.5037 - acc: 0.1679 - val_loss: 3.4516 - val_acc: 0.1862\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4898 - acc: 0.1724 - val_loss: 3.4623 - val_acc: 0.1878\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.4653 - acc: 0.1739 - val_loss: 3.4633 - val_acc: 0.1819\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.4641 - acc: 0.1719 - val_loss: 3.4629 - val_acc: 0.1826\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.4449 - acc: 0.1703 - val_loss: 3.4537 - val_acc: 0.1878\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.4475 - acc: 0.1787 - val_loss: 3.4358 - val_acc: 0.1872\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 31s 272ms/step - loss: 3.4329 - acc: 0.1766 - val_loss: 3.4461 - val_acc: 0.1826\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 3.4452 - acc: 0.1818 - val_loss: 3.4478 - val_acc: 0.1836\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 3.4457 - acc: 0.1814 - val_loss: 3.4309 - val_acc: 0.1862\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.4297 - acc: 0.1754 - val_loss: 3.4448 - val_acc: 0.1816\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4263 - acc: 0.1784 - val_loss: 3.4258 - val_acc: 0.1858\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4229 - acc: 0.1776 - val_loss: 3.4494 - val_acc: 0.1858\n",
      "Epoch 00091: early stopping\n",
      "Test accuracy: 0.185849364204\n",
      "Creating model\n",
      "\n",
      "dropout= 0.6165806722373868\n",
      "layers= 0\n",
      "dontFreeze= 4\n",
      "batchSize= 256\n",
      "\n",
      "Epoch 1/150\n",
      "28/28 [==============================] - 41s 1s/step - loss: 4.9200 - acc: 0.0099 - val_loss: 4.7872 - val_acc: 0.0101\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 25s 898ms/step - loss: 4.7873 - acc: 0.0116 - val_loss: 4.7872 - val_acc: 0.0098\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 25s 897ms/step - loss: 4.7872 - acc: 0.0113 - val_loss: 4.7871 - val_acc: 0.0098\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 25s 893ms/step - loss: 4.7869 - acc: 0.0104 - val_loss: 4.7870 - val_acc: 0.0098\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 25s 894ms/step - loss: 4.7868 - acc: 0.0114 - val_loss: 4.7869 - val_acc: 0.0098\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 25s 897ms/step - loss: 4.7866 - acc: 0.0101 - val_loss: 4.7869 - val_acc: 0.0098\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 25s 893ms/step - loss: 4.7865 - acc: 0.0112 - val_loss: 4.7868 - val_acc: 0.0098\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 25s 900ms/step - loss: 4.7863 - acc: 0.0106 - val_loss: 4.7867 - val_acc: 0.0098\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 25s 899ms/step - loss: 4.7862 - acc: 0.0102 - val_loss: 4.7866 - val_acc: 0.0098\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 25s 894ms/step - loss: 4.7860 - acc: 0.0099 - val_loss: 4.7865 - val_acc: 0.0098\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 25s 898ms/step - loss: 4.7859 - acc: 0.0115 - val_loss: 4.7864 - val_acc: 0.0098\n",
      "Epoch 00011: early stopping\n",
      "Test accuracy: 0.00978154548419\n",
      "Creating model\n",
      "\n",
      "dropout= 0.8814062151635532\n",
      "layers= 1\n",
      "dontFreeze= 4\n",
      "batchSize= 64\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 4.8727 - acc: 0.0107 - val_loss: 4.7872 - val_acc: 0.0104\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.7869 - acc: 0.0116 - val_loss: 4.7869 - val_acc: 0.0104\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.7865 - acc: 0.0116 - val_loss: 4.7866 - val_acc: 0.0104\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 4.7861 - acc: 0.0116 - val_loss: 4.7864 - val_acc: 0.0104\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 4.7857 - acc: 0.0116 - val_loss: 4.7861 - val_acc: 0.0104\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 4.7853 - acc: 0.0116 - val_loss: 4.7859 - val_acc: 0.0104\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 4.7849 - acc: 0.0116 - val_loss: 4.7856 - val_acc: 0.0104\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 4.7845 - acc: 0.0116 - val_loss: 4.7853 - val_acc: 0.0104\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.7840 - acc: 0.0116 - val_loss: 4.7851 - val_acc: 0.0104\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 4.7836 - acc: 0.0116 - val_loss: 4.7848 - val_acc: 0.0104\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.7831 - acc: 0.0116 - val_loss: 4.7846 - val_acc: 0.0104\n",
      "Epoch 00011: early stopping\n",
      "Test accuracy: 0.0104336485189\n",
      "Creating model\n",
      "\n",
      "dropout= 0.742222761866006\n",
      "layers= 1\n",
      "dontFreeze= 1\n",
      "batchSize= 256\n",
      "\n",
      "Epoch 1/150\n",
      "28/28 [==============================] - 31s 1s/step - loss: 5.3116 - acc: 0.0084 - val_loss: 4.8216 - val_acc: 0.0127\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 5.0555 - acc: 0.0070 - val_loss: 4.7888 - val_acc: 0.0183\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.9706 - acc: 0.0099 - val_loss: 4.7735 - val_acc: 0.0173\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 23s 832ms/step - loss: 4.9210 - acc: 0.0098 - val_loss: 4.7671 - val_acc: 0.0186\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.8821 - acc: 0.0121 - val_loss: 4.7640 - val_acc: 0.0196\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.8649 - acc: 0.0129 - val_loss: 4.7598 - val_acc: 0.0192\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.8382 - acc: 0.0124 - val_loss: 4.7571 - val_acc: 0.0225\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.8354 - acc: 0.0138 - val_loss: 4.7552 - val_acc: 0.0215\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.8353 - acc: 0.0135 - val_loss: 4.7544 - val_acc: 0.0225\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.8227 - acc: 0.0148 - val_loss: 4.7531 - val_acc: 0.0215\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.7919 - acc: 0.0155 - val_loss: 4.7525 - val_acc: 0.0215\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.7860 - acc: 0.0193 - val_loss: 4.7497 - val_acc: 0.0212\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 23s 825ms/step - loss: 4.7801 - acc: 0.0159 - val_loss: 4.7468 - val_acc: 0.0225\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.7711 - acc: 0.0154 - val_loss: 4.7438 - val_acc: 0.0238\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.7733 - acc: 0.0168 - val_loss: 4.7396 - val_acc: 0.0264\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.7591 - acc: 0.0201 - val_loss: 4.7354 - val_acc: 0.0245\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.7548 - acc: 0.0207 - val_loss: 4.7303 - val_acc: 0.0277\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.7559 - acc: 0.0192 - val_loss: 4.7262 - val_acc: 0.0287\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.7448 - acc: 0.0207 - val_loss: 4.7212 - val_acc: 0.0316\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 26s 924ms/step - loss: 4.7407 - acc: 0.0218 - val_loss: 4.7159 - val_acc: 0.0342\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 23s 826ms/step - loss: 4.7388 - acc: 0.0215 - val_loss: 4.7084 - val_acc: 0.0333\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.7285 - acc: 0.0203 - val_loss: 4.7022 - val_acc: 0.0329\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.7210 - acc: 0.0264 - val_loss: 4.6935 - val_acc: 0.0342\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.7219 - acc: 0.0197 - val_loss: 4.6851 - val_acc: 0.0365\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.7139 - acc: 0.0236 - val_loss: 4.6749 - val_acc: 0.0359\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.6962 - acc: 0.0254 - val_loss: 4.6648 - val_acc: 0.0378\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.7045 - acc: 0.0228 - val_loss: 4.6533 - val_acc: 0.0391\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.6866 - acc: 0.0298 - val_loss: 4.6437 - val_acc: 0.0408\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6918 - acc: 0.0243 - val_loss: 4.6330 - val_acc: 0.0440\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6782 - acc: 0.0257 - val_loss: 4.6237 - val_acc: 0.0460\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 23s 829ms/step - loss: 4.6819 - acc: 0.0292 - val_loss: 4.6142 - val_acc: 0.0479\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 23s 826ms/step - loss: 4.6606 - acc: 0.0317 - val_loss: 4.6045 - val_acc: 0.0492\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6699 - acc: 0.0284 - val_loss: 4.5943 - val_acc: 0.0476\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.6587 - acc: 0.0291 - val_loss: 4.5874 - val_acc: 0.0463\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6470 - acc: 0.0307 - val_loss: 4.5751 - val_acc: 0.0470\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6415 - acc: 0.0297 - val_loss: 4.5639 - val_acc: 0.0499\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6368 - acc: 0.0337 - val_loss: 4.5546 - val_acc: 0.0518\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6387 - acc: 0.0329 - val_loss: 4.5446 - val_acc: 0.0509\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.6192 - acc: 0.0331 - val_loss: 4.5339 - val_acc: 0.0548\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.6261 - acc: 0.0334 - val_loss: 4.5246 - val_acc: 0.0541\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 23s 835ms/step - loss: 4.6084 - acc: 0.0383 - val_loss: 4.5169 - val_acc: 0.0574\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.6071 - acc: 0.0308 - val_loss: 4.5077 - val_acc: 0.0574\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5957 - acc: 0.0362 - val_loss: 4.4985 - val_acc: 0.0567\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5996 - acc: 0.0398 - val_loss: 4.4873 - val_acc: 0.0587\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5937 - acc: 0.0397 - val_loss: 4.4792 - val_acc: 0.0584\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5872 - acc: 0.0376 - val_loss: 4.4708 - val_acc: 0.0600\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5776 - acc: 0.0421 - val_loss: 4.4636 - val_acc: 0.0571\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5667 - acc: 0.0450 - val_loss: 4.4550 - val_acc: 0.0577\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5598 - acc: 0.0428 - val_loss: 4.4486 - val_acc: 0.0567\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5696 - acc: 0.0402 - val_loss: 4.4436 - val_acc: 0.0626\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5583 - acc: 0.0436 - val_loss: 4.4369 - val_acc: 0.0590\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5621 - acc: 0.0401 - val_loss: 4.4274 - val_acc: 0.0639\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5635 - acc: 0.0377 - val_loss: 4.4184 - val_acc: 0.0633\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5538 - acc: 0.0397 - val_loss: 4.4116 - val_acc: 0.0646\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5435 - acc: 0.0421 - val_loss: 4.4084 - val_acc: 0.0672\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5305 - acc: 0.0463 - val_loss: 4.4006 - val_acc: 0.0678\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5375 - acc: 0.0425 - val_loss: 4.3950 - val_acc: 0.0668\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5306 - acc: 0.0455 - val_loss: 4.3867 - val_acc: 0.0659\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5291 - acc: 0.0421 - val_loss: 4.3806 - val_acc: 0.0681\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5284 - acc: 0.0439 - val_loss: 4.3767 - val_acc: 0.0685\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5116 - acc: 0.0474 - val_loss: 4.3684 - val_acc: 0.0694\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5186 - acc: 0.0412 - val_loss: 4.3623 - val_acc: 0.0694\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5064 - acc: 0.0475 - val_loss: 4.3591 - val_acc: 0.0698\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5262 - acc: 0.0448 - val_loss: 4.3546 - val_acc: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.5117 - acc: 0.0447 - val_loss: 4.3493 - val_acc: 0.0672\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.5136 - acc: 0.0453 - val_loss: 4.3422 - val_acc: 0.0717\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4896 - acc: 0.0454 - val_loss: 4.3391 - val_acc: 0.0734\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.5008 - acc: 0.0439 - val_loss: 4.3338 - val_acc: 0.0730\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4898 - acc: 0.0466 - val_loss: 4.3306 - val_acc: 0.0753\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4957 - acc: 0.0478 - val_loss: 4.3277 - val_acc: 0.0743\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4837 - acc: 0.0488 - val_loss: 4.3219 - val_acc: 0.0776\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4769 - acc: 0.0443 - val_loss: 4.3169 - val_acc: 0.0769\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4810 - acc: 0.0472 - val_loss: 4.3155 - val_acc: 0.0756\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 23s 829ms/step - loss: 4.4808 - acc: 0.0516 - val_loss: 4.3090 - val_acc: 0.0779\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4895 - acc: 0.0479 - val_loss: 4.3060 - val_acc: 0.0766\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4606 - acc: 0.0537 - val_loss: 4.3014 - val_acc: 0.0802\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4927 - acc: 0.0460 - val_loss: 4.2978 - val_acc: 0.0779\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4691 - acc: 0.0521 - val_loss: 4.2965 - val_acc: 0.0747\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4721 - acc: 0.0450 - val_loss: 4.2895 - val_acc: 0.0779\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 23s 837ms/step - loss: 4.4587 - acc: 0.0524 - val_loss: 4.2862 - val_acc: 0.0786\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4595 - acc: 0.0515 - val_loss: 4.2829 - val_acc: 0.0789\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4615 - acc: 0.0530 - val_loss: 4.2783 - val_acc: 0.0802\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 23s 828ms/step - loss: 4.4550 - acc: 0.0514 - val_loss: 4.2758 - val_acc: 0.0789\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 23s 829ms/step - loss: 4.4662 - acc: 0.0508 - val_loss: 4.2731 - val_acc: 0.0763\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 4.4636 - acc: 0.0503 - val_loss: 4.2678 - val_acc: 0.0789\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 23s 829ms/step - loss: 4.4481 - acc: 0.0536 - val_loss: 4.2646 - val_acc: 0.0792\n",
      "Epoch 00086: early stopping\n",
      "Test accuracy: 0.0792305184243\n",
      "Creating model\n",
      "\n",
      "dropout= 0.7919157826643053\n",
      "layers= 0\n",
      "dontFreeze= 3\n",
      "batchSize= 256\n",
      "\n",
      "Epoch 1/150\n",
      "28/28 [==============================] - 26s 914ms/step - loss: 5.0863 - acc: 0.0091 - val_loss: 4.7872 - val_acc: 0.0117\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 24s 866ms/step - loss: 4.7879 - acc: 0.0113 - val_loss: 4.7872 - val_acc: 0.0130\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 24s 864ms/step - loss: 4.7871 - acc: 0.0116 - val_loss: 4.7871 - val_acc: 0.0137\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 24s 866ms/step - loss: 4.7870 - acc: 0.0117 - val_loss: 4.7869 - val_acc: 0.0137\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7866 - acc: 0.0115 - val_loss: 4.7859 - val_acc: 0.0153\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7866 - acc: 0.0110 - val_loss: 4.7868 - val_acc: 0.0137\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7865 - acc: 0.0117 - val_loss: 4.7867 - val_acc: 0.0137\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7863 - acc: 0.0117 - val_loss: 4.7867 - val_acc: 0.0137\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7862 - acc: 0.0117 - val_loss: 4.7866 - val_acc: 0.0137\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7861 - acc: 0.0118 - val_loss: 4.7865 - val_acc: 0.0137\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 24s 864ms/step - loss: 4.7859 - acc: 0.0117 - val_loss: 4.7864 - val_acc: 0.0137\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 24s 874ms/step - loss: 4.7858 - acc: 0.0117 - val_loss: 4.7863 - val_acc: 0.0137\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 24s 866ms/step - loss: 4.7857 - acc: 0.0117 - val_loss: 4.7863 - val_acc: 0.0137\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7855 - acc: 0.0117 - val_loss: 4.7862 - val_acc: 0.0137\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 24s 865ms/step - loss: 4.7854 - acc: 0.0118 - val_loss: 4.7861 - val_acc: 0.0137\n",
      "Epoch 00015: early stopping\n",
      "Test accuracy: 0.0136941636779\n",
      "Creating model\n",
      "\n",
      "dropout= 0.5802309085723005\n",
      "layers= 2\n",
      "dontFreeze= 3\n",
      "batchSize= 16\n",
      "\n",
      "Epoch 1/150\n",
      "448/447 [==============================] - 45s 100ms/step - loss: 4.7959 - acc: 0.0094 - val_loss: 4.7846 - val_acc: 0.0134\n",
      "Epoch 2/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.7834 - acc: 0.0112 - val_loss: 4.7762 - val_acc: 0.0130\n",
      "Epoch 3/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.7615 - acc: 0.0126 - val_loss: 4.7269 - val_acc: 0.0121\n",
      "Epoch 4/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.7236 - acc: 0.0156 - val_loss: 4.7093 - val_acc: 0.0114\n",
      "Epoch 5/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.7011 - acc: 0.0154 - val_loss: 4.6851 - val_acc: 0.0166\n",
      "Epoch 6/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.6793 - acc: 0.0169 - val_loss: 4.6707 - val_acc: 0.0205\n",
      "Epoch 7/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.6616 - acc: 0.0165 - val_loss: 4.6494 - val_acc: 0.0231\n",
      "Epoch 8/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.6455 - acc: 0.0197 - val_loss: 4.6311 - val_acc: 0.0199\n",
      "Epoch 9/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.6267 - acc: 0.0206 - val_loss: 4.6261 - val_acc: 0.0241\n",
      "Epoch 10/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.6146 - acc: 0.0235 - val_loss: 4.6099 - val_acc: 0.0271\n",
      "Epoch 11/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.6038 - acc: 0.0228 - val_loss: 4.5932 - val_acc: 0.0284\n",
      "Epoch 12/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.5939 - acc: 0.0278 - val_loss: 4.5737 - val_acc: 0.0316\n",
      "Epoch 13/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.5621 - acc: 0.0294 - val_loss: 4.5509 - val_acc: 0.0336\n",
      "Epoch 14/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.5494 - acc: 0.0315 - val_loss: 4.5224 - val_acc: 0.0398\n",
      "Epoch 15/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.5204 - acc: 0.0354 - val_loss: 4.4910 - val_acc: 0.0417\n",
      "Epoch 16/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.5001 - acc: 0.0367 - val_loss: 4.4570 - val_acc: 0.0443\n",
      "Epoch 17/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.4799 - acc: 0.0376 - val_loss: 4.4294 - val_acc: 0.0486\n",
      "Epoch 18/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.4642 - acc: 0.0400 - val_loss: 4.4020 - val_acc: 0.0512\n",
      "Epoch 19/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.4441 - acc: 0.0394 - val_loss: 4.3737 - val_acc: 0.0502\n",
      "Epoch 20/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.4271 - acc: 0.0451 - val_loss: 4.3486 - val_acc: 0.0554\n",
      "Epoch 21/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.3989 - acc: 0.0464 - val_loss: 4.3261 - val_acc: 0.0597\n",
      "Epoch 22/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/447 [==============================] - 43s 95ms/step - loss: 4.3925 - acc: 0.0453 - val_loss: 4.3128 - val_acc: 0.0577\n",
      "Epoch 23/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.3720 - acc: 0.0483 - val_loss: 4.2800 - val_acc: 0.0616\n",
      "Epoch 24/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.3531 - acc: 0.0489 - val_loss: 4.2709 - val_acc: 0.0649\n",
      "Epoch 25/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.3392 - acc: 0.0518 - val_loss: 4.2401 - val_acc: 0.0600\n",
      "Epoch 26/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.3327 - acc: 0.0522 - val_loss: 4.2359 - val_acc: 0.0616\n",
      "Epoch 27/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.3190 - acc: 0.0514 - val_loss: 4.1975 - val_acc: 0.0668\n",
      "Epoch 28/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.2967 - acc: 0.0536 - val_loss: 4.1942 - val_acc: 0.0688\n",
      "Epoch 29/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.2826 - acc: 0.0563 - val_loss: 4.1711 - val_acc: 0.0701\n",
      "Epoch 30/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.2782 - acc: 0.0609 - val_loss: 4.1676 - val_acc: 0.0750\n",
      "Epoch 31/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.2509 - acc: 0.0603 - val_loss: 4.1446 - val_acc: 0.0766\n",
      "Epoch 32/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.2329 - acc: 0.0624 - val_loss: 4.1174 - val_acc: 0.0792\n",
      "Epoch 33/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.2358 - acc: 0.0600 - val_loss: 4.1111 - val_acc: 0.0805\n",
      "Epoch 34/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.2268 - acc: 0.0663 - val_loss: 4.1135 - val_acc: 0.0779\n",
      "Epoch 35/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.2194 - acc: 0.0657 - val_loss: 4.0883 - val_acc: 0.0835\n",
      "Epoch 36/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1925 - acc: 0.0700 - val_loss: 4.0660 - val_acc: 0.0877\n",
      "Epoch 37/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.1820 - acc: 0.0725 - val_loss: 4.0637 - val_acc: 0.0858\n",
      "Epoch 38/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.1744 - acc: 0.0699 - val_loss: 4.0442 - val_acc: 0.0877\n",
      "Epoch 39/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1740 - acc: 0.0703 - val_loss: 4.0285 - val_acc: 0.0884\n",
      "Epoch 40/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1611 - acc: 0.0718 - val_loss: 4.0053 - val_acc: 0.0913\n",
      "Epoch 41/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1442 - acc: 0.0725 - val_loss: 4.0124 - val_acc: 0.0936\n",
      "Epoch 42/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1437 - acc: 0.0735 - val_loss: 3.9870 - val_acc: 0.0946\n",
      "Epoch 43/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1215 - acc: 0.0793 - val_loss: 3.9770 - val_acc: 0.0946\n",
      "Epoch 44/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1095 - acc: 0.0761 - val_loss: 3.9577 - val_acc: 0.0981\n",
      "Epoch 45/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.1029 - acc: 0.0813 - val_loss: 3.9563 - val_acc: 0.0955\n",
      "Epoch 46/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0935 - acc: 0.0828 - val_loss: 3.9607 - val_acc: 0.0965\n",
      "Epoch 47/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0811 - acc: 0.0813 - val_loss: 3.9371 - val_acc: 0.1014\n",
      "Epoch 48/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0831 - acc: 0.0811 - val_loss: 3.9223 - val_acc: 0.1007\n",
      "Epoch 49/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0895 - acc: 0.0814 - val_loss: 3.9178 - val_acc: 0.1040\n",
      "Epoch 50/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0626 - acc: 0.0840 - val_loss: 3.9029 - val_acc: 0.1030\n",
      "Epoch 51/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0480 - acc: 0.0897 - val_loss: 3.9047 - val_acc: 0.0994\n",
      "Epoch 52/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.0382 - acc: 0.0854 - val_loss: 3.8843 - val_acc: 0.1021\n",
      "Epoch 53/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0108 - acc: 0.0910 - val_loss: 3.8853 - val_acc: 0.1024\n",
      "Epoch 54/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 4.0225 - acc: 0.0875 - val_loss: 3.8570 - val_acc: 0.1063\n",
      "Epoch 55/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0108 - acc: 0.0849 - val_loss: 3.8518 - val_acc: 0.1069\n",
      "Epoch 56/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0153 - acc: 0.0874 - val_loss: 3.8439 - val_acc: 0.1109\n",
      "Epoch 57/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0126 - acc: 0.0943 - val_loss: 3.8423 - val_acc: 0.1096\n",
      "Epoch 58/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 4.0011 - acc: 0.0882 - val_loss: 3.8332 - val_acc: 0.1105\n",
      "Epoch 59/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.9738 - acc: 0.0979 - val_loss: 3.8298 - val_acc: 0.1096\n",
      "Epoch 60/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.9782 - acc: 0.0921 - val_loss: 3.8265 - val_acc: 0.1092\n",
      "Epoch 61/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9728 - acc: 0.0946 - val_loss: 3.8103 - val_acc: 0.1157\n",
      "Epoch 62/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9694 - acc: 0.1001 - val_loss: 3.8126 - val_acc: 0.1148\n",
      "Epoch 63/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9611 - acc: 0.1006 - val_loss: 3.8204 - val_acc: 0.1118\n",
      "Epoch 64/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.9518 - acc: 0.0950 - val_loss: 3.7908 - val_acc: 0.1118\n",
      "Epoch 65/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.9561 - acc: 0.1017 - val_loss: 3.7992 - val_acc: 0.1105\n",
      "Epoch 66/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9518 - acc: 0.1003 - val_loss: 3.7942 - val_acc: 0.1151\n",
      "Epoch 67/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9226 - acc: 0.1025 - val_loss: 3.7740 - val_acc: 0.1164\n",
      "Epoch 68/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9311 - acc: 0.0997 - val_loss: 3.7693 - val_acc: 0.1213\n",
      "Epoch 69/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9099 - acc: 0.1074 - val_loss: 3.7847 - val_acc: 0.1180\n",
      "Epoch 70/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9263 - acc: 0.1036 - val_loss: 3.7704 - val_acc: 0.1187\n",
      "Epoch 71/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9211 - acc: 0.1059 - val_loss: 3.7582 - val_acc: 0.1203\n",
      "Epoch 72/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9229 - acc: 0.1071 - val_loss: 3.7578 - val_acc: 0.1190\n",
      "Epoch 73/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8998 - acc: 0.1046 - val_loss: 3.7568 - val_acc: 0.1252\n",
      "Epoch 74/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8818 - acc: 0.1103 - val_loss: 3.7620 - val_acc: 0.1203\n",
      "Epoch 75/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.9129 - acc: 0.1034 - val_loss: 3.7541 - val_acc: 0.1236\n",
      "Epoch 76/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8940 - acc: 0.1036 - val_loss: 3.7536 - val_acc: 0.1249\n",
      "Epoch 77/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8895 - acc: 0.1057 - val_loss: 3.7494 - val_acc: 0.1255\n",
      "Epoch 78/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8909 - acc: 0.1082 - val_loss: 3.7428 - val_acc: 0.1262\n",
      "Epoch 79/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8860 - acc: 0.1039 - val_loss: 3.7467 - val_acc: 0.1272\n",
      "Epoch 80/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8789 - acc: 0.1145 - val_loss: 3.7423 - val_acc: 0.1239\n",
      "Epoch 81/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8888 - acc: 0.1074 - val_loss: 3.7439 - val_acc: 0.1268\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8788 - acc: 0.1118 - val_loss: 3.7282 - val_acc: 0.1307\n",
      "Epoch 83/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8699 - acc: 0.1118 - val_loss: 3.7333 - val_acc: 0.1265\n",
      "Epoch 84/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8600 - acc: 0.1108 - val_loss: 3.7342 - val_acc: 0.1259\n",
      "Epoch 85/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8651 - acc: 0.1050 - val_loss: 3.7132 - val_acc: 0.1314\n",
      "Epoch 86/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8426 - acc: 0.1149 - val_loss: 3.7156 - val_acc: 0.1298\n",
      "Epoch 87/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8416 - acc: 0.1103 - val_loss: 3.6993 - val_acc: 0.1314\n",
      "Epoch 88/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8563 - acc: 0.1125 - val_loss: 3.7141 - val_acc: 0.1324\n",
      "Epoch 89/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8532 - acc: 0.1142 - val_loss: 3.7074 - val_acc: 0.1321\n",
      "Epoch 90/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8390 - acc: 0.1089 - val_loss: 3.7130 - val_acc: 0.1301\n",
      "Epoch 91/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8417 - acc: 0.1136 - val_loss: 3.6972 - val_acc: 0.1294\n",
      "Epoch 92/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8178 - acc: 0.1158 - val_loss: 3.6858 - val_acc: 0.1327\n",
      "Epoch 93/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8273 - acc: 0.1161 - val_loss: 3.7021 - val_acc: 0.1327\n",
      "Epoch 94/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8204 - acc: 0.1103 - val_loss: 3.6863 - val_acc: 0.1366\n",
      "Epoch 95/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8213 - acc: 0.1163 - val_loss: 3.6923 - val_acc: 0.1307\n",
      "Epoch 96/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8177 - acc: 0.1189 - val_loss: 3.6726 - val_acc: 0.1366\n",
      "Epoch 97/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8196 - acc: 0.1158 - val_loss: 3.6747 - val_acc: 0.1347\n",
      "Epoch 98/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.8240 - acc: 0.1113 - val_loss: 3.6812 - val_acc: 0.1337\n",
      "Epoch 99/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8183 - acc: 0.1162 - val_loss: 3.6783 - val_acc: 0.1347\n",
      "Epoch 100/150\n",
      "448/447 [==============================] - 57s 128ms/step - loss: 3.8205 - acc: 0.1158 - val_loss: 3.6688 - val_acc: 0.1334\n",
      "Epoch 101/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8030 - acc: 0.1182 - val_loss: 3.6597 - val_acc: 0.1376\n",
      "Epoch 102/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8040 - acc: 0.1212 - val_loss: 3.6670 - val_acc: 0.1379\n",
      "Epoch 103/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8140 - acc: 0.1175 - val_loss: 3.6678 - val_acc: 0.1376\n",
      "Epoch 104/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7882 - acc: 0.1206 - val_loss: 3.6524 - val_acc: 0.1431\n",
      "Epoch 105/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7933 - acc: 0.1238 - val_loss: 3.6793 - val_acc: 0.1343\n",
      "Epoch 106/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7902 - acc: 0.1228 - val_loss: 3.6574 - val_acc: 0.1360\n",
      "Epoch 107/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7865 - acc: 0.1209 - val_loss: 3.6620 - val_acc: 0.1396\n",
      "Epoch 108/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7721 - acc: 0.1199 - val_loss: 3.6464 - val_acc: 0.1428\n",
      "Epoch 109/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.8044 - acc: 0.1221 - val_loss: 3.6593 - val_acc: 0.1399\n",
      "Epoch 110/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7628 - acc: 0.1279 - val_loss: 3.6525 - val_acc: 0.1438\n",
      "Epoch 111/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7866 - acc: 0.1224 - val_loss: 3.6490 - val_acc: 0.1412\n",
      "Epoch 112/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7729 - acc: 0.1269 - val_loss: 3.6612 - val_acc: 0.1412\n",
      "Epoch 113/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7619 - acc: 0.1293 - val_loss: 3.6567 - val_acc: 0.1438\n",
      "Epoch 114/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7675 - acc: 0.1265 - val_loss: 3.6579 - val_acc: 0.1415\n",
      "Epoch 115/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7711 - acc: 0.1250 - val_loss: 3.6558 - val_acc: 0.1441\n",
      "Epoch 116/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7797 - acc: 0.1246 - val_loss: 3.6378 - val_acc: 0.1467\n",
      "Epoch 117/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7511 - acc: 0.1254 - val_loss: 3.6500 - val_acc: 0.1431\n",
      "Epoch 118/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7548 - acc: 0.1282 - val_loss: 3.6490 - val_acc: 0.1441\n",
      "Epoch 119/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7665 - acc: 0.1271 - val_loss: 3.6409 - val_acc: 0.1441\n",
      "Epoch 120/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7590 - acc: 0.1264 - val_loss: 3.6322 - val_acc: 0.1438\n",
      "Epoch 121/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7614 - acc: 0.1287 - val_loss: 3.6416 - val_acc: 0.1451\n",
      "Epoch 122/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7661 - acc: 0.1188 - val_loss: 3.6274 - val_acc: 0.1490\n",
      "Epoch 123/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7526 - acc: 0.1292 - val_loss: 3.6394 - val_acc: 0.1454\n",
      "Epoch 124/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7417 - acc: 0.1289 - val_loss: 3.6373 - val_acc: 0.1418\n",
      "Epoch 125/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7341 - acc: 0.1294 - val_loss: 3.6271 - val_acc: 0.1490\n",
      "Epoch 126/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7496 - acc: 0.1279 - val_loss: 3.6349 - val_acc: 0.1451\n",
      "Epoch 127/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7447 - acc: 0.1272 - val_loss: 3.6199 - val_acc: 0.1451\n",
      "Epoch 128/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7303 - acc: 0.1288 - val_loss: 3.6312 - val_acc: 0.1451\n",
      "Epoch 129/150\n",
      "448/447 [==============================] - 43s 95ms/step - loss: 3.7562 - acc: 0.1264 - val_loss: 3.6272 - val_acc: 0.1470\n",
      "Epoch 130/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7429 - acc: 0.1325 - val_loss: 3.6317 - val_acc: 0.1435\n",
      "Epoch 131/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7315 - acc: 0.1313 - val_loss: 3.6173 - val_acc: 0.1467\n",
      "Epoch 132/150\n",
      "448/447 [==============================] - 43s 96ms/step - loss: 3.7346 - acc: 0.1273 - val_loss: 3.6256 - val_acc: 0.1444\n",
      "Epoch 00132: early stopping\n",
      "Test accuracy: 0.14444082165\n",
      "Creating model\n",
      "\n",
      "dropout= 0.6986522016432655\n",
      "layers= 0\n",
      "dontFreeze= 2\n",
      "batchSize= 16\n",
      "\n",
      "Epoch 1/150\n",
      "448/447 [==============================] - 39s 86ms/step - loss: 4.8943 - acc: 0.0120 - val_loss: 4.7266 - val_acc: 0.0248\n",
      "Epoch 2/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.7544 - acc: 0.0197 - val_loss: 4.6410 - val_acc: 0.0342\n",
      "Epoch 3/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.6983 - acc: 0.0242 - val_loss: 4.5474 - val_acc: 0.0538\n",
      "Epoch 4/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.6332 - acc: 0.0290 - val_loss: 4.4552 - val_acc: 0.0577\n",
      "Epoch 5/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.5794 - acc: 0.0386 - val_loss: 4.3793 - val_acc: 0.0708\n",
      "Epoch 6/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.5237 - acc: 0.0420 - val_loss: 4.3203 - val_acc: 0.0750\n",
      "Epoch 7/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.4777 - acc: 0.0474 - val_loss: 4.2699 - val_acc: 0.0835\n",
      "Epoch 8/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.4405 - acc: 0.0500 - val_loss: 4.2338 - val_acc: 0.0835\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/447 [==============================] - 38s 84ms/step - loss: 4.4156 - acc: 0.0543 - val_loss: 4.1902 - val_acc: 0.0838\n",
      "Epoch 10/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.3862 - acc: 0.0512 - val_loss: 4.1568 - val_acc: 0.0903\n",
      "Epoch 11/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.3665 - acc: 0.0588 - val_loss: 4.1310 - val_acc: 0.0946\n",
      "Epoch 12/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.3320 - acc: 0.0580 - val_loss: 4.1088 - val_acc: 0.0978\n",
      "Epoch 13/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.3109 - acc: 0.0617 - val_loss: 4.0907 - val_acc: 0.1017\n",
      "Epoch 14/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.2981 - acc: 0.0631 - val_loss: 4.0681 - val_acc: 0.0981\n",
      "Epoch 15/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.2878 - acc: 0.0669 - val_loss: 4.0457 - val_acc: 0.1017\n",
      "Epoch 16/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.2571 - acc: 0.0679 - val_loss: 4.0245 - val_acc: 0.1043\n",
      "Epoch 17/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.2507 - acc: 0.0685 - val_loss: 4.0153 - val_acc: 0.1125\n",
      "Epoch 18/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.2425 - acc: 0.0643 - val_loss: 3.9908 - val_acc: 0.1109\n",
      "Epoch 19/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.2284 - acc: 0.0707 - val_loss: 3.9922 - val_acc: 0.1125\n",
      "Epoch 20/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.2120 - acc: 0.0758 - val_loss: 3.9745 - val_acc: 0.1135\n",
      "Epoch 21/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1983 - acc: 0.0732 - val_loss: 3.9589 - val_acc: 0.1164\n",
      "Epoch 22/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1887 - acc: 0.0765 - val_loss: 3.9546 - val_acc: 0.1171\n",
      "Epoch 23/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1799 - acc: 0.0775 - val_loss: 3.9497 - val_acc: 0.1180\n",
      "Epoch 24/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1666 - acc: 0.0781 - val_loss: 3.9421 - val_acc: 0.1219\n",
      "Epoch 25/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1566 - acc: 0.0790 - val_loss: 3.9352 - val_acc: 0.1187\n",
      "Epoch 26/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.1573 - acc: 0.0777 - val_loss: 3.9320 - val_acc: 0.1203\n",
      "Epoch 27/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1289 - acc: 0.0878 - val_loss: 3.9185 - val_acc: 0.1206\n",
      "Epoch 28/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1341 - acc: 0.0800 - val_loss: 3.9117 - val_acc: 0.1242\n",
      "Epoch 29/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1320 - acc: 0.0812 - val_loss: 3.9110 - val_acc: 0.1203\n",
      "Epoch 30/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1230 - acc: 0.0785 - val_loss: 3.8995 - val_acc: 0.1216\n",
      "Epoch 31/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1191 - acc: 0.0825 - val_loss: 3.9008 - val_acc: 0.1239\n",
      "Epoch 32/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1138 - acc: 0.0857 - val_loss: 3.8901 - val_acc: 0.1249\n",
      "Epoch 33/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.1136 - acc: 0.0839 - val_loss: 3.8880 - val_acc: 0.1265\n",
      "Epoch 34/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0991 - acc: 0.0898 - val_loss: 3.8863 - val_acc: 0.1281\n",
      "Epoch 35/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.0910 - acc: 0.0917 - val_loss: 3.8823 - val_acc: 0.1304\n",
      "Epoch 36/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0709 - acc: 0.0917 - val_loss: 3.8733 - val_acc: 0.1301\n",
      "Epoch 37/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0790 - acc: 0.0850 - val_loss: 3.8753 - val_acc: 0.1311\n",
      "Epoch 38/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0871 - acc: 0.0851 - val_loss: 3.8695 - val_acc: 0.1363\n",
      "Epoch 39/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0620 - acc: 0.0921 - val_loss: 3.8671 - val_acc: 0.1304\n",
      "Epoch 40/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0750 - acc: 0.0945 - val_loss: 3.8629 - val_acc: 0.1307\n",
      "Epoch 41/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0680 - acc: 0.0928 - val_loss: 3.8546 - val_acc: 0.1317\n",
      "Epoch 42/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0436 - acc: 0.0972 - val_loss: 3.8553 - val_acc: 0.1307\n",
      "Epoch 43/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0601 - acc: 0.0968 - val_loss: 3.8560 - val_acc: 0.1304\n",
      "Epoch 44/150\n",
      "448/447 [==============================] - 38s 85ms/step - loss: 4.0455 - acc: 0.0970 - val_loss: 3.8467 - val_acc: 0.1337\n",
      "Epoch 45/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0449 - acc: 0.0949 - val_loss: 3.8440 - val_acc: 0.1353\n",
      "Epoch 46/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0391 - acc: 0.0941 - val_loss: 3.8427 - val_acc: 0.1314\n",
      "Epoch 47/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0160 - acc: 0.1036 - val_loss: 3.8401 - val_acc: 0.1337\n",
      "Epoch 48/150\n",
      "448/447 [==============================] - 38s 84ms/step - loss: 4.0344 - acc: 0.0927 - val_loss: 3.8346 - val_acc: 0.1347\n",
      "Epoch 00048: early stopping\n",
      "Test accuracy: 0.134659276168\n",
      "Creating model\n",
      "\n",
      "dropout= 0.9115536700268596\n",
      "layers= 2\n",
      "dontFreeze= 1\n",
      "batchSize= 256\n",
      "\n",
      "Epoch 1/150\n",
      "28/28 [==============================] - 25s 893ms/step - loss: 5.3512 - acc: 0.0089 - val_loss: 4.8039 - val_acc: 0.0062\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.9644 - acc: 0.0080 - val_loss: 4.7871 - val_acc: 0.0101\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.8688 - acc: 0.0087 - val_loss: 4.7843 - val_acc: 0.0101\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.8318 - acc: 0.0092 - val_loss: 4.7838 - val_acc: 0.0091\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.8149 - acc: 0.0106 - val_loss: 4.7839 - val_acc: 0.0111\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.8013 - acc: 0.0094 - val_loss: 4.7845 - val_acc: 0.0117\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7980 - acc: 0.0094 - val_loss: 4.7851 - val_acc: 0.0104\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 24s 840ms/step - loss: 4.7919 - acc: 0.0102 - val_loss: 4.7851 - val_acc: 0.0065\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7903 - acc: 0.0102 - val_loss: 4.7848 - val_acc: 0.0098\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 24s 840ms/step - loss: 4.7892 - acc: 0.0103 - val_loss: 4.7843 - val_acc: 0.0108\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7882 - acc: 0.0098 - val_loss: 4.7843 - val_acc: 0.0124\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 23s 833ms/step - loss: 4.7865 - acc: 0.0122 - val_loss: 4.7848 - val_acc: 0.0137\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7898 - acc: 0.0080 - val_loss: 4.7854 - val_acc: 0.0124\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7839 - acc: 0.0125 - val_loss: 4.7852 - val_acc: 0.0127\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 23s 833ms/step - loss: 4.7850 - acc: 0.0132 - val_loss: 4.7841 - val_acc: 0.0098\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7865 - acc: 0.0123 - val_loss: 4.7836 - val_acc: 0.0104\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7844 - acc: 0.0127 - val_loss: 4.7831 - val_acc: 0.0134\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7846 - acc: 0.0123 - val_loss: 4.7820 - val_acc: 0.0127\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7861 - acc: 0.0115 - val_loss: 4.7816 - val_acc: 0.0130\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7830 - acc: 0.0126 - val_loss: 4.7796 - val_acc: 0.0150\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7820 - acc: 0.0122 - val_loss: 4.7785 - val_acc: 0.0157\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7826 - acc: 0.0127 - val_loss: 4.7797 - val_acc: 0.0163\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 4.7812 - acc: 0.0115 - val_loss: 4.7784 - val_acc: 0.0114\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.7817 - acc: 0.0130 - val_loss: 4.7785 - val_acc: 0.0124\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7835 - acc: 0.0117 - val_loss: 4.7790 - val_acc: 0.0124\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7796 - acc: 0.0138 - val_loss: 4.7772 - val_acc: 0.0137\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 23s 829ms/step - loss: 4.7789 - acc: 0.0129 - val_loss: 4.7755 - val_acc: 0.0160\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7774 - acc: 0.0113 - val_loss: 4.7749 - val_acc: 0.0137\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7776 - acc: 0.0140 - val_loss: 4.7749 - val_acc: 0.0114\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.7779 - acc: 0.0124 - val_loss: 4.7745 - val_acc: 0.0140\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 4.7762 - acc: 0.0119 - val_loss: 4.7730 - val_acc: 0.0153\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 4.7748 - acc: 0.0140 - val_loss: 4.7718 - val_acc: 0.0143\n",
      "Epoch 00032: early stopping\n",
      "Test accuracy: 0.0143462667101\n",
      "Creating model\n",
      "\n",
      "dropout= 0.5828475352693441\n",
      "layers= 0\n",
      "dontFreeze= 2\n",
      "batchSize= 256\n",
      "\n",
      "Epoch 1/150\n",
      "28/28 [==============================] - 25s 899ms/step - loss: 5.1536 - acc: 0.0071 - val_loss: 4.7611 - val_acc: 0.0153\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 4.8383 - acc: 0.0125 - val_loss: 4.7169 - val_acc: 0.0245\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.7646 - acc: 0.0198 - val_loss: 4.6771 - val_acc: 0.0310\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 4.7174 - acc: 0.0228 - val_loss: 4.6295 - val_acc: 0.0456\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.6779 - acc: 0.0285 - val_loss: 4.5727 - val_acc: 0.0515\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.6244 - acc: 0.0344 - val_loss: 4.4973 - val_acc: 0.0593\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.5840 - acc: 0.0391 - val_loss: 4.4418 - val_acc: 0.0649\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 4.5366 - acc: 0.0425 - val_loss: 4.3665 - val_acc: 0.0685\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 4.4838 - acc: 0.0491 - val_loss: 4.3037 - val_acc: 0.0769\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.4372 - acc: 0.0558 - val_loss: 4.2454 - val_acc: 0.0871\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.4037 - acc: 0.0544 - val_loss: 4.2061 - val_acc: 0.0877\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 4.3530 - acc: 0.0636 - val_loss: 4.1660 - val_acc: 0.0903\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 4.3197 - acc: 0.0636 - val_loss: 4.1211 - val_acc: 0.1027\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 4.2895 - acc: 0.0660 - val_loss: 4.0890 - val_acc: 0.1030\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 4.2780 - acc: 0.0752 - val_loss: 4.0578 - val_acc: 0.1063\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 4.2277 - acc: 0.0767 - val_loss: 4.0357 - val_acc: 0.1027\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 4.2363 - acc: 0.0788 - val_loss: 4.0099 - val_acc: 0.1135\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.1920 - acc: 0.0765 - val_loss: 3.9832 - val_acc: 0.1177\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 4.1557 - acc: 0.0849 - val_loss: 3.9601 - val_acc: 0.1223\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 4.1363 - acc: 0.0830 - val_loss: 3.9440 - val_acc: 0.1213\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.1431 - acc: 0.0837 - val_loss: 3.9268 - val_acc: 0.1229\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.1244 - acc: 0.0935 - val_loss: 3.9123 - val_acc: 0.1242\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.0906 - acc: 0.0930 - val_loss: 3.8991 - val_acc: 0.1291\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.0915 - acc: 0.0949 - val_loss: 3.8834 - val_acc: 0.1340\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 4.0726 - acc: 0.0963 - val_loss: 3.8809 - val_acc: 0.1268\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 4.0711 - acc: 0.0952 - val_loss: 3.8664 - val_acc: 0.1301\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.0376 - acc: 0.1041 - val_loss: 3.8498 - val_acc: 0.1327\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 4.0367 - acc: 0.0952 - val_loss: 3.8393 - val_acc: 0.1396\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 4.0185 - acc: 0.1047 - val_loss: 3.8213 - val_acc: 0.1412\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.9916 - acc: 0.1098 - val_loss: 3.8150 - val_acc: 0.1409\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.9963 - acc: 0.1101 - val_loss: 3.8107 - val_acc: 0.1418\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 3.9949 - acc: 0.1047 - val_loss: 3.7985 - val_acc: 0.1431\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.9614 - acc: 0.1048 - val_loss: 3.7913 - val_acc: 0.1396\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.9491 - acc: 0.1162 - val_loss: 3.7892 - val_acc: 0.1461\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.9327 - acc: 0.1194 - val_loss: 3.7794 - val_acc: 0.1448\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 3.9248 - acc: 0.1142 - val_loss: 3.7729 - val_acc: 0.1412\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.9363 - acc: 0.1146 - val_loss: 3.7532 - val_acc: 0.1510\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.9106 - acc: 0.1171 - val_loss: 3.7498 - val_acc: 0.1506\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 24s 851ms/step - loss: 3.9131 - acc: 0.1148 - val_loss: 3.7482 - val_acc: 0.1503\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 3.9170 - acc: 0.1103 - val_loss: 3.7454 - val_acc: 0.1497\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.8971 - acc: 0.1164 - val_loss: 3.7290 - val_acc: 0.1506\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.8643 - acc: 0.1182 - val_loss: 3.7191 - val_acc: 0.1562\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 3.8743 - acc: 0.1213 - val_loss: 3.7231 - val_acc: 0.1529\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.8937 - acc: 0.1167 - val_loss: 3.7206 - val_acc: 0.1532\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 24s 844ms/step - loss: 3.8607 - acc: 0.1263 - val_loss: 3.7104 - val_acc: 0.1542\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.8517 - acc: 0.1235 - val_loss: 3.7000 - val_acc: 0.1545\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 24s 846ms/step - loss: 3.8646 - acc: 0.1214 - val_loss: 3.6981 - val_acc: 0.1575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.8482 - acc: 0.1287 - val_loss: 3.7008 - val_acc: 0.1559\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.8270 - acc: 0.1280 - val_loss: 3.6909 - val_acc: 0.1594\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.8108 - acc: 0.1301 - val_loss: 3.6794 - val_acc: 0.1562\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.8330 - acc: 0.1265 - val_loss: 3.6855 - val_acc: 0.1572\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.8166 - acc: 0.1346 - val_loss: 3.6772 - val_acc: 0.1585\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.8104 - acc: 0.1352 - val_loss: 3.6703 - val_acc: 0.1572\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 3.8106 - acc: 0.1288 - val_loss: 3.6763 - val_acc: 0.1607\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7809 - acc: 0.1322 - val_loss: 3.6627 - val_acc: 0.1617\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 3.7907 - acc: 0.1328 - val_loss: 3.6750 - val_acc: 0.1575\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.7679 - acc: 0.1357 - val_loss: 3.6649 - val_acc: 0.1591\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7723 - acc: 0.1341 - val_loss: 3.6671 - val_acc: 0.1604\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 3.7671 - acc: 0.1314 - val_loss: 3.6626 - val_acc: 0.1572\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.7595 - acc: 0.1392 - val_loss: 3.6531 - val_acc: 0.1624\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7603 - acc: 0.1439 - val_loss: 3.6518 - val_acc: 0.1614\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.7467 - acc: 0.1394 - val_loss: 3.6558 - val_acc: 0.1692\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 3.7400 - acc: 0.1429 - val_loss: 3.6529 - val_acc: 0.1627\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7437 - acc: 0.1455 - val_loss: 3.6453 - val_acc: 0.1624\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 24s 841ms/step - loss: 3.7220 - acc: 0.1473 - val_loss: 3.6440 - val_acc: 0.1617\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7154 - acc: 0.1486 - val_loss: 3.6435 - val_acc: 0.1601\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.7347 - acc: 0.1376 - val_loss: 3.6387 - val_acc: 0.1643\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7150 - acc: 0.1480 - val_loss: 3.6378 - val_acc: 0.1627\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7095 - acc: 0.1497 - val_loss: 3.6284 - val_acc: 0.1643\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.7113 - acc: 0.1466 - val_loss: 3.6275 - val_acc: 0.1647\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.7146 - acc: 0.1514 - val_loss: 3.6241 - val_acc: 0.1643\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.6966 - acc: 0.1514 - val_loss: 3.6167 - val_acc: 0.1702\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.6955 - acc: 0.1485 - val_loss: 3.6113 - val_acc: 0.1728\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 3.7002 - acc: 0.1471 - val_loss: 3.6158 - val_acc: 0.1738\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 3.7023 - acc: 0.1478 - val_loss: 3.6214 - val_acc: 0.1647\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.6681 - acc: 0.1543 - val_loss: 3.6162 - val_acc: 0.1705\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.6863 - acc: 0.1484 - val_loss: 3.6042 - val_acc: 0.1660\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.6719 - acc: 0.1508 - val_loss: 3.6059 - val_acc: 0.1702\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.6919 - acc: 0.1468 - val_loss: 3.6072 - val_acc: 0.1647\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.6699 - acc: 0.1528 - val_loss: 3.6088 - val_acc: 0.1650\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.6681 - acc: 0.1552 - val_loss: 3.5975 - val_acc: 0.1712\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 3.6699 - acc: 0.1519 - val_loss: 3.5995 - val_acc: 0.1718\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 3.6427 - acc: 0.1539 - val_loss: 3.6026 - val_acc: 0.1692\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 24s 842ms/step - loss: 3.6441 - acc: 0.1574 - val_loss: 3.6002 - val_acc: 0.1715\n",
      "Epoch 00084: early stopping\n",
      "Test accuracy: 0.171503097494\n",
      "Creating model\n",
      "\n",
      "dropout= 0.6139002077632487\n",
      "layers= 1\n",
      "dontFreeze= 3\n",
      "batchSize= 64\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 4.8244 - acc: 0.0099 - val_loss: 4.7773 - val_acc: 0.0088\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.7783 - acc: 0.0121 - val_loss: 4.7604 - val_acc: 0.0157\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.7581 - acc: 0.0126 - val_loss: 4.7239 - val_acc: 0.0183\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.7433 - acc: 0.0116 - val_loss: 4.6872 - val_acc: 0.0192\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.7183 - acc: 0.0172 - val_loss: 4.6536 - val_acc: 0.0280\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6978 - acc: 0.0210 - val_loss: 4.6255 - val_acc: 0.0355\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6938 - acc: 0.0198 - val_loss: 4.6157 - val_acc: 0.0280\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6711 - acc: 0.0235 - val_loss: 4.6068 - val_acc: 0.0287\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6639 - acc: 0.0244 - val_loss: 4.5855 - val_acc: 0.0352\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6469 - acc: 0.0217 - val_loss: 4.5659 - val_acc: 0.0365\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6271 - acc: 0.0270 - val_loss: 4.5707 - val_acc: 0.0381\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6163 - acc: 0.0271 - val_loss: 4.5167 - val_acc: 0.0368\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.6015 - acc: 0.0274 - val_loss: 4.5060 - val_acc: 0.0378\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.5850 - acc: 0.0268 - val_loss: 4.4873 - val_acc: 0.0408\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.5769 - acc: 0.0271 - val_loss: 4.4875 - val_acc: 0.0489\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.5669 - acc: 0.0295 - val_loss: 4.4609 - val_acc: 0.0463\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.5543 - acc: 0.0343 - val_loss: 4.4446 - val_acc: 0.0404\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.5399 - acc: 0.0345 - val_loss: 4.4010 - val_acc: 0.0505\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.5154 - acc: 0.0344 - val_loss: 4.4021 - val_acc: 0.0561\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.5062 - acc: 0.0355 - val_loss: 4.3590 - val_acc: 0.0577\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4940 - acc: 0.0377 - val_loss: 4.3603 - val_acc: 0.0554\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4744 - acc: 0.0393 - val_loss: 4.3469 - val_acc: 0.0587\n",
      "Epoch 23/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4658 - acc: 0.0420 - val_loss: 4.3560 - val_acc: 0.0574\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4611 - acc: 0.0447 - val_loss: 4.3238 - val_acc: 0.0623\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4369 - acc: 0.0409 - val_loss: 4.2971 - val_acc: 0.0580\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.4300 - acc: 0.0463 - val_loss: 4.2753 - val_acc: 0.0681\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4308 - acc: 0.0428 - val_loss: 4.2666 - val_acc: 0.0629\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4167 - acc: 0.0488 - val_loss: 4.2365 - val_acc: 0.0675\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.3970 - acc: 0.0443 - val_loss: 4.2336 - val_acc: 0.0665\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.3841 - acc: 0.0438 - val_loss: 4.2206 - val_acc: 0.0659\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.3807 - acc: 0.0555 - val_loss: 4.2049 - val_acc: 0.0708\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.3676 - acc: 0.0482 - val_loss: 4.2151 - val_acc: 0.0704\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.3409 - acc: 0.0546 - val_loss: 4.1817 - val_acc: 0.0769\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.3248 - acc: 0.0484 - val_loss: 4.1347 - val_acc: 0.0799\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.3230 - acc: 0.0545 - val_loss: 4.1354 - val_acc: 0.0769\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.2899 - acc: 0.0548 - val_loss: 4.1143 - val_acc: 0.0792\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.2773 - acc: 0.0585 - val_loss: 4.1081 - val_acc: 0.0779\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.2633 - acc: 0.0575 - val_loss: 4.0738 - val_acc: 0.0838\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.2656 - acc: 0.0584 - val_loss: 4.0365 - val_acc: 0.0923\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.2315 - acc: 0.0607 - val_loss: 4.0291 - val_acc: 0.0923\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.2346 - acc: 0.0587 - val_loss: 4.0304 - val_acc: 0.0893\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.2004 - acc: 0.0640 - val_loss: 4.0049 - val_acc: 0.0910\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.1788 - acc: 0.0671 - val_loss: 3.9543 - val_acc: 0.0955\n",
      "Epoch 44/150\n",
      "  1/112 [..............................] - ETA: 47s - loss: 4.0506 - acc: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/callbacks.py:116: UserWarning: Method on_batch_end() is slow compared to the batch update (0.237195). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 29s 261ms/step - loss: 4.1830 - acc: 0.0629 - val_loss: 3.9523 - val_acc: 0.0981\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.1536 - acc: 0.0689 - val_loss: 3.9722 - val_acc: 0.0936\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.1401 - acc: 0.0725 - val_loss: 3.9343 - val_acc: 0.1034\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.1246 - acc: 0.0774 - val_loss: 3.8975 - val_acc: 0.1060\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.1012 - acc: 0.0794 - val_loss: 3.8756 - val_acc: 0.1109\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.0903 - acc: 0.0791 - val_loss: 3.8873 - val_acc: 0.1092\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 4.0853 - acc: 0.0800 - val_loss: 3.8774 - val_acc: 0.1151\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.0745 - acc: 0.0764 - val_loss: 3.8480 - val_acc: 0.1193\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.0564 - acc: 0.0827 - val_loss: 3.8381 - val_acc: 0.1200\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 4.0459 - acc: 0.0805 - val_loss: 3.8382 - val_acc: 0.1157\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.0335 - acc: 0.0892 - val_loss: 3.8150 - val_acc: 0.1223\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.0158 - acc: 0.0853 - val_loss: 3.8163 - val_acc: 0.1193\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.0146 - acc: 0.0889 - val_loss: 3.8073 - val_acc: 0.1197\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.9952 - acc: 0.0903 - val_loss: 3.8111 - val_acc: 0.1210\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.9884 - acc: 0.0922 - val_loss: 3.7789 - val_acc: 0.1268\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.9578 - acc: 0.0959 - val_loss: 3.7703 - val_acc: 0.1236\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.9553 - acc: 0.0982 - val_loss: 3.7698 - val_acc: 0.1259\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.9563 - acc: 0.0983 - val_loss: 3.7465 - val_acc: 0.1294\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.9496 - acc: 0.0991 - val_loss: 3.7544 - val_acc: 0.1317\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.9349 - acc: 0.0967 - val_loss: 3.7442 - val_acc: 0.1356\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.9194 - acc: 0.1075 - val_loss: 3.7267 - val_acc: 0.1337\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.9157 - acc: 0.1055 - val_loss: 3.7430 - val_acc: 0.1307\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.8952 - acc: 0.1056 - val_loss: 3.7122 - val_acc: 0.1389\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.8877 - acc: 0.1043 - val_loss: 3.6899 - val_acc: 0.1405\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.8798 - acc: 0.1146 - val_loss: 3.6979 - val_acc: 0.1435\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.8913 - acc: 0.1054 - val_loss: 3.7147 - val_acc: 0.1389\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.8559 - acc: 0.1139 - val_loss: 3.6861 - val_acc: 0.1418\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.8560 - acc: 0.1167 - val_loss: 3.6706 - val_acc: 0.1431\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.8544 - acc: 0.1121 - val_loss: 3.6698 - val_acc: 0.1425\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 3.8334 - acc: 0.1185 - val_loss: 3.6936 - val_acc: 0.1399\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 77s 691ms/step - loss: 3.8283 - acc: 0.1123 - val_loss: 3.6519 - val_acc: 0.1438\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 3.8357 - acc: 0.1130 - val_loss: 3.6579 - val_acc: 0.1484\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.8128 - acc: 0.1226 - val_loss: 3.6654 - val_acc: 0.1457\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.7895 - acc: 0.1233 - val_loss: 3.6235 - val_acc: 0.1542\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.8081 - acc: 0.1195 - val_loss: 3.6400 - val_acc: 0.1480\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.7829 - acc: 0.1220 - val_loss: 3.6296 - val_acc: 0.1467\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.8058 - acc: 0.1177 - val_loss: 3.6399 - val_acc: 0.1474\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.7708 - acc: 0.1179 - val_loss: 3.6167 - val_acc: 0.1542\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.7715 - acc: 0.1284 - val_loss: 3.6296 - val_acc: 0.1484\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.7678 - acc: 0.1227 - val_loss: 3.6184 - val_acc: 0.1484\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.7526 - acc: 0.1280 - val_loss: 3.6132 - val_acc: 0.1539\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.7643 - acc: 0.1257 - val_loss: 3.5981 - val_acc: 0.1598\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.7564 - acc: 0.1332 - val_loss: 3.5990 - val_acc: 0.1588\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.7396 - acc: 0.1298 - val_loss: 3.5927 - val_acc: 0.1532\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.7434 - acc: 0.1314 - val_loss: 3.6032 - val_acc: 0.1545\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 3.7241 - acc: 0.1377 - val_loss: 3.5986 - val_acc: 0.1575\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.7226 - acc: 0.1321 - val_loss: 3.5875 - val_acc: 0.1545\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 3.7185 - acc: 0.1308 - val_loss: 3.6020 - val_acc: 0.1536\n",
      "Epoch 92/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.6891 - acc: 0.1454 - val_loss: 3.5932 - val_acc: 0.1539\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.7109 - acc: 0.1316 - val_loss: 3.5934 - val_acc: 0.1555\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.6791 - acc: 0.1401 - val_loss: 3.5946 - val_acc: 0.1536\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.6842 - acc: 0.1373 - val_loss: 3.5752 - val_acc: 0.1578\n",
      "Epoch 00095: early stopping\n",
      "Test accuracy: 0.157808933816\n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2164/10222 [01:06<04:09, 32.31it/s] "
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='VGG19Optimization_2')\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "val_loss, val_acc = best_model.evaluate(X_test, Y_test);\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(\"Validation loss: \", val_loss)\n",
    "print(\"Validation accuracy: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(modelPath);\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame(preds)\n",
    "# # Set column names to those generated by the one-hot encoding earlier\n",
    "# col_names = one_hot.columns.values\n",
    "# sub.columns = col_names\n",
    "# # Insert the column id from the sample_submission at the start of the data frame\n",
    "# sub.insert(0, 'id', df_test['id'])\n",
    "# sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
