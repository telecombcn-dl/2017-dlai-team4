{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# parameters #\n",
    "##############\n",
    "# dontFreezeLast = 0;\n",
    "\n",
    "# patience = 10;\n",
    "\n",
    "# gpuName = '/device:GPU:0'\n",
    "# workers = 2;\n",
    "# histogram_freq = 0;\n",
    "\n",
    "# epochs = 100;\n",
    "# validation_size=0.3;\n",
    "\n",
    "\n",
    "modelPath = '../models/VGG19_opt/run_adam.h5';\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the csv's so we can see some more information on the filenames and breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('../input/labels.csv')\n",
    "# df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "# print('Training images: ',df_train.shape[0])\n",
    "# print('Test images: ',df_test.shape[0])\n",
    "\n",
    "# reduce dimensionality\n",
    "#df_train = df_train.head(100)\n",
    "#df_test = df_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the breed needs to be one-hot encoded for the final submission, so we will now do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_series = pd.Series(df_train['breed'])\n",
    "# one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to, 90x90 px, you should play with this number to see how it affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 \n",
    "# for f, breed in tqdm(df_train.values[:10]):\n",
    "#     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "#     label = one_hot_labels[i]\n",
    "#     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "#     y_train.append(label)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in tqdm(df_test['id'].values):\n",
    "#     img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    "#     x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_raw = np.array(y_train, np.uint8)\n",
    "# x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "# x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shape of the outputs to make sure everyting went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Adam/lr:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# print(x_train_raw.shape)\n",
    "# print(y_train_raw.shape)\n",
    "# print(x_test.shape)\n",
    "a = keras.optimizers.Adam(lr=.4);\n",
    "print(a.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = y_train_raw.shape[1]\n",
    "# print('Number of classes: ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to create a validation set so that you can gauge the performance of your model on independent data, unseen to the model in training. We do this by splitting the current training set (x_train_raw) and the corresponding labels (y_train_raw) so that we set aside 30 % of the data at random and put these in validation sets (X_valid and Y_valid).\n",
    "\n",
    "* This split needs to be improved so that it contains images from every class, with 120 separate classes some can not be represented and so the validation score is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the CNN architecture. Here we are using a pre-trained model VGG19 which has already been trained to identify many different dog breeds (as well as a lot of other objects from the imagenet dataset see here for more information: http://image-net.org/about-overview). Unfortunately it doesn't seem possible to downlod the weights from within this kernel so make sure you set the weights argument to 'imagenet' and not None, as it currently is below.\n",
    "\n",
    "We then remove the final layer and instead replace it with a single dense layer with the number of nodes corresponding to the number of breed classes we have (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('Getting data')\n",
    "    df_train = pd.read_csv('../input/labels.csv')\n",
    "    df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "    \n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "    \n",
    "    im_size = 90\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values[:10]):\n",
    "        img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "    \n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    print('Splitting into training/validation')\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and model for hyperas\n",
    "\n",
    "def model(X_train,Y_train,X_valid,Y_valid):\n",
    "    print('Creating model')\n",
    "#     with tf.device('/device:GPU:0'):\n",
    "    base_model = VGG19(weights = 'imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(im_size, im_size, 3))\n",
    "\n",
    "    # Add a new top layer\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "    x = Dense(512,activation='relu')(x)\n",
    "    predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "    # This is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # First: train only the top layers (which were randomly initialized)\n",
    "    for i in range(len(base_model.layers)):\n",
    "        base_model.layers[i].trainable = False\n",
    "\n",
    "    # optimization\n",
    "    lr={{uniform(0.00001,0.01)}};\n",
    "    beta_1={{uniform(0.8,0.999)}};\n",
    "    beta_2={{uniform(0.99,0.99999)}};\n",
    "    decay={{uniform(0,0.01)}};\n",
    "\n",
    "    print()\n",
    "    print('lr=',lr);\n",
    "    print('beta_1=',beta_1);\n",
    "    print('beta_2=',beta_2);\n",
    "    print('decay=',decay);\n",
    "    print()\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks_list = [];\n",
    "    callbacks_list.append(keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=1));\n",
    "\n",
    "    print('Tensorboard NOT activated')\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "      epochs=100,\n",
    "      batch_size = 64,\n",
    "      validation_data=(X_valid, Y_valid),\n",
    "      verbose=1,\n",
    "      callbacks=callbacks_list)\n",
    "\n",
    "    score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.applications.vgg19 import VGG19\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from subprocess import check_output\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'lr': hp.uniform('lr', 0.00001,0.01),\n",
      "        'beta_1': hp.uniform('beta_1', 0.8,0.999),\n",
      "        'beta_2': hp.uniform('beta_2', 0.99,0.99999),\n",
      "        'decay': hp.uniform('decay', 0,0.01),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: print('Getting data')\n",
      "  3: df_train = pd.read_csv('../input/labels.csv')\n",
      "  4: df_test = pd.read_csv('../input/sample_submission.csv')\n",
      "  5: \n",
      "  6: targets_series = pd.Series(df_train['breed'])\n",
      "  7: one_hot = pd.get_dummies(targets_series, sparse = True)\n",
      "  8: one_hot_labels = np.asarray(one_hot)\n",
      "  9: \n",
      " 10: im_size = 90\n",
      " 11: x_train = []\n",
      " 12: y_train = []\n",
      " 13: x_test = []\n",
      " 14: \n",
      " 15: i = 0 \n",
      " 16: for f, breed in tqdm(df_train.values):\n",
      " 17:     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
      " 18:     label = one_hot_labels[i]\n",
      " 19:     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
      " 20:     y_train.append(label)\n",
      " 21:     i += 1\n",
      " 22: \n",
      " 23: y_train_raw = np.array(y_train, np.uint8)\n",
      " 24: x_train_raw = np.array(x_train, np.float32) / 255.\n",
      " 25: num_class = y_train_raw.shape[1]\n",
      " 26: \n",
      " 27: print('Splitting into training/validation')\n",
      " 28: X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
      " 29: \n",
      " 30: \n",
      " 31: \n",
      " 32: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print('Creating model')\n",
      "   4: #     with tf.device('/device:GPU:0'):\n",
      "   5:     config = tf.ConfigProto(allow_soft_placement=True)\n",
      "   6:     config.gpu_options.allow_growth=True\n",
      "   7:     sess = tf.Session(config=config)\n",
      "   8:     K.set_session(sess)\n",
      "   9: \n",
      "  10:     base_model = VGG19(weights = 'imagenet',\n",
      "  11:                        include_top=False,\n",
      "  12:                        input_shape=(im_size, im_size, 3))\n",
      "  13: \n",
      "  14:     # Add a new top layer\n",
      "  15:     x = base_model.output\n",
      "  16:     x = Flatten()(x)\n",
      "  17:     x = Dropout(0.7)(x)\n",
      "  18:     x = Dense(1024,activation='relu')(x)\n",
      "  19:     x = Dense(512,activation='relu')(x)\n",
      "  20:     predictions = Dense(num_class, activation='softmax')(x)\n",
      "  21: \n",
      "  22:     # This is the model we will train\n",
      "  23:     model = Model(inputs=base_model.input, outputs=predictions)\n",
      "  24: \n",
      "  25:     # First: train only the top layers (which were randomly initialized)\n",
      "  26:     for i in range(len(base_model.layers)):\n",
      "  27:         base_model.layers[i].trainable = False\n",
      "  28: \n",
      "  29:     # optimization\n",
      "  30:     lr=space['lr'];\n",
      "  31:     beta_1=space['beta_1'];\n",
      "  32:     beta_2=space['beta_2'];\n",
      "  33:     decay=space['decay'];\n",
      "  34: \n",
      "  35:     print()\n",
      "  36:     print('lr=',lr);\n",
      "  37:     print('beta_1=',beta_1);\n",
      "  38:     print('beta_2=',beta_2);\n",
      "  39:     print('decay=',decay);\n",
      "  40:     print()\n",
      "  41: \n",
      "  42:     adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
      "  43:     model.compile(loss='categorical_crossentropy', \n",
      "  44:                   optimizer=adam, \n",
      "  45:                   metrics=['accuracy'])\n",
      "  46: \n",
      "  47:     callbacks_list = [];\n",
      "  48:     callbacks_list.append(keras.callbacks.EarlyStopping(\n",
      "  49:         monitor='val_acc',\n",
      "  50:         patience=10,\n",
      "  51:         verbose=1));\n",
      "  52: \n",
      "  53:     print('Tensorboard NOT activated')\n",
      "  54: \n",
      "  55:     model.fit(X_train, Y_train,\n",
      "  56:       epochs=100,\n",
      "  57:       batch_size = 64,\n",
      "  58:       validation_data=(X_valid, Y_valid),\n",
      "  59:       verbose=1,\n",
      "  60:       callbacks=callbacks_list)\n",
      "  61: \n",
      "  62:     score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
      "  63:     print('Test accuracy:', acc)\n",
      "  64:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  65: \n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:31<00:00, 325.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "Creating model\n",
      "\n",
      "lr= 0.004376791431724103\n",
      "beta_1= 0.921564385546966\n",
      "beta_2= 0.9973643266762406\n",
      "decay= 0.006517968154887782\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.8475 - acc: 0.0091 - val_loss: 4.7859 - val_acc: 0.0114\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7391 - acc: 0.0177 - val_loss: 4.6365 - val_acc: 0.0241\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5565 - acc: 0.0333 - val_loss: 4.4187 - val_acc: 0.0470\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3568 - acc: 0.0537 - val_loss: 4.2446 - val_acc: 0.0727\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2304 - acc: 0.0693 - val_loss: 4.1663 - val_acc: 0.0799\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1395 - acc: 0.0778 - val_loss: 4.0932 - val_acc: 0.0919\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0498 - acc: 0.0992 - val_loss: 4.0402 - val_acc: 0.0972\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9978 - acc: 0.1003 - val_loss: 4.0160 - val_acc: 0.0942\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9277 - acc: 0.1087 - val_loss: 3.9590 - val_acc: 0.1082\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9075 - acc: 0.1113 - val_loss: 3.9421 - val_acc: 0.1099\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8513 - acc: 0.1220 - val_loss: 3.9282 - val_acc: 0.1115\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8255 - acc: 0.1249 - val_loss: 3.9224 - val_acc: 0.1138\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7770 - acc: 0.1386 - val_loss: 3.9063 - val_acc: 0.1167\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7678 - acc: 0.1372 - val_loss: 3.8882 - val_acc: 0.1157\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7456 - acc: 0.1434 - val_loss: 3.8845 - val_acc: 0.1180\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7095 - acc: 0.1403 - val_loss: 3.8790 - val_acc: 0.1135\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7038 - acc: 0.1462 - val_loss: 3.8604 - val_acc: 0.1239\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6679 - acc: 0.1557 - val_loss: 3.8566 - val_acc: 0.1239\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6495 - acc: 0.1579 - val_loss: 3.8563 - val_acc: 0.1226\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6424 - acc: 0.1515 - val_loss: 3.8621 - val_acc: 0.1229\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6073 - acc: 0.1638 - val_loss: 3.8469 - val_acc: 0.1206\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5904 - acc: 0.1613 - val_loss: 3.8431 - val_acc: 0.1242\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5797 - acc: 0.1700 - val_loss: 3.8349 - val_acc: 0.1242\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5619 - acc: 0.1722 - val_loss: 3.8346 - val_acc: 0.1236\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5540 - acc: 0.1734 - val_loss: 3.8317 - val_acc: 0.1288\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5363 - acc: 0.1733 - val_loss: 3.8348 - val_acc: 0.1291\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5205 - acc: 0.1762 - val_loss: 3.8286 - val_acc: 0.1307\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5256 - acc: 0.1785 - val_loss: 3.8353 - val_acc: 0.1288\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5023 - acc: 0.1867 - val_loss: 3.8267 - val_acc: 0.1307\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 3.4912 - acc: 0.1876 - val_loss: 3.8234 - val_acc: 0.1324\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4922 - acc: 0.1783 - val_loss: 3.8267 - val_acc: 0.1294\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4704 - acc: 0.1818 - val_loss: 3.8157 - val_acc: 0.1340\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4445 - acc: 0.1925 - val_loss: 3.8199 - val_acc: 0.1321\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4755 - acc: 0.1866 - val_loss: 3.8159 - val_acc: 0.1301\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4423 - acc: 0.1961 - val_loss: 3.8174 - val_acc: 0.1298\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4264 - acc: 0.1955 - val_loss: 3.8125 - val_acc: 0.1304\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4141 - acc: 0.1965 - val_loss: 3.8137 - val_acc: 0.1334\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4013 - acc: 0.1930 - val_loss: 3.8124 - val_acc: 0.1340\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4151 - acc: 0.1905 - val_loss: 3.8126 - val_acc: 0.1379\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3953 - acc: 0.1983 - val_loss: 3.8165 - val_acc: 0.1327\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3985 - acc: 0.1925 - val_loss: 3.8093 - val_acc: 0.1350\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3818 - acc: 0.2001 - val_loss: 3.8058 - val_acc: 0.1360\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3670 - acc: 0.2056 - val_loss: 3.8107 - val_acc: 0.1356\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3559 - acc: 0.2034 - val_loss: 3.8000 - val_acc: 0.1340\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 3.3500 - acc: 0.2122 - val_loss: 3.8081 - val_acc: 0.1343\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3512 - acc: 0.2055 - val_loss: 3.8059 - val_acc: 0.1343\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3423 - acc: 0.2088 - val_loss: 3.8061 - val_acc: 0.1373\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3307 - acc: 0.2112 - val_loss: 3.8106 - val_acc: 0.1334\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3318 - acc: 0.2095 - val_loss: 3.8099 - val_acc: 0.1334\n",
      "Epoch 00049: early stopping\n",
      "Test accuracy: 0.133355070101\n",
      "Creating model\n",
      "\n",
      "lr= 0.0038442505156940352\n",
      "beta_1= 0.9944231029585302\n",
      "beta_2= 0.9983583001802687\n",
      "decay= 0.009128294469805703\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.8680 - acc: 0.0096 - val_loss: 4.7709 - val_acc: 0.0124\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.7543 - acc: 0.0159 - val_loss: 4.7419 - val_acc: 0.0192\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.7113 - acc: 0.0194 - val_loss: 4.6989 - val_acc: 0.0212\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.6627 - acc: 0.0267 - val_loss: 4.6505 - val_acc: 0.0293\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6104 - acc: 0.0317 - val_loss: 4.6017 - val_acc: 0.0372\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5529 - acc: 0.0391 - val_loss: 4.5246 - val_acc: 0.0421\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4807 - acc: 0.0442 - val_loss: 4.4551 - val_acc: 0.0522\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4156 - acc: 0.0528 - val_loss: 4.3865 - val_acc: 0.0577\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3531 - acc: 0.0574 - val_loss: 4.3468 - val_acc: 0.0613\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3237 - acc: 0.0555 - val_loss: 4.3048 - val_acc: 0.0668\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2939 - acc: 0.0609 - val_loss: 4.2699 - val_acc: 0.0652\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2639 - acc: 0.0653 - val_loss: 4.2413 - val_acc: 0.0740\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2414 - acc: 0.0660 - val_loss: 4.2229 - val_acc: 0.0753\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2110 - acc: 0.0635 - val_loss: 4.2117 - val_acc: 0.0701\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2039 - acc: 0.0706 - val_loss: 4.1922 - val_acc: 0.0737\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.1802 - acc: 0.0713 - val_loss: 4.1820 - val_acc: 0.0763\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1704 - acc: 0.0728 - val_loss: 4.1706 - val_acc: 0.0799\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1557 - acc: 0.0794 - val_loss: 4.1593 - val_acc: 0.0786\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1400 - acc: 0.0818 - val_loss: 4.1476 - val_acc: 0.0822\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1335 - acc: 0.0797 - val_loss: 4.1406 - val_acc: 0.0815\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1211 - acc: 0.0868 - val_loss: 4.1339 - val_acc: 0.0828\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.1164 - acc: 0.0855 - val_loss: 4.1251 - val_acc: 0.0815\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1036 - acc: 0.0848 - val_loss: 4.1209 - val_acc: 0.0851\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0985 - acc: 0.0853 - val_loss: 4.1130 - val_acc: 0.0828\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0767 - acc: 0.0840 - val_loss: 4.1050 - val_acc: 0.0867\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0854 - acc: 0.0901 - val_loss: 4.0984 - val_acc: 0.0880\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.0718 - acc: 0.0839 - val_loss: 4.0933 - val_acc: 0.0910\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.0575 - acc: 0.0925 - val_loss: 4.0866 - val_acc: 0.0906\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0590 - acc: 0.0899 - val_loss: 4.0824 - val_acc: 0.0933\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.0607 - acc: 0.0904 - val_loss: 4.0792 - val_acc: 0.0955\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0548 - acc: 0.0934 - val_loss: 4.0719 - val_acc: 0.0946\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.0483 - acc: 0.0978 - val_loss: 4.0736 - val_acc: 0.0939\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0346 - acc: 0.0964 - val_loss: 4.0639 - val_acc: 0.0959\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0386 - acc: 0.0925 - val_loss: 4.0622 - val_acc: 0.0939\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0275 - acc: 0.0911 - val_loss: 4.0602 - val_acc: 0.0972\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0264 - acc: 0.0959 - val_loss: 4.0549 - val_acc: 0.0972\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0131 - acc: 0.0959 - val_loss: 4.0512 - val_acc: 0.0981\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0168 - acc: 0.0959 - val_loss: 4.0495 - val_acc: 0.0959\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9974 - acc: 0.0984 - val_loss: 4.0461 - val_acc: 0.0991\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0069 - acc: 0.0984 - val_loss: 4.0430 - val_acc: 0.0985\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0065 - acc: 0.0956 - val_loss: 4.0394 - val_acc: 0.1011\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0100 - acc: 0.0994 - val_loss: 4.0368 - val_acc: 0.1001\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0035 - acc: 0.1016 - val_loss: 4.0338 - val_acc: 0.0978\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9941 - acc: 0.1008 - val_loss: 4.0321 - val_acc: 0.1034\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9945 - acc: 0.0992 - val_loss: 4.0314 - val_acc: 0.0981\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9816 - acc: 0.1012 - val_loss: 4.0303 - val_acc: 0.1004\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9840 - acc: 0.1017 - val_loss: 4.0253 - val_acc: 0.1021\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9787 - acc: 0.1017 - val_loss: 4.0242 - val_acc: 0.1011\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9891 - acc: 0.0998 - val_loss: 4.0231 - val_acc: 0.1004\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9752 - acc: 0.1019 - val_loss: 4.0215 - val_acc: 0.1001\n",
      "Epoch 51/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9702 - acc: 0.1052 - val_loss: 4.0183 - val_acc: 0.1004\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9717 - acc: 0.1037 - val_loss: 4.0153 - val_acc: 0.1037\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9569 - acc: 0.1040 - val_loss: 4.0154 - val_acc: 0.0994\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9657 - acc: 0.1041 - val_loss: 4.0121 - val_acc: 0.1011\n",
      "Epoch 55/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9649 - acc: 0.1043 - val_loss: 4.0129 - val_acc: 0.1014\n",
      "Epoch 56/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9587 - acc: 0.1013 - val_loss: 4.0100 - val_acc: 0.1021\n",
      "Epoch 57/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9710 - acc: 0.1002 - val_loss: 4.0072 - val_acc: 0.1040\n",
      "Epoch 58/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9545 - acc: 0.1036 - val_loss: 4.0068 - val_acc: 0.1030\n",
      "Epoch 59/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9488 - acc: 0.1083 - val_loss: 4.0073 - val_acc: 0.1004\n",
      "Epoch 60/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9493 - acc: 0.1057 - val_loss: 4.0032 - val_acc: 0.1017\n",
      "Epoch 61/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9443 - acc: 0.1080 - val_loss: 4.0024 - val_acc: 0.1001\n",
      "Epoch 62/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9311 - acc: 0.1090 - val_loss: 4.0002 - val_acc: 0.1034\n",
      "Epoch 63/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9413 - acc: 0.1075 - val_loss: 3.9993 - val_acc: 0.1021\n",
      "Epoch 64/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 3.9473 - acc: 0.1013 - val_loss: 3.9973 - val_acc: 0.1021\n",
      "Epoch 65/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9313 - acc: 0.1058 - val_loss: 3.9976 - val_acc: 0.1043\n",
      "Epoch 66/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9406 - acc: 0.1057 - val_loss: 3.9968 - val_acc: 0.1037\n",
      "Epoch 67/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9334 - acc: 0.1083 - val_loss: 3.9919 - val_acc: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9175 - acc: 0.1113 - val_loss: 3.9921 - val_acc: 0.1050\n",
      "Epoch 69/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9260 - acc: 0.1115 - val_loss: 3.9945 - val_acc: 0.1056\n",
      "Epoch 70/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9296 - acc: 0.1061 - val_loss: 3.9900 - val_acc: 0.1030\n",
      "Epoch 71/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9317 - acc: 0.1108 - val_loss: 3.9892 - val_acc: 0.1040\n",
      "Epoch 72/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9233 - acc: 0.1093 - val_loss: 3.9900 - val_acc: 0.1034\n",
      "Epoch 73/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9257 - acc: 0.1160 - val_loss: 3.9867 - val_acc: 0.1053\n",
      "Epoch 74/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9162 - acc: 0.1104 - val_loss: 3.9840 - val_acc: 0.1063\n",
      "Epoch 75/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9263 - acc: 0.1108 - val_loss: 3.9835 - val_acc: 0.1063\n",
      "Epoch 76/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9265 - acc: 0.1093 - val_loss: 3.9816 - val_acc: 0.1050\n",
      "Epoch 77/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9247 - acc: 0.1152 - val_loss: 3.9823 - val_acc: 0.1053\n",
      "Epoch 78/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9105 - acc: 0.1097 - val_loss: 3.9842 - val_acc: 0.1040\n",
      "Epoch 79/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9054 - acc: 0.1119 - val_loss: 3.9808 - val_acc: 0.1056\n",
      "Epoch 80/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9140 - acc: 0.1101 - val_loss: 3.9787 - val_acc: 0.1076\n",
      "Epoch 81/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9132 - acc: 0.1086 - val_loss: 3.9776 - val_acc: 0.1073\n",
      "Epoch 82/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9131 - acc: 0.1125 - val_loss: 3.9780 - val_acc: 0.1073\n",
      "Epoch 83/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9109 - acc: 0.1111 - val_loss: 3.9780 - val_acc: 0.1060\n",
      "Epoch 84/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9166 - acc: 0.1108 - val_loss: 3.9762 - val_acc: 0.1076\n",
      "Epoch 85/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9074 - acc: 0.1138 - val_loss: 3.9757 - val_acc: 0.1069\n",
      "Epoch 86/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9143 - acc: 0.1103 - val_loss: 3.9743 - val_acc: 0.1053\n",
      "Epoch 87/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9077 - acc: 0.1083 - val_loss: 3.9740 - val_acc: 0.1066\n",
      "Epoch 88/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9105 - acc: 0.1121 - val_loss: 3.9733 - val_acc: 0.1073\n",
      "Epoch 89/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8984 - acc: 0.1121 - val_loss: 3.9743 - val_acc: 0.1060\n",
      "Epoch 90/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8906 - acc: 0.1178 - val_loss: 3.9732 - val_acc: 0.1040\n",
      "Epoch 00090: early stopping\n",
      "Test accuracy: 0.104010433656\n",
      "Creating model\n",
      "\n",
      "lr= 0.00338288754560423\n",
      "beta_1= 0.8786037317058711\n",
      "beta_2= 0.9997484269982735\n",
      "decay= 0.00288662535902546\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.8259 - acc: 0.0130 - val_loss: 4.7324 - val_acc: 0.0199\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6586 - acc: 0.0232 - val_loss: 4.5222 - val_acc: 0.0411\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4295 - acc: 0.0514 - val_loss: 4.3287 - val_acc: 0.0528\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2773 - acc: 0.0676 - val_loss: 4.1745 - val_acc: 0.0818\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1450 - acc: 0.0826 - val_loss: 4.0766 - val_acc: 0.0942\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0710 - acc: 0.0900 - val_loss: 4.0228 - val_acc: 0.0952\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9826 - acc: 0.1068 - val_loss: 3.9661 - val_acc: 0.1105\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9256 - acc: 0.1153 - val_loss: 3.9310 - val_acc: 0.1069\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8434 - acc: 0.1210 - val_loss: 3.9043 - val_acc: 0.1131\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8157 - acc: 0.1258 - val_loss: 3.8837 - val_acc: 0.1190\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7821 - acc: 0.1326 - val_loss: 3.8798 - val_acc: 0.1135\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7168 - acc: 0.1423 - val_loss: 3.8792 - val_acc: 0.1167\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6554 - acc: 0.1578 - val_loss: 3.8755 - val_acc: 0.1190\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6348 - acc: 0.1561 - val_loss: 3.8431 - val_acc: 0.1219\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6046 - acc: 0.1639 - val_loss: 3.8447 - val_acc: 0.1232\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5735 - acc: 0.1645 - val_loss: 3.8414 - val_acc: 0.1206\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5415 - acc: 0.1687 - val_loss: 3.8258 - val_acc: 0.1187\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4891 - acc: 0.1782 - val_loss: 3.8405 - val_acc: 0.1262\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4585 - acc: 0.1878 - val_loss: 3.8232 - val_acc: 0.1268\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4296 - acc: 0.1939 - val_loss: 3.8167 - val_acc: 0.1255\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3901 - acc: 0.1985 - val_loss: 3.8148 - val_acc: 0.1314\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3697 - acc: 0.2011 - val_loss: 3.8277 - val_acc: 0.1301\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3386 - acc: 0.2074 - val_loss: 3.8442 - val_acc: 0.1275\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3032 - acc: 0.2150 - val_loss: 3.8280 - val_acc: 0.1281\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2547 - acc: 0.2218 - val_loss: 3.8372 - val_acc: 0.1347\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2303 - acc: 0.2280 - val_loss: 3.8417 - val_acc: 0.1347\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2178 - acc: 0.2212 - val_loss: 3.8486 - val_acc: 0.1288\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1791 - acc: 0.2340 - val_loss: 3.8328 - val_acc: 0.1340\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1555 - acc: 0.2401 - val_loss: 3.8495 - val_acc: 0.1350\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1142 - acc: 0.2447 - val_loss: 3.8456 - val_acc: 0.1353\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0824 - acc: 0.2505 - val_loss: 3.8590 - val_acc: 0.1317\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0503 - acc: 0.2539 - val_loss: 3.8792 - val_acc: 0.1353\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0194 - acc: 0.2734 - val_loss: 3.8672 - val_acc: 0.1343\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0030 - acc: 0.2682 - val_loss: 3.8918 - val_acc: 0.1285\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.9573 - acc: 0.2730 - val_loss: 3.8963 - val_acc: 0.1304\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.9468 - acc: 0.2783 - val_loss: 3.9015 - val_acc: 0.1340\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.9384 - acc: 0.2839 - val_loss: 3.9115 - val_acc: 0.1402\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.8912 - acc: 0.2920 - val_loss: 3.9311 - val_acc: 0.1307\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.8895 - acc: 0.2867 - val_loss: 3.9397 - val_acc: 0.1317\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.8363 - acc: 0.3050 - val_loss: 3.9516 - val_acc: 0.1363\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.8253 - acc: 0.3041 - val_loss: 3.9559 - val_acc: 0.1314\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.8052 - acc: 0.3009 - val_loss: 3.9603 - val_acc: 0.1386\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.7619 - acc: 0.3149 - val_loss: 3.9581 - val_acc: 0.1337\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.7666 - acc: 0.3168 - val_loss: 3.9779 - val_acc: 0.1379\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.7402 - acc: 0.3220 - val_loss: 3.9770 - val_acc: 0.1317\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.7035 - acc: 0.3314 - val_loss: 3.9856 - val_acc: 0.1373\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.6890 - acc: 0.3252 - val_loss: 4.0132 - val_acc: 0.1356\n",
      "Epoch 00047: early stopping\n",
      "Test accuracy: 0.135637430719\n",
      "Creating model\n",
      "\n",
      "lr= 0.0002705372330877263\n",
      "beta_1= 0.9521587186332212\n",
      "beta_2= 0.9941224941073791\n",
      "decay= 0.0048444552373201185\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.8820 - acc: 0.0096 - val_loss: 4.7731 - val_acc: 0.0186\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7685 - acc: 0.0161 - val_loss: 4.7460 - val_acc: 0.0218\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7255 - acc: 0.0254 - val_loss: 4.7128 - val_acc: 0.0355\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6926 - acc: 0.0280 - val_loss: 4.6701 - val_acc: 0.0421\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6391 - acc: 0.0314 - val_loss: 4.6246 - val_acc: 0.0538\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5937 - acc: 0.0387 - val_loss: 4.5780 - val_acc: 0.0590\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5383 - acc: 0.0507 - val_loss: 4.5381 - val_acc: 0.0606\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4830 - acc: 0.0546 - val_loss: 4.4963 - val_acc: 0.0646\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4453 - acc: 0.0601 - val_loss: 4.4617 - val_acc: 0.0672\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3936 - acc: 0.0665 - val_loss: 4.4226 - val_acc: 0.0698\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3515 - acc: 0.0709 - val_loss: 4.3947 - val_acc: 0.0734\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3257 - acc: 0.0723 - val_loss: 4.3646 - val_acc: 0.0730\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2933 - acc: 0.0797 - val_loss: 4.3429 - val_acc: 0.0766\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2646 - acc: 0.0808 - val_loss: 4.3223 - val_acc: 0.0809\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2374 - acc: 0.0858 - val_loss: 4.2998 - val_acc: 0.0809\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2205 - acc: 0.0894 - val_loss: 4.2833 - val_acc: 0.0799\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1947 - acc: 0.0943 - val_loss: 4.2621 - val_acc: 0.0880\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1692 - acc: 0.0960 - val_loss: 4.2497 - val_acc: 0.0880\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1650 - acc: 0.0959 - val_loss: 4.2366 - val_acc: 0.0900\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1271 - acc: 0.0977 - val_loss: 4.2232 - val_acc: 0.0864\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1143 - acc: 0.1001 - val_loss: 4.2086 - val_acc: 0.0910\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1105 - acc: 0.1012 - val_loss: 4.2007 - val_acc: 0.0933\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0944 - acc: 0.1103 - val_loss: 4.1924 - val_acc: 0.0929\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0778 - acc: 0.1073 - val_loss: 4.1791 - val_acc: 0.0949\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0457 - acc: 0.1150 - val_loss: 4.1716 - val_acc: 0.0919\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0503 - acc: 0.1168 - val_loss: 4.1645 - val_acc: 0.0942\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0293 - acc: 0.1153 - val_loss: 4.1519 - val_acc: 0.0972\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0012 - acc: 0.1166 - val_loss: 4.1428 - val_acc: 0.0942\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.0063 - acc: 0.1094 - val_loss: 4.1384 - val_acc: 0.0959\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9924 - acc: 0.1185 - val_loss: 4.1303 - val_acc: 0.0981\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9790 - acc: 0.1195 - val_loss: 4.1242 - val_acc: 0.0994\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9730 - acc: 0.1209 - val_loss: 4.1157 - val_acc: 0.0985\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9524 - acc: 0.1342 - val_loss: 4.1097 - val_acc: 0.1007\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9480 - acc: 0.1254 - val_loss: 4.1041 - val_acc: 0.0972\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9336 - acc: 0.1263 - val_loss: 4.0976 - val_acc: 0.0988\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9331 - acc: 0.1270 - val_loss: 4.0920 - val_acc: 0.0978\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9209 - acc: 0.1283 - val_loss: 4.0855 - val_acc: 0.1011\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9097 - acc: 0.1398 - val_loss: 4.0812 - val_acc: 0.1017\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9127 - acc: 0.1340 - val_loss: 4.0758 - val_acc: 0.1011\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8955 - acc: 0.1358 - val_loss: 4.0731 - val_acc: 0.1007\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.9005 - acc: 0.1312 - val_loss: 4.0689 - val_acc: 0.1024\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8900 - acc: 0.1282 - val_loss: 4.0642 - val_acc: 0.1011\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8888 - acc: 0.1332 - val_loss: 4.0592 - val_acc: 0.1034\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8631 - acc: 0.1377 - val_loss: 4.0552 - val_acc: 0.1030\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8597 - acc: 0.1395 - val_loss: 4.0514 - val_acc: 0.1017\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8626 - acc: 0.1370 - val_loss: 4.0468 - val_acc: 0.1030\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8629 - acc: 0.1393 - val_loss: 4.0442 - val_acc: 0.1037\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8546 - acc: 0.1374 - val_loss: 4.0391 - val_acc: 0.1056\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8340 - acc: 0.1370 - val_loss: 4.0374 - val_acc: 0.1037\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8400 - acc: 0.1426 - val_loss: 4.0338 - val_acc: 0.1037\n",
      "Epoch 51/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8334 - acc: 0.1370 - val_loss: 4.0303 - val_acc: 0.1050\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8279 - acc: 0.1461 - val_loss: 4.0287 - val_acc: 0.1086\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8427 - acc: 0.1400 - val_loss: 4.0253 - val_acc: 0.1092\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8105 - acc: 0.1488 - val_loss: 4.0232 - val_acc: 0.1092\n",
      "Epoch 55/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8276 - acc: 0.1406 - val_loss: 4.0185 - val_acc: 0.1082\n",
      "Epoch 56/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7974 - acc: 0.1493 - val_loss: 4.0179 - val_acc: 0.1076\n",
      "Epoch 57/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7869 - acc: 0.1444 - val_loss: 4.0151 - val_acc: 0.1089\n",
      "Epoch 58/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7952 - acc: 0.1486 - val_loss: 4.0129 - val_acc: 0.1089\n",
      "Epoch 59/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.8006 - acc: 0.1502 - val_loss: 4.0058 - val_acc: 0.1112\n",
      "Epoch 60/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7713 - acc: 0.1501 - val_loss: 4.0084 - val_acc: 0.1115\n",
      "Epoch 61/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7869 - acc: 0.1501 - val_loss: 4.0026 - val_acc: 0.1112\n",
      "Epoch 62/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7878 - acc: 0.1477 - val_loss: 4.0026 - val_acc: 0.1141\n",
      "Epoch 63/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7746 - acc: 0.1528 - val_loss: 3.9985 - val_acc: 0.1148\n",
      "Epoch 64/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7725 - acc: 0.1554 - val_loss: 3.9966 - val_acc: 0.1122\n",
      "Epoch 65/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7535 - acc: 0.1600 - val_loss: 3.9945 - val_acc: 0.1125\n",
      "Epoch 66/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7675 - acc: 0.1504 - val_loss: 3.9922 - val_acc: 0.1144\n",
      "Epoch 67/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7744 - acc: 0.1498 - val_loss: 3.9900 - val_acc: 0.1141\n",
      "Epoch 68/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7573 - acc: 0.1461 - val_loss: 3.9872 - val_acc: 0.1148\n",
      "Epoch 69/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7438 - acc: 0.1574 - val_loss: 3.9858 - val_acc: 0.1157\n",
      "Epoch 70/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 3.7440 - acc: 0.1547 - val_loss: 3.9854 - val_acc: 0.1148\n",
      "Epoch 71/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7477 - acc: 0.1514 - val_loss: 3.9827 - val_acc: 0.1161\n",
      "Epoch 72/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7455 - acc: 0.1560 - val_loss: 3.9810 - val_acc: 0.1154\n",
      "Epoch 73/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7363 - acc: 0.1515 - val_loss: 3.9785 - val_acc: 0.1171\n",
      "Epoch 74/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 3.7405 - acc: 0.1592 - val_loss: 3.9775 - val_acc: 0.1157\n",
      "Epoch 75/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7346 - acc: 0.1585 - val_loss: 3.9750 - val_acc: 0.1151\n",
      "Epoch 76/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7180 - acc: 0.1618 - val_loss: 3.9740 - val_acc: 0.1161\n",
      "Epoch 77/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7164 - acc: 0.1597 - val_loss: 3.9715 - val_acc: 0.1200\n",
      "Epoch 78/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7271 - acc: 0.1578 - val_loss: 3.9700 - val_acc: 0.1177\n",
      "Epoch 79/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7346 - acc: 0.1595 - val_loss: 3.9685 - val_acc: 0.1171\n",
      "Epoch 80/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7052 - acc: 0.1595 - val_loss: 3.9670 - val_acc: 0.1154\n",
      "Epoch 81/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7167 - acc: 0.1581 - val_loss: 3.9663 - val_acc: 0.1171\n",
      "Epoch 82/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7248 - acc: 0.1639 - val_loss: 3.9641 - val_acc: 0.1193\n",
      "Epoch 83/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7013 - acc: 0.1627 - val_loss: 3.9645 - val_acc: 0.1177\n",
      "Epoch 84/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6866 - acc: 0.1655 - val_loss: 3.9634 - val_acc: 0.1190\n",
      "Epoch 85/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6885 - acc: 0.1616 - val_loss: 3.9624 - val_acc: 0.1203\n",
      "Epoch 86/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6936 - acc: 0.1597 - val_loss: 3.9611 - val_acc: 0.1210\n",
      "Epoch 87/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6891 - acc: 0.1662 - val_loss: 3.9595 - val_acc: 0.1203\n",
      "Epoch 88/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6942 - acc: 0.1712 - val_loss: 3.9584 - val_acc: 0.1210\n",
      "Epoch 89/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6846 - acc: 0.1642 - val_loss: 3.9555 - val_acc: 0.1223\n",
      "Epoch 90/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6771 - acc: 0.1635 - val_loss: 3.9558 - val_acc: 0.1223\n",
      "Epoch 91/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7031 - acc: 0.1567 - val_loss: 3.9547 - val_acc: 0.1203\n",
      "Epoch 92/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6795 - acc: 0.1623 - val_loss: 3.9520 - val_acc: 0.1226\n",
      "Epoch 93/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6796 - acc: 0.1658 - val_loss: 3.9530 - val_acc: 0.1219\n",
      "Epoch 94/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6709 - acc: 0.1646 - val_loss: 3.9519 - val_acc: 0.1219\n",
      "Epoch 95/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6684 - acc: 0.1663 - val_loss: 3.9520 - val_acc: 0.1210\n",
      "Epoch 96/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6782 - acc: 0.1681 - val_loss: 3.9489 - val_acc: 0.1246\n",
      "Epoch 97/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6756 - acc: 0.1658 - val_loss: 3.9486 - val_acc: 0.1242\n",
      "Epoch 98/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6746 - acc: 0.1686 - val_loss: 3.9469 - val_acc: 0.1239\n",
      "Epoch 99/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6754 - acc: 0.1684 - val_loss: 3.9452 - val_acc: 0.1232\n",
      "Epoch 100/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6534 - acc: 0.1701 - val_loss: 3.9438 - val_acc: 0.1223\n",
      "Test accuracy: 0.122269318557\n",
      "Creating model\n",
      "\n",
      "lr= 0.008714428754919309\n",
      "beta_1= 0.9169337389365839\n",
      "beta_2= 0.9937426036916324\n",
      "decay= 0.005838315653286106\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.9745 - acc: 0.0112 - val_loss: 4.7580 - val_acc: 0.0127\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7072 - acc: 0.0200 - val_loss: 4.6123 - val_acc: 0.0280\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5743 - acc: 0.0314 - val_loss: 4.5056 - val_acc: 0.0401\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4864 - acc: 0.0362 - val_loss: 4.4417 - val_acc: 0.0453\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4292 - acc: 0.0423 - val_loss: 4.3921 - val_acc: 0.0456\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3955 - acc: 0.0443 - val_loss: 4.3741 - val_acc: 0.0470\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3497 - acc: 0.0519 - val_loss: 4.3362 - val_acc: 0.0528\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3339 - acc: 0.0485 - val_loss: 4.3223 - val_acc: 0.0525\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2970 - acc: 0.0544 - val_loss: 4.3081 - val_acc: 0.0528\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2891 - acc: 0.0573 - val_loss: 4.2748 - val_acc: 0.0531\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2503 - acc: 0.0594 - val_loss: 4.2612 - val_acc: 0.0558\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2296 - acc: 0.0668 - val_loss: 4.2342 - val_acc: 0.0675\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1934 - acc: 0.0713 - val_loss: 4.2230 - val_acc: 0.0675\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1702 - acc: 0.0746 - val_loss: 4.1921 - val_acc: 0.0721\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1472 - acc: 0.0791 - val_loss: 4.1733 - val_acc: 0.0750\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1235 - acc: 0.0763 - val_loss: 4.1484 - val_acc: 0.0743\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0993 - acc: 0.0830 - val_loss: 4.1287 - val_acc: 0.0760\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0857 - acc: 0.0869 - val_loss: 4.1197 - val_acc: 0.0786\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0768 - acc: 0.0841 - val_loss: 4.1119 - val_acc: 0.0825\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0576 - acc: 0.0893 - val_loss: 4.1023 - val_acc: 0.0835\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0352 - acc: 0.0928 - val_loss: 4.0840 - val_acc: 0.0864\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0175 - acc: 0.0917 - val_loss: 4.0725 - val_acc: 0.0864\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9975 - acc: 0.0927 - val_loss: 4.0641 - val_acc: 0.0884\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9926 - acc: 0.0950 - val_loss: 4.0592 - val_acc: 0.0874\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9893 - acc: 0.0936 - val_loss: 4.0551 - val_acc: 0.0884\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9716 - acc: 0.0966 - val_loss: 4.0380 - val_acc: 0.0933\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9557 - acc: 0.1040 - val_loss: 4.0343 - val_acc: 0.0955\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9339 - acc: 0.1075 - val_loss: 4.0270 - val_acc: 0.0946\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9314 - acc: 0.1078 - val_loss: 4.0258 - val_acc: 0.0962\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9423 - acc: 0.1016 - val_loss: 4.0192 - val_acc: 0.0965\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9115 - acc: 0.1069 - val_loss: 4.0144 - val_acc: 0.0978\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9098 - acc: 0.1045 - val_loss: 4.0139 - val_acc: 0.0978\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8944 - acc: 0.1066 - val_loss: 4.0051 - val_acc: 0.0962\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9009 - acc: 0.1125 - val_loss: 4.0026 - val_acc: 0.0952\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8921 - acc: 0.1126 - val_loss: 4.0027 - val_acc: 0.0975\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8782 - acc: 0.1166 - val_loss: 3.9937 - val_acc: 0.1007\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8461 - acc: 0.1171 - val_loss: 3.9848 - val_acc: 0.1004\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8549 - acc: 0.1154 - val_loss: 3.9888 - val_acc: 0.1017\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8400 - acc: 0.1235 - val_loss: 3.9849 - val_acc: 0.1004\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8491 - acc: 0.1188 - val_loss: 3.9824 - val_acc: 0.0962\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8297 - acc: 0.1209 - val_loss: 3.9753 - val_acc: 0.1017\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8451 - acc: 0.1220 - val_loss: 3.9823 - val_acc: 0.1021\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8197 - acc: 0.1194 - val_loss: 3.9742 - val_acc: 0.1024\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8197 - acc: 0.1251 - val_loss: 3.9646 - val_acc: 0.1050\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8210 - acc: 0.1233 - val_loss: 3.9679 - val_acc: 0.1014\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8020 - acc: 0.1224 - val_loss: 3.9705 - val_acc: 0.1034\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7966 - acc: 0.1245 - val_loss: 3.9662 - val_acc: 0.1050\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7927 - acc: 0.1231 - val_loss: 3.9617 - val_acc: 0.1021\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7824 - acc: 0.1294 - val_loss: 3.9599 - val_acc: 0.1037\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7837 - acc: 0.1310 - val_loss: 3.9590 - val_acc: 0.1024\n",
      "Epoch 51/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7857 - acc: 0.1229 - val_loss: 3.9537 - val_acc: 0.1040\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7695 - acc: 0.1315 - val_loss: 3.9517 - val_acc: 0.1037\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7691 - acc: 0.1294 - val_loss: 3.9518 - val_acc: 0.1024\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7404 - acc: 0.1374 - val_loss: 3.9485 - val_acc: 0.1034\n",
      "Epoch 00054: early stopping\n",
      "Test accuracy: 0.103358330621\n",
      "Creating model\n",
      "\n",
      "lr= 0.004259280928619306\n",
      "beta_1= 0.9944790680299204\n",
      "beta_2= 0.9968768098139091\n",
      "decay= 0.0052789979236449605\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.8424 - acc: 0.0096 - val_loss: 4.7787 - val_acc: 0.0085\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7671 - acc: 0.0137 - val_loss: 4.7483 - val_acc: 0.0163\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7257 - acc: 0.0198 - val_loss: 4.7081 - val_acc: 0.0199\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6844 - acc: 0.0224 - val_loss: 4.6581 - val_acc: 0.0264\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6347 - acc: 0.0253 - val_loss: 4.6130 - val_acc: 0.0313\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6105 - acc: 0.0296 - val_loss: 4.5885 - val_acc: 0.0326\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5616 - acc: 0.0328 - val_loss: 4.5490 - val_acc: 0.0404\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5454 - acc: 0.0319 - val_loss: 4.5241 - val_acc: 0.0447\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5196 - acc: 0.0380 - val_loss: 4.5137 - val_acc: 0.0443\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4940 - acc: 0.0393 - val_loss: 4.4761 - val_acc: 0.0476\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4766 - acc: 0.0407 - val_loss: 4.4654 - val_acc: 0.0473\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4555 - acc: 0.0433 - val_loss: 4.4410 - val_acc: 0.0496\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4316 - acc: 0.0443 - val_loss: 4.4323 - val_acc: 0.0518\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4227 - acc: 0.0426 - val_loss: 4.4074 - val_acc: 0.0515\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4173 - acc: 0.0430 - val_loss: 4.4043 - val_acc: 0.0525\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4029 - acc: 0.0499 - val_loss: 4.4154 - val_acc: 0.0496\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3945 - acc: 0.0465 - val_loss: 4.3790 - val_acc: 0.0580\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3773 - acc: 0.0484 - val_loss: 4.3761 - val_acc: 0.0548\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3747 - acc: 0.0558 - val_loss: 4.3774 - val_acc: 0.0512\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3559 - acc: 0.0495 - val_loss: 4.3508 - val_acc: 0.0597\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3518 - acc: 0.0507 - val_loss: 4.3537 - val_acc: 0.0551\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3499 - acc: 0.0513 - val_loss: 4.3429 - val_acc: 0.0558\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3366 - acc: 0.0523 - val_loss: 4.3333 - val_acc: 0.0580\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3292 - acc: 0.0519 - val_loss: 4.3339 - val_acc: 0.0574\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3240 - acc: 0.0560 - val_loss: 4.3215 - val_acc: 0.0613\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3113 - acc: 0.0541 - val_loss: 4.3170 - val_acc: 0.0619\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3208 - acc: 0.0534 - val_loss: 4.3173 - val_acc: 0.0610\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3031 - acc: 0.0570 - val_loss: 4.3076 - val_acc: 0.0629\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2984 - acc: 0.0528 - val_loss: 4.3111 - val_acc: 0.0623\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2928 - acc: 0.0569 - val_loss: 4.2997 - val_acc: 0.0613\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2913 - acc: 0.0563 - val_loss: 4.2988 - val_acc: 0.0623\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2831 - acc: 0.0574 - val_loss: 4.2938 - val_acc: 0.0616\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2907 - acc: 0.0576 - val_loss: 4.2921 - val_acc: 0.0629\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2790 - acc: 0.0614 - val_loss: 4.2892 - val_acc: 0.0584\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2760 - acc: 0.0553 - val_loss: 4.2853 - val_acc: 0.0593\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2614 - acc: 0.0608 - val_loss: 4.2767 - val_acc: 0.0600\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2496 - acc: 0.0595 - val_loss: 4.2764 - val_acc: 0.0606\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2639 - acc: 0.0608 - val_loss: 4.2723 - val_acc: 0.0600\n",
      "Epoch 00038: early stopping\n",
      "Test accuracy: 0.0599934789721\n",
      "Creating model\n",
      "\n",
      "lr= 0.004652194730669497\n",
      "beta_1= 0.9079060125436689\n",
      "beta_2= 0.9933318042214533\n",
      "decay= 0.0010530729142803252\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.8585 - acc: 0.0092 - val_loss: 4.7816 - val_acc: 0.0108\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7382 - acc: 0.0165 - val_loss: 4.6652 - val_acc: 0.0205\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6013 - acc: 0.0330 - val_loss: 4.4949 - val_acc: 0.0362\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4576 - acc: 0.0433 - val_loss: 4.3459 - val_acc: 0.0525\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3068 - acc: 0.0576 - val_loss: 4.2342 - val_acc: 0.0675\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2330 - acc: 0.0669 - val_loss: 4.1492 - val_acc: 0.0776\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1467 - acc: 0.0778 - val_loss: 4.0966 - val_acc: 0.0871\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0900 - acc: 0.0858 - val_loss: 4.0864 - val_acc: 0.0942\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0216 - acc: 0.0918 - val_loss: 4.0247 - val_acc: 0.0994\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9957 - acc: 0.0922 - val_loss: 4.0143 - val_acc: 0.0933\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9217 - acc: 0.1051 - val_loss: 3.9556 - val_acc: 0.1056\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9019 - acc: 0.1107 - val_loss: 3.9805 - val_acc: 0.1118\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8500 - acc: 0.1202 - val_loss: 3.9406 - val_acc: 0.1118\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7985 - acc: 0.1259 - val_loss: 3.9485 - val_acc: 0.1105\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7746 - acc: 0.1289 - val_loss: 3.9318 - val_acc: 0.1128\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7509 - acc: 0.1340 - val_loss: 3.9278 - val_acc: 0.1079\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7195 - acc: 0.1321 - val_loss: 3.9165 - val_acc: 0.1144\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6963 - acc: 0.1379 - val_loss: 3.9234 - val_acc: 0.1203\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6764 - acc: 0.1426 - val_loss: 3.9049 - val_acc: 0.1216\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6418 - acc: 0.1543 - val_loss: 3.9152 - val_acc: 0.1161\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6157 - acc: 0.1484 - val_loss: 3.9142 - val_acc: 0.1206\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5942 - acc: 0.1525 - val_loss: 3.9199 - val_acc: 0.1216\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5742 - acc: 0.1644 - val_loss: 3.9266 - val_acc: 0.1154\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5201 - acc: 0.1630 - val_loss: 3.9288 - val_acc: 0.1219\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5133 - acc: 0.1744 - val_loss: 3.9167 - val_acc: 0.1239\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4878 - acc: 0.1655 - val_loss: 3.9205 - val_acc: 0.1246\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4526 - acc: 0.1843 - val_loss: 3.9423 - val_acc: 0.1174\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4307 - acc: 0.1814 - val_loss: 3.9393 - val_acc: 0.1131\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4148 - acc: 0.1810 - val_loss: 3.9511 - val_acc: 0.1223\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4024 - acc: 0.1859 - val_loss: 3.9553 - val_acc: 0.1236\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3677 - acc: 0.1965 - val_loss: 3.9576 - val_acc: 0.1125\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3420 - acc: 0.1989 - val_loss: 3.9639 - val_acc: 0.1174\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2940 - acc: 0.2088 - val_loss: 3.9924 - val_acc: 0.1216\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2814 - acc: 0.2067 - val_loss: 3.9869 - val_acc: 0.1210\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2807 - acc: 0.2122 - val_loss: 3.9838 - val_acc: 0.1226\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2506 - acc: 0.2165 - val_loss: 4.0191 - val_acc: 0.1148\n",
      "Epoch 00036: early stopping\n",
      "Test accuracy: 0.114770133681\n",
      "Creating model\n",
      "\n",
      "lr= 0.00020389590556056983\n",
      "beta_1= 0.9453158868247398\n",
      "beta_2= 0.9925872692991417\n",
      "decay= 0.000821336141287018\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.8784 - acc: 0.0131 - val_loss: 4.7543 - val_acc: 0.0173\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7717 - acc: 0.0175 - val_loss: 4.7246 - val_acc: 0.0303\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6999 - acc: 0.0254 - val_loss: 4.6656 - val_acc: 0.0368\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.6277 - acc: 0.0372 - val_loss: 4.5716 - val_acc: 0.0515\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5316 - acc: 0.0495 - val_loss: 4.4827 - val_acc: 0.0633\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4076 - acc: 0.0586 - val_loss: 4.3887 - val_acc: 0.0675\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3018 - acc: 0.0678 - val_loss: 4.3354 - val_acc: 0.0763\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2334 - acc: 0.0820 - val_loss: 4.2560 - val_acc: 0.0796\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1447 - acc: 0.0929 - val_loss: 4.1968 - val_acc: 0.0962\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0870 - acc: 0.1037 - val_loss: 4.1463 - val_acc: 0.1056\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0373 - acc: 0.1065 - val_loss: 4.1101 - val_acc: 0.0968\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9842 - acc: 0.1168 - val_loss: 4.0764 - val_acc: 0.1037\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9209 - acc: 0.1201 - val_loss: 4.0508 - val_acc: 0.1079\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8843 - acc: 0.1311 - val_loss: 4.0206 - val_acc: 0.1092\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8211 - acc: 0.1347 - val_loss: 3.9888 - val_acc: 0.1167\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7882 - acc: 0.1402 - val_loss: 3.9748 - val_acc: 0.1193\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7552 - acc: 0.1455 - val_loss: 3.9675 - val_acc: 0.1249\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7315 - acc: 0.1440 - val_loss: 3.9583 - val_acc: 0.1167\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6994 - acc: 0.1606 - val_loss: 3.9415 - val_acc: 0.1268\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6581 - acc: 0.1677 - val_loss: 3.9291 - val_acc: 0.1226\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6346 - acc: 0.1646 - val_loss: 3.9181 - val_acc: 0.1275\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6260 - acc: 0.1679 - val_loss: 3.9146 - val_acc: 0.1343\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5980 - acc: 0.1754 - val_loss: 3.8978 - val_acc: 0.1356\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5844 - acc: 0.1753 - val_loss: 3.8965 - val_acc: 0.1373\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5238 - acc: 0.1870 - val_loss: 3.8924 - val_acc: 0.1330\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5208 - acc: 0.1911 - val_loss: 3.8861 - val_acc: 0.1330\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5121 - acc: 0.1891 - val_loss: 3.8888 - val_acc: 0.1360\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4891 - acc: 0.1925 - val_loss: 3.8794 - val_acc: 0.1382\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4625 - acc: 0.2003 - val_loss: 3.8767 - val_acc: 0.1317\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4652 - acc: 0.1906 - val_loss: 3.8603 - val_acc: 0.1389\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4302 - acc: 0.2022 - val_loss: 3.8756 - val_acc: 0.1330\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3981 - acc: 0.2098 - val_loss: 3.8620 - val_acc: 0.1396\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4016 - acc: 0.2084 - val_loss: 3.8564 - val_acc: 0.1366\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4013 - acc: 0.2063 - val_loss: 3.8555 - val_acc: 0.1379\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3695 - acc: 0.2152 - val_loss: 3.8478 - val_acc: 0.1396\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3557 - acc: 0.2141 - val_loss: 3.8478 - val_acc: 0.1376\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3392 - acc: 0.2217 - val_loss: 3.8548 - val_acc: 0.1412\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3266 - acc: 0.2252 - val_loss: 3.8379 - val_acc: 0.1444\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3303 - acc: 0.2207 - val_loss: 3.8440 - val_acc: 0.1409\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3131 - acc: 0.2267 - val_loss: 3.8483 - val_acc: 0.1428\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2916 - acc: 0.2285 - val_loss: 3.8398 - val_acc: 0.1392\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2725 - acc: 0.2282 - val_loss: 3.8354 - val_acc: 0.1363\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2751 - acc: 0.2317 - val_loss: 3.8352 - val_acc: 0.1415\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2673 - acc: 0.2266 - val_loss: 3.8238 - val_acc: 0.1457\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2434 - acc: 0.2337 - val_loss: 3.8371 - val_acc: 0.1379\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2286 - acc: 0.2382 - val_loss: 3.8204 - val_acc: 0.1457\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2246 - acc: 0.2370 - val_loss: 3.8275 - val_acc: 0.1392\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2194 - acc: 0.2443 - val_loss: 3.8315 - val_acc: 0.1422\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2025 - acc: 0.2491 - val_loss: 3.8261 - val_acc: 0.1422\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2027 - acc: 0.2461 - val_loss: 3.8291 - val_acc: 0.1412\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1780 - acc: 0.2472 - val_loss: 3.8163 - val_acc: 0.1451\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1959 - acc: 0.2492 - val_loss: 3.8134 - val_acc: 0.1480\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1547 - acc: 0.2537 - val_loss: 3.8215 - val_acc: 0.1510\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1686 - acc: 0.2474 - val_loss: 3.8152 - val_acc: 0.1415\n",
      "Epoch 55/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1510 - acc: 0.2549 - val_loss: 3.8240 - val_acc: 0.1405\n",
      "Epoch 56/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1415 - acc: 0.2457 - val_loss: 3.8194 - val_acc: 0.1519\n",
      "Epoch 57/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1378 - acc: 0.2570 - val_loss: 3.8179 - val_acc: 0.1402\n",
      "Epoch 58/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1370 - acc: 0.2552 - val_loss: 3.8156 - val_acc: 0.1454\n",
      "Epoch 59/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1089 - acc: 0.2598 - val_loss: 3.8091 - val_acc: 0.1444\n",
      "Epoch 60/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0950 - acc: 0.2728 - val_loss: 3.8109 - val_acc: 0.1454\n",
      "Epoch 61/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1036 - acc: 0.2623 - val_loss: 3.8162 - val_acc: 0.1428\n",
      "Epoch 62/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0925 - acc: 0.2628 - val_loss: 3.8066 - val_acc: 0.1470\n",
      "Epoch 63/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0813 - acc: 0.2648 - val_loss: 3.8168 - val_acc: 0.1497\n",
      "Epoch 64/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0676 - acc: 0.2679 - val_loss: 3.8193 - val_acc: 0.1484\n",
      "Epoch 65/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0668 - acc: 0.2774 - val_loss: 3.8236 - val_acc: 0.1425\n",
      "Epoch 66/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0766 - acc: 0.2716 - val_loss: 3.8086 - val_acc: 0.1451\n",
      "Epoch 00066: early stopping\n",
      "Test accuracy: 0.145092924685\n",
      "Creating model\n",
      "\n",
      "lr= 0.002264940611834032\n",
      "beta_1= 0.9245240717380647\n",
      "beta_2= 0.9944331087756243\n",
      "decay= 0.009085024575574235\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.8431 - acc: 0.0101 - val_loss: 4.7674 - val_acc: 0.0153\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7214 - acc: 0.0236 - val_loss: 4.6650 - val_acc: 0.0264\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5953 - acc: 0.0354 - val_loss: 4.5289 - val_acc: 0.0417\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.4538 - acc: 0.0512 - val_loss: 4.3993 - val_acc: 0.0616\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3276 - acc: 0.0683 - val_loss: 4.2981 - val_acc: 0.0616\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2316 - acc: 0.0822 - val_loss: 4.2081 - val_acc: 0.0763\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1641 - acc: 0.0900 - val_loss: 4.1585 - val_acc: 0.0792\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0909 - acc: 0.0910 - val_loss: 4.1183 - val_acc: 0.0887\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0439 - acc: 0.1029 - val_loss: 4.1016 - val_acc: 0.0884\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0104 - acc: 0.1044 - val_loss: 4.0528 - val_acc: 0.0972\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9668 - acc: 0.1122 - val_loss: 4.0246 - val_acc: 0.0939\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9432 - acc: 0.1132 - val_loss: 4.0100 - val_acc: 0.1017\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9097 - acc: 0.1215 - val_loss: 4.0025 - val_acc: 0.1047\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8816 - acc: 0.1231 - val_loss: 3.9846 - val_acc: 0.1034\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8682 - acc: 0.1276 - val_loss: 3.9760 - val_acc: 0.1037\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8540 - acc: 0.1290 - val_loss: 3.9618 - val_acc: 0.1086\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8249 - acc: 0.1314 - val_loss: 3.9478 - val_acc: 0.1144\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8134 - acc: 0.1353 - val_loss: 3.9438 - val_acc: 0.1089\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7875 - acc: 0.1452 - val_loss: 3.9350 - val_acc: 0.1102\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7704 - acc: 0.1375 - val_loss: 3.9249 - val_acc: 0.1180\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7595 - acc: 0.1484 - val_loss: 3.9182 - val_acc: 0.1138\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7501 - acc: 0.1434 - val_loss: 3.9271 - val_acc: 0.1144\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7417 - acc: 0.1433 - val_loss: 3.9176 - val_acc: 0.1197\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7297 - acc: 0.1532 - val_loss: 3.9077 - val_acc: 0.1213\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7220 - acc: 0.1491 - val_loss: 3.9053 - val_acc: 0.1187\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7038 - acc: 0.1525 - val_loss: 3.8918 - val_acc: 0.1242\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6965 - acc: 0.1614 - val_loss: 3.8943 - val_acc: 0.1232\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6983 - acc: 0.1525 - val_loss: 3.8908 - val_acc: 0.1268\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6801 - acc: 0.1579 - val_loss: 3.8888 - val_acc: 0.1291\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6864 - acc: 0.1537 - val_loss: 3.8780 - val_acc: 0.1298\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6675 - acc: 0.1621 - val_loss: 3.8829 - val_acc: 0.1275\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6625 - acc: 0.1586 - val_loss: 3.8743 - val_acc: 0.1275\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6514 - acc: 0.1630 - val_loss: 3.8775 - val_acc: 0.1252\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6415 - acc: 0.1732 - val_loss: 3.8688 - val_acc: 0.1239\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6533 - acc: 0.1669 - val_loss: 3.8670 - val_acc: 0.1288\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6154 - acc: 0.1693 - val_loss: 3.8666 - val_acc: 0.1265\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6223 - acc: 0.1726 - val_loss: 3.8623 - val_acc: 0.1259\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6294 - acc: 0.1674 - val_loss: 3.8649 - val_acc: 0.1268\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6153 - acc: 0.1732 - val_loss: 3.8637 - val_acc: 0.1268\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5988 - acc: 0.1733 - val_loss: 3.8599 - val_acc: 0.1278\n",
      "Epoch 00040: early stopping\n",
      "Test accuracy: 0.127812194327\n",
      "Creating model\n",
      "\n",
      "lr= 0.005666213002620087\n",
      "beta_1= 0.8824580373106985\n",
      "beta_2= 0.9909216748347716\n",
      "decay= 0.0020942239619394943\n",
      "\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7155/7155 [==============================] - 28s 4ms/step - loss: 4.8732 - acc: 0.0103 - val_loss: 4.7668 - val_acc: 0.0121\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.7258 - acc: 0.0179 - val_loss: 4.6131 - val_acc: 0.0241\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.5386 - acc: 0.0340 - val_loss: 4.4195 - val_acc: 0.0515\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.3667 - acc: 0.0488 - val_loss: 4.2430 - val_acc: 0.0672\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2516 - acc: 0.0623 - val_loss: 4.1499 - val_acc: 0.0779\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1857 - acc: 0.0679 - val_loss: 4.1059 - val_acc: 0.0825\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.1148 - acc: 0.0804 - val_loss: 4.0527 - val_acc: 0.0871\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0721 - acc: 0.0823 - val_loss: 4.0500 - val_acc: 0.0887\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.0344 - acc: 0.0932 - val_loss: 4.0136 - val_acc: 0.0936\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9795 - acc: 0.0946 - val_loss: 3.9864 - val_acc: 0.0968\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.9354 - acc: 0.1033 - val_loss: 3.9537 - val_acc: 0.1073\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8931 - acc: 0.1122 - val_loss: 3.9414 - val_acc: 0.1131\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8453 - acc: 0.1212 - val_loss: 3.9304 - val_acc: 0.1099\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8185 - acc: 0.1227 - val_loss: 3.9385 - val_acc: 0.1109\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7729 - acc: 0.1234 - val_loss: 3.9342 - val_acc: 0.1076\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7612 - acc: 0.1312 - val_loss: 3.9200 - val_acc: 0.1154\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.7451 - acc: 0.1294 - val_loss: 3.9183 - val_acc: 0.1167\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6894 - acc: 0.1438 - val_loss: 3.9145 - val_acc: 0.1112\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6709 - acc: 0.1469 - val_loss: 3.9113 - val_acc: 0.1226\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6420 - acc: 0.1518 - val_loss: 3.9086 - val_acc: 0.1246\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6451 - acc: 0.1458 - val_loss: 3.9148 - val_acc: 0.1206\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.6080 - acc: 0.1530 - val_loss: 3.9053 - val_acc: 0.1180\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5651 - acc: 0.1593 - val_loss: 3.9083 - val_acc: 0.1203\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5315 - acc: 0.1644 - val_loss: 3.9090 - val_acc: 0.1259\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5227 - acc: 0.1674 - val_loss: 3.9100 - val_acc: 0.1219\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5127 - acc: 0.1711 - val_loss: 3.9124 - val_acc: 0.1259\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4613 - acc: 0.1790 - val_loss: 3.9323 - val_acc: 0.1216\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4482 - acc: 0.1737 - val_loss: 3.9250 - val_acc: 0.1259\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4365 - acc: 0.1850 - val_loss: 3.9327 - val_acc: 0.1249\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4459 - acc: 0.1789 - val_loss: 3.9306 - val_acc: 0.1210\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.4233 - acc: 0.1811 - val_loss: 3.9374 - val_acc: 0.1236\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3688 - acc: 0.1947 - val_loss: 3.9384 - val_acc: 0.1278\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3607 - acc: 0.2035 - val_loss: 3.9450 - val_acc: 0.1278\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3584 - acc: 0.1932 - val_loss: 3.9453 - val_acc: 0.1239\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3232 - acc: 0.1999 - val_loss: 3.9609 - val_acc: 0.1216\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3086 - acc: 0.2041 - val_loss: 3.9554 - val_acc: 0.1252\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.3016 - acc: 0.2068 - val_loss: 3.9594 - val_acc: 0.1285\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2542 - acc: 0.2123 - val_loss: 3.9556 - val_acc: 0.1301\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2742 - acc: 0.2120 - val_loss: 3.9829 - val_acc: 0.1311\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2649 - acc: 0.2119 - val_loss: 3.9638 - val_acc: 0.1288\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2353 - acc: 0.2259 - val_loss: 3.9984 - val_acc: 0.1242\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2175 - acc: 0.2211 - val_loss: 3.9875 - val_acc: 0.1314\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1954 - acc: 0.2239 - val_loss: 3.9923 - val_acc: 0.1288\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.2034 - acc: 0.2281 - val_loss: 4.0087 - val_acc: 0.1294\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1937 - acc: 0.2268 - val_loss: 4.0177 - val_acc: 0.1232\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1547 - acc: 0.2320 - val_loss: 4.0333 - val_acc: 0.1184\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1522 - acc: 0.2321 - val_loss: 4.0202 - val_acc: 0.1262\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1419 - acc: 0.2299 - val_loss: 4.0256 - val_acc: 0.1356\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1146 - acc: 0.2384 - val_loss: 4.0337 - val_acc: 0.1307\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.1209 - acc: 0.2429 - val_loss: 4.0447 - val_acc: 0.1265\n",
      "Epoch 51/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0867 - acc: 0.2421 - val_loss: 4.0536 - val_acc: 0.1321\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0618 - acc: 0.2472 - val_loss: 4.0581 - val_acc: 0.1301\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0691 - acc: 0.2491 - val_loss: 4.0450 - val_acc: 0.1337\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0363 - acc: 0.2537 - val_loss: 4.0617 - val_acc: 0.1327\n",
      "Epoch 55/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0543 - acc: 0.2479 - val_loss: 4.0688 - val_acc: 0.1317\n",
      "Epoch 56/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0508 - acc: 0.2479 - val_loss: 4.0696 - val_acc: 0.1301\n",
      "Epoch 57/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0261 - acc: 0.2531 - val_loss: 4.0587 - val_acc: 0.1291\n",
      "Epoch 58/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.0239 - acc: 0.2560 - val_loss: 4.0843 - val_acc: 0.1311\n",
      "Epoch 00058: early stopping\n",
      "Test accuracy: 0.131072709488\n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:49<00:00, 206.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value block1_conv1_7/kernel\n\t [[Node: block1_conv1_7/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@block1_conv1_7/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_7/kernel)]]\n\nCaused by op 'block1_conv1_7/kernel/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-cbcce3cab251>\", line 6, in <module>\n    notebook_name='VGG19Optimization_adam')\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperas/optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperas/optim.py\", line 133, in base_minimizer\n    return_argmin=True),\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"/home/mattia-lecci/2017-dlai-team4/code/temp_model.py\", line 136, in keras_fmin_fnct\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/applications/vgg19.py\", line 112, in VGG19\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 134, in build\n    constraint=self.kernel_constraint)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 380, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2071, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value block1_conv1_7/kernel\n\t [[Node: block1_conv1_7/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@block1_conv1_7/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_7/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value block1_conv1_7/kernel\n\t [[Node: block1_conv1_7/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@block1_conv1_7/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_7/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cbcce3cab251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evalutation of best performing model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value block1_conv1_7/kernel\n\t [[Node: block1_conv1_7/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@block1_conv1_7/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_7/kernel)]]\n\nCaused by op 'block1_conv1_7/kernel/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-cbcce3cab251>\", line 6, in <module>\n    notebook_name='VGG19Optimization_adam')\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperas/optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperas/optim.py\", line 133, in base_minimizer\n    return_argmin=True),\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/hyperopt/base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"/home/mattia-lecci/2017-dlai-team4/code/temp_model.py\", line 136, in keras_fmin_fnct\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/applications/vgg19.py\", line 112, in VGG19\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 134, in build\n    constraint=self.kernel_constraint)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 380, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 356, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2071, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mattia-lecci/venv_project/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value block1_conv1_7/kernel\n\t [[Node: block1_conv1_7/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@block1_conv1_7/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_7/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='VGG19Optimization_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 197.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "data loaded\n",
      "3/3 [==============================] - 1s 187ms/step\n",
      "Evalutation of best performing model:\n",
      "Validation loss:  4.78766489029\n",
      "Validation accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print('data loaded')\n",
    "\n",
    "val_loss, val_acc = best_model.evaluate(X_test, Y_test);\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(\"Validation loss: \", val_loss)\n",
    "print(\"Validation accuracy: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d771fb245f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "print(best_model.weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(modelPath);\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame(preds)\n",
    "# # Set column names to those generated by the one-hot encoding earlier\n",
    "# col_names = one_hot.columns.values\n",
    "# sub.columns = col_names\n",
    "# # Insert the column id from the sample_submission at the start of the data frame\n",
    "# sub.insert(0, 'id', df_test['id'])\n",
    "# sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
