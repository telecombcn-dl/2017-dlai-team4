{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# parameters #\n",
    "##############\n",
    "# dontFreezeLast = 0;\n",
    "\n",
    "# patience = 10;\n",
    "\n",
    "# gpuName = '/device:GPU:0'\n",
    "# workers = 2;\n",
    "# histogram_freq = 0;\n",
    "\n",
    "# epochs = 100;\n",
    "# validation_size=0.3;\n",
    "\n",
    "modelPath = '../models/VGG19_opt/run1.h5';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the csv's so we can see some more information on the filenames and breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('../input/labels.csv')\n",
    "# df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "# print('Training images: ',df_train.shape[0])\n",
    "# print('Test images: ',df_test.shape[0])\n",
    "\n",
    "# reduce dimensionality\n",
    "#df_train = df_train.head(100)\n",
    "#df_test = df_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the breed needs to be one-hot encoded for the final submission, so we will now do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_series = pd.Series(df_train['breed'])\n",
    "# one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to, 90x90 px, you should play with this number to see how it affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 \n",
    "# for f, breed in tqdm(df_train.values[:10]):\n",
    "#     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "#     label = one_hot_labels[i]\n",
    "#     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "#     y_train.append(label)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in tqdm(df_test['id'].values):\n",
    "#     img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    "#     x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_raw = np.array(y_train, np.uint8)\n",
    "# x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "# x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shape of the outputs to make sure everyting went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train_raw.shape)\n",
    "# print(y_train_raw.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = y_train_raw.shape[1]\n",
    "# print('Number of classes: ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to create a validation set so that you can gauge the performance of your model on independent data, unseen to the model in training. We do this by splitting the current training set (x_train_raw) and the corresponding labels (y_train_raw) so that we set aside 30 % of the data at random and put these in validation sets (X_valid and Y_valid).\n",
    "\n",
    "* This split needs to be improved so that it contains images from every class, with 120 separate classes some can not be represented and so the validation score is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the CNN architecture. Here we are using a pre-trained model VGG19 which has already been trained to identify many different dog breeds (as well as a lot of other objects from the imagenet dataset see here for more information: http://image-net.org/about-overview). Unfortunately it doesn't seem possible to downlod the weights from within this kernel so make sure you set the weights argument to 'imagenet' and not None, as it currently is below.\n",
    "\n",
    "We then remove the final layer and instead replace it with a single dense layer with the number of nodes corresponding to the number of breed classes we have (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('Getting data')\n",
    "    df_train = pd.read_csv('../input/labels.csv')\n",
    "    df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "    \n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "    \n",
    "    im_size = 90\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "    \n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    print('Splitting into training/validation')\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and model for hyperas\n",
    "\n",
    "def model(X_train,Y_train,X_valid,Y_valid):\n",
    "    print('Creating model')\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        base_model = VGG19(weights = 'imagenet',\n",
    "                           include_top=False,\n",
    "                           input_shape=(im_size, im_size, 3))\n",
    "\n",
    "        # Add a new top layer\n",
    "        x = base_model.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout({{uniform(0,1)}})(x)\n",
    "        x = Dense(1024,activation='relu')(x)\n",
    "        x = Dense(512,activation='relu')(x)\n",
    "        predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "        # This is the model we will train\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # First: train only the top layers (which were randomly initialized)\n",
    "        for i in range(len(base_model.layers)):\n",
    "            base_model.layers[i].trainable = False\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer={{choice(['adam','rmsprop','sgd'])}}, \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        callbacks_list = [];\n",
    "        callbacks_list.append(keras.callbacks.EarlyStopping(\n",
    "            monitor='val_acc',\n",
    "            patience=10,\n",
    "            verbose=1));\n",
    "        \n",
    "        print('Tensorboard NOT activated')\n",
    "        \n",
    "        model.fit(X_train, Y_train,\n",
    "          epochs=100,\n",
    "          batch_size = {{choice([16,32,64,128,256])}},\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          verbose=1,\n",
    "          callbacks=callbacks_list)\n",
    "        \n",
    "        score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
    "        print('Test accuracy:', acc)\n",
    "        return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.applications.vgg19 import VGG19\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from subprocess import check_output\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0,1),\n",
      "        'optimizer': hp.choice('optimizer', ['adam','rmsprop','sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [16,32,64,128,256]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: print('Getting data')\n",
      "  3: df_train = pd.read_csv('../input/labels.csv')\n",
      "  4: df_test = pd.read_csv('../input/sample_submission.csv')\n",
      "  5: \n",
      "  6: targets_series = pd.Series(df_train['breed'])\n",
      "  7: one_hot = pd.get_dummies(targets_series, sparse = True)\n",
      "  8: one_hot_labels = np.asarray(one_hot)\n",
      "  9: \n",
      " 10: im_size = 90\n",
      " 11: x_train = []\n",
      " 12: y_train = []\n",
      " 13: x_test = []\n",
      " 14: \n",
      " 15: i = 0 \n",
      " 16: for f, breed in tqdm(df_train.values):\n",
      " 17:     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
      " 18:     label = one_hot_labels[i]\n",
      " 19:     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
      " 20:     y_train.append(label)\n",
      " 21:     i += 1\n",
      " 22: \n",
      " 23: y_train_raw = np.array(y_train, np.uint8)\n",
      " 24: x_train_raw = np.array(x_train, np.float32) / 255.\n",
      " 25: num_class = y_train_raw.shape[1]\n",
      " 26: \n",
      " 27: print('Splitting into training/validation')\n",
      " 28: X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
      " 29: \n",
      " 30: \n",
      " 31: \n",
      " 32: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print('Creating model')\n",
      "   4:     with tf.device('/device:GPU:0'):\n",
      "   5:         base_model = VGG19(weights = 'imagenet',\n",
      "   6:                            include_top=False,\n",
      "   7:                            input_shape=(im_size, im_size, 3))\n",
      "   8: \n",
      "   9:         # Add a new top layer\n",
      "  10:         x = base_model.output\n",
      "  11:         x = Flatten()(x)\n",
      "  12:         x = Dropout(space['Dropout'])(x)\n",
      "  13:         x = Dense(1024,activation='relu')(x)\n",
      "  14:         x = Dense(512,activation='relu')(x)\n",
      "  15:         predictions = Dense(num_class, activation='softmax')(x)\n",
      "  16: \n",
      "  17:         # This is the model we will train\n",
      "  18:         model = Model(inputs=base_model.input, outputs=predictions)\n",
      "  19: \n",
      "  20:         # First: train only the top layers (which were randomly initialized)\n",
      "  21:         for i in range(len(base_model.layers)):\n",
      "  22:             base_model.layers[i].trainable = False\n",
      "  23: \n",
      "  24:         model.compile(loss='categorical_crossentropy', \n",
      "  25:                       optimizer=space['optimizer'], \n",
      "  26:                       metrics=['accuracy'])\n",
      "  27: \n",
      "  28:         callbacks_list = [];\n",
      "  29:         callbacks_list.append(keras.callbacks.EarlyStopping(\n",
      "  30:             monitor='val_acc',\n",
      "  31:             patience=10,\n",
      "  32:             verbose=1));\n",
      "  33:         \n",
      "  34:         print('Tensorboard NOT activated')\n",
      "  35:         \n",
      "  36:         model.fit(X_train, Y_train,\n",
      "  37:           epochs=100,\n",
      "  38:           batch_size = space['batch_size'],\n",
      "  39:           validation_data=(X_valid, Y_valid),\n",
      "  40:           verbose=1,\n",
      "  41:           callbacks=callbacks_list)\n",
      "  42:         \n",
      "  43:         score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
      "  44:         print('Test accuracy:', acc)\n",
      "  45:         return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  46: \n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:36<00:00, 283.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "Creating model\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 41s 6ms/step - loss: 4.8905 - acc: 0.0082 - val_loss: 4.7814 - val_acc: 0.0140\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.8106 - acc: 0.0137 - val_loss: 4.7736 - val_acc: 0.0153\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7830 - acc: 0.0126 - val_loss: 4.7597 - val_acc: 0.0196\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7673 - acc: 0.0150 - val_loss: 4.7481 - val_acc: 0.0218\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7517 - acc: 0.0171 - val_loss: 4.7322 - val_acc: 0.0228\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7262 - acc: 0.0225 - val_loss: 4.7025 - val_acc: 0.0342\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7038 - acc: 0.0250 - val_loss: 4.6702 - val_acc: 0.0339\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.6644 - acc: 0.0319 - val_loss: 4.6401 - val_acc: 0.0359\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.6265 - acc: 0.0321 - val_loss: 4.5854 - val_acc: 0.0476\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.5800 - acc: 0.0405 - val_loss: 4.5341 - val_acc: 0.0463\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.5273 - acc: 0.0460 - val_loss: 4.4900 - val_acc: 0.0531\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.4626 - acc: 0.0506 - val_loss: 4.4370 - val_acc: 0.0603\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.4165 - acc: 0.0590 - val_loss: 4.4021 - val_acc: 0.0629\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.3496 - acc: 0.0642 - val_loss: 4.4000 - val_acc: 0.0473\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.3088 - acc: 0.0734 - val_loss: 4.2795 - val_acc: 0.0737\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2609 - acc: 0.0707 - val_loss: 4.2610 - val_acc: 0.0727\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2226 - acc: 0.0770 - val_loss: 4.1928 - val_acc: 0.0864\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1838 - acc: 0.0815 - val_loss: 4.2173 - val_acc: 0.0783\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1590 - acc: 0.0881 - val_loss: 4.1311 - val_acc: 0.0952\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1160 - acc: 0.0917 - val_loss: 4.1092 - val_acc: 0.0955\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.0730 - acc: 0.0946 - val_loss: 4.0994 - val_acc: 0.0994\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.0556 - acc: 0.0985 - val_loss: 4.0861 - val_acc: 0.0851\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.0355 - acc: 0.0966 - val_loss: 4.0493 - val_acc: 0.1053\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.0090 - acc: 0.1099 - val_loss: 4.0287 - val_acc: 0.0975\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.9675 - acc: 0.1139 - val_loss: 4.0270 - val_acc: 0.0981\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.9605 - acc: 0.1106 - val_loss: 3.9784 - val_acc: 0.1102\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.9394 - acc: 0.1149 - val_loss: 4.0190 - val_acc: 0.1050\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.9263 - acc: 0.1156 - val_loss: 3.9751 - val_acc: 0.1154\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.8977 - acc: 0.1220 - val_loss: 3.9742 - val_acc: 0.1131\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.8717 - acc: 0.1198 - val_loss: 3.9468 - val_acc: 0.1164\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.8501 - acc: 0.1315 - val_loss: 3.9478 - val_acc: 0.1053\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.8300 - acc: 0.1275 - val_loss: 3.9566 - val_acc: 0.1096\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.8153 - acc: 0.1332 - val_loss: 3.9513 - val_acc: 0.1086\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.8179 - acc: 0.1287 - val_loss: 3.9081 - val_acc: 0.1184\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7900 - acc: 0.1365 - val_loss: 3.9172 - val_acc: 0.1197\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7851 - acc: 0.1356 - val_loss: 3.8831 - val_acc: 0.1275\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7691 - acc: 0.1468 - val_loss: 3.8992 - val_acc: 0.1259\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7481 - acc: 0.1452 - val_loss: 3.8707 - val_acc: 0.1272\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7245 - acc: 0.1416 - val_loss: 3.8982 - val_acc: 0.1324\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7159 - acc: 0.1518 - val_loss: 3.8751 - val_acc: 0.1259\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.7181 - acc: 0.1468 - val_loss: 3.8758 - val_acc: 0.1291\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6876 - acc: 0.1565 - val_loss: 3.8661 - val_acc: 0.1307\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6610 - acc: 0.1560 - val_loss: 3.9134 - val_acc: 0.1187\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6842 - acc: 0.1526 - val_loss: 3.8380 - val_acc: 0.1340\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6469 - acc: 0.1638 - val_loss: 3.8624 - val_acc: 0.1278\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6544 - acc: 0.1549 - val_loss: 3.8366 - val_acc: 0.1275\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6270 - acc: 0.1610 - val_loss: 3.8727 - val_acc: 0.1193\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.6282 - acc: 0.1645 - val_loss: 3.8381 - val_acc: 0.1236\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5984 - acc: 0.1705 - val_loss: 3.8620 - val_acc: 0.1285\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5997 - acc: 0.1674 - val_loss: 3.9010 - val_acc: 0.1239\n",
      "Epoch 51/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5932 - acc: 0.1646 - val_loss: 3.8668 - val_acc: 0.1291\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5912 - acc: 0.1715 - val_loss: 3.8358 - val_acc: 0.1314\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5584 - acc: 0.1761 - val_loss: 3.8524 - val_acc: 0.1337\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5651 - acc: 0.1704 - val_loss: 3.8391 - val_acc: 0.1373\n",
      "Epoch 55/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5341 - acc: 0.1750 - val_loss: 3.8393 - val_acc: 0.1255\n",
      "Epoch 56/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5211 - acc: 0.1869 - val_loss: 3.8498 - val_acc: 0.1366\n",
      "Epoch 57/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5072 - acc: 0.1834 - val_loss: 3.8501 - val_acc: 0.1255\n",
      "Epoch 58/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5103 - acc: 0.1737 - val_loss: 3.8503 - val_acc: 0.1379\n",
      "Epoch 59/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.5092 - acc: 0.1876 - val_loss: 3.8822 - val_acc: 0.1262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4901 - acc: 0.1894 - val_loss: 3.8460 - val_acc: 0.1399\n",
      "Epoch 61/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4916 - acc: 0.1873 - val_loss: 3.8912 - val_acc: 0.1259\n",
      "Epoch 62/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4649 - acc: 0.1874 - val_loss: 3.8498 - val_acc: 0.1334\n",
      "Epoch 63/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4517 - acc: 0.1936 - val_loss: 3.8757 - val_acc: 0.1356\n",
      "Epoch 64/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4528 - acc: 0.1944 - val_loss: 3.8083 - val_acc: 0.1402\n",
      "Epoch 65/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4442 - acc: 0.1883 - val_loss: 3.8208 - val_acc: 0.1392\n",
      "Epoch 66/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4331 - acc: 0.1950 - val_loss: 3.8112 - val_acc: 0.1386\n",
      "Epoch 67/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.4116 - acc: 0.2011 - val_loss: 3.8266 - val_acc: 0.1360\n",
      "Epoch 68/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3962 - acc: 0.1990 - val_loss: 3.8484 - val_acc: 0.1268\n",
      "Epoch 69/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3879 - acc: 0.2061 - val_loss: 3.8187 - val_acc: 0.1396\n",
      "Epoch 70/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3871 - acc: 0.1976 - val_loss: 3.8648 - val_acc: 0.1334\n",
      "Epoch 71/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3718 - acc: 0.2031 - val_loss: 3.8136 - val_acc: 0.1425\n",
      "Epoch 72/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3421 - acc: 0.2063 - val_loss: 3.8459 - val_acc: 0.1422\n",
      "Epoch 73/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3402 - acc: 0.2095 - val_loss: 3.9167 - val_acc: 0.1281\n",
      "Epoch 74/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3529 - acc: 0.2088 - val_loss: 3.8156 - val_acc: 0.1356\n",
      "Epoch 75/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3239 - acc: 0.2025 - val_loss: 3.8868 - val_acc: 0.1311\n",
      "Epoch 76/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.3130 - acc: 0.2182 - val_loss: 3.8605 - val_acc: 0.1366\n",
      "Epoch 77/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.2965 - acc: 0.2243 - val_loss: 3.8490 - val_acc: 0.1392\n",
      "Epoch 78/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.2864 - acc: 0.2235 - val_loss: 3.8949 - val_acc: 0.1327\n",
      "Epoch 79/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.2905 - acc: 0.2197 - val_loss: 3.8481 - val_acc: 0.1278\n",
      "Epoch 80/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.2750 - acc: 0.2207 - val_loss: 3.8293 - val_acc: 0.1422\n",
      "Epoch 81/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 3.2659 - acc: 0.2247 - val_loss: 3.7965 - val_acc: 0.1415\n",
      "Epoch 00081: early stopping\n",
      "Test accuracy: 0.141506358012\n",
      "Creating model\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.7835 - acc: 0.0147 - val_loss: 4.6170 - val_acc: 0.0306\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.3699 - acc: 0.0555 - val_loss: 4.1745 - val_acc: 0.0779\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.0054 - acc: 0.1029 - val_loss: 4.0180 - val_acc: 0.1007\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.7692 - acc: 0.1283 - val_loss: 3.9206 - val_acc: 0.1144\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.5826 - acc: 0.1631 - val_loss: 3.8704 - val_acc: 0.1232\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.4008 - acc: 0.1947 - val_loss: 3.8587 - val_acc: 0.1317\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.2490 - acc: 0.2198 - val_loss: 3.8350 - val_acc: 0.1356\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 3.0701 - acc: 0.2519 - val_loss: 3.8501 - val_acc: 0.1409\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 2.8939 - acc: 0.2826 - val_loss: 3.9244 - val_acc: 0.1311\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 2.7127 - acc: 0.3217 - val_loss: 3.9547 - val_acc: 0.1392\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 2.5403 - acc: 0.3592 - val_loss: 4.0294 - val_acc: 0.1350\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 2.3675 - acc: 0.3944 - val_loss: 4.0955 - val_acc: 0.1441\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 2.1988 - acc: 0.4261 - val_loss: 4.2413 - val_acc: 0.1301\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 2.0376 - acc: 0.4647 - val_loss: 4.2962 - val_acc: 0.1301\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.8828 - acc: 0.5003 - val_loss: 4.4410 - val_acc: 0.1239\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.7138 - acc: 0.5371 - val_loss: 4.5962 - val_acc: 0.1115\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.5656 - acc: 0.5704 - val_loss: 4.7693 - val_acc: 0.1206\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.4581 - acc: 0.6000 - val_loss: 4.8874 - val_acc: 0.1330\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.3360 - acc: 0.6344 - val_loss: 5.0409 - val_acc: 0.1255\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.2038 - acc: 0.6612 - val_loss: 5.2287 - val_acc: 0.1206\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.1197 - acc: 0.6850 - val_loss: 5.3067 - val_acc: 0.1213\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 1.0487 - acc: 0.7036 - val_loss: 5.3596 - val_acc: 0.1161\n",
      "Epoch 00022: early stopping\n",
      "Test accuracy: 0.116074339751\n",
      "Creating model\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.7740 - acc: 0.0224 - val_loss: 4.5246 - val_acc: 0.0466\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 4.2639 - acc: 0.0703 - val_loss: 4.1612 - val_acc: 0.0796\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.8582 - acc: 0.1163 - val_loss: 3.9728 - val_acc: 0.1135\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 3.5830 - acc: 0.1613 - val_loss: 3.9472 - val_acc: 0.1063\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 3.3294 - acc: 0.2071 - val_loss: 3.9720 - val_acc: 0.1148\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 3.1103 - acc: 0.2514 - val_loss: 3.8834 - val_acc: 0.1219\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.8659 - acc: 0.2971 - val_loss: 3.9743 - val_acc: 0.1213\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.6163 - acc: 0.3518 - val_loss: 4.0441 - val_acc: 0.1334\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 2.4010 - acc: 0.3918 - val_loss: 4.0498 - val_acc: 0.1200\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 2.1670 - acc: 0.4393 - val_loss: 4.1859 - val_acc: 0.1340\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 1.9309 - acc: 0.5008 - val_loss: 4.3475 - val_acc: 0.1301\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 1.7107 - acc: 0.5412 - val_loss: 4.5681 - val_acc: 0.1311\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 1.4884 - acc: 0.5996 - val_loss: 4.8608 - val_acc: 0.1167\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 1.3290 - acc: 0.6373 - val_loss: 4.7862 - val_acc: 0.1369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 1.1246 - acc: 0.6932 - val_loss: 4.9797 - val_acc: 0.1275\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 0.9857 - acc: 0.7205 - val_loss: 5.3360 - val_acc: 0.1206\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 0.8636 - acc: 0.7530 - val_loss: 5.4551 - val_acc: 0.1184\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 0.7426 - acc: 0.7866 - val_loss: 5.6273 - val_acc: 0.1174\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 0.6514 - acc: 0.8131 - val_loss: 5.7840 - val_acc: 0.1187\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 0.5762 - acc: 0.8306 - val_loss: 5.8695 - val_acc: 0.1242\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 0.5100 - acc: 0.8485 - val_loss: 6.2124 - val_acc: 0.1200\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 0.4603 - acc: 0.8594 - val_loss: 6.2898 - val_acc: 0.1122\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 27s 4ms/step - loss: 0.3910 - acc: 0.8833 - val_loss: 6.3376 - val_acc: 0.1255\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 26s 4ms/step - loss: 0.3813 - acc: 0.8854 - val_loss: 6.6665 - val_acc: 0.1246\n",
      "Epoch 00024: early stopping\n",
      "Test accuracy: 0.124551679175\n",
      "Creating model\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.8901 - acc: 0.0115 - val_loss: 4.7861 - val_acc: 0.0121\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7894 - acc: 0.0152 - val_loss: 4.7485 - val_acc: 0.0215\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.7163 - acc: 0.0247 - val_loss: 4.6444 - val_acc: 0.0355\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.6093 - acc: 0.0342 - val_loss: 4.5187 - val_acc: 0.0460\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.5116 - acc: 0.0432 - val_loss: 4.4565 - val_acc: 0.0492\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.4701 - acc: 0.0440 - val_loss: 4.3811 - val_acc: 0.0655\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.4072 - acc: 0.0516 - val_loss: 4.3461 - val_acc: 0.0541\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.3713 - acc: 0.0576 - val_loss: 4.3691 - val_acc: 0.0619\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.3422 - acc: 0.0615 - val_loss: 4.2913 - val_acc: 0.0773\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.3161 - acc: 0.0597 - val_loss: 4.2958 - val_acc: 0.0796\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.3042 - acc: 0.0644 - val_loss: 4.3045 - val_acc: 0.0792\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2760 - acc: 0.0655 - val_loss: 4.2736 - val_acc: 0.0802\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2542 - acc: 0.0704 - val_loss: 4.2440 - val_acc: 0.0858\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2531 - acc: 0.0672 - val_loss: 4.2488 - val_acc: 0.0913\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2252 - acc: 0.0760 - val_loss: 4.2332 - val_acc: 0.0858\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2121 - acc: 0.0753 - val_loss: 4.2352 - val_acc: 0.0812\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.2368 - acc: 0.0718 - val_loss: 4.2256 - val_acc: 0.0978\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1987 - acc: 0.0790 - val_loss: 4.2034 - val_acc: 0.0965\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1890 - acc: 0.0832 - val_loss: 4.2056 - val_acc: 0.0903\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1827 - acc: 0.0837 - val_loss: 4.2017 - val_acc: 0.0972\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1798 - acc: 0.0802 - val_loss: 4.2209 - val_acc: 0.0913\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1861 - acc: 0.0790 - val_loss: 4.1745 - val_acc: 0.0968\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1828 - acc: 0.0781 - val_loss: 4.1876 - val_acc: 0.0923\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1719 - acc: 0.0855 - val_loss: 4.1791 - val_acc: 0.0933\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1752 - acc: 0.0834 - val_loss: 4.2151 - val_acc: 0.0897\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 29s 4ms/step - loss: 4.1722 - acc: 0.0822 - val_loss: 4.2109 - val_acc: 0.0962\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.1647 - acc: 0.0822 - val_loss: 4.2183 - val_acc: 0.0893\n",
      "Epoch 00027: early stopping\n",
      "Test accuracy: 0.0893381154247\n",
      "Creating model\n",
      "Tensorboard NOT activated\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 30s 4ms/step - loss: 4.7701 - acc: 0.0212 - val_loss: 4.6367 - val_acc: 0.0290\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 4.3653 - acc: 0.0692 - val_loss: 4.2495 - val_acc: 0.0756\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 3.9159 - acc: 0.1269 - val_loss: 4.0343 - val_acc: 0.1017\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 3.5603 - acc: 0.1711 - val_loss: 3.9246 - val_acc: 0.1102\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 3.3169 - acc: 0.2143 - val_loss: 3.8651 - val_acc: 0.1360\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 3.1037 - acc: 0.2630 - val_loss: 3.8552 - val_acc: 0.1373\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 2.8941 - acc: 0.3012 - val_loss: 3.9026 - val_acc: 0.1314\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 2.7210 - acc: 0.3317 - val_loss: 3.9332 - val_acc: 0.1373\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 2.4931 - acc: 0.3813 - val_loss: 3.9512 - val_acc: 0.1366\n",
      "Epoch 10/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 2.3044 - acc: 0.4152 - val_loss: 3.9712 - val_acc: 0.1405\n",
      "Epoch 11/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 2.0883 - acc: 0.4741 - val_loss: 4.0280 - val_acc: 0.1467\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.9072 - acc: 0.5129 - val_loss: 4.1394 - val_acc: 0.1376\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.7417 - acc: 0.5536 - val_loss: 4.2042 - val_acc: 0.1366\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.5416 - acc: 0.6014 - val_loss: 4.3310 - val_acc: 0.1317\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.4211 - acc: 0.6282 - val_loss: 4.3227 - val_acc: 0.1428\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.2476 - acc: 0.6783 - val_loss: 4.4792 - val_acc: 0.1347\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.0938 - acc: 0.7156 - val_loss: 4.5600 - val_acc: 0.1386\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 1.0023 - acc: 0.7382 - val_loss: 4.7453 - val_acc: 0.1324\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 0.8382 - acc: 0.7842 - val_loss: 4.8124 - val_acc: 0.1337\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 0.7432 - acc: 0.8087 - val_loss: 4.9891 - val_acc: 0.1415\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 24s 3ms/step - loss: 0.6692 - acc: 0.8281 - val_loss: 5.1293 - val_acc: 0.1353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: early stopping\n",
      "Test accuracy: 0.135311379203\n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:36<00:00, 281.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "Evalutation of best performing model:\n",
      "3067/3067 [==============================] - 9s 3ms/step\n",
      "[3.7964961458037645, 0.14150635801185255]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='VGG19Optimization_1')\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "val_loss, val_acc = best_model.evaluate(X_test, Y_test);\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(\"Validation loss: \", val_loss)\n",
    "print(\"Validation accuracy: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 90, 90, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 90, 90, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 90, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 45, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 22,708,920\n",
      "Trainable params: 2,684,536\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.save(modelPath);\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame(preds)\n",
    "# # Set column names to those generated by the one-hot encoding earlier\n",
    "# col_names = one_hot.columns.values\n",
    "# sub.columns = col_names\n",
    "# # Insert the column id from the sample_submission at the start of the data frame\n",
    "# sub.insert(0, 'id', df_test['id'])\n",
    "# sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
