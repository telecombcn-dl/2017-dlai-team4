{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from hyperas.distributions import uniform\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### VGG19 parameters ########\n",
    "dontFreezeLast = 2;\n",
    "\n",
    "patience = 30;\n",
    "\n",
    "loadWeights = False;\n",
    "saveWeights = False;\n",
    "\n",
    "\n",
    "tensorboard_dir = '../tb/catsdogs/try_64_dense90_64_90x2_120_drop05';\n",
    "if not os.path.exists(tensorboard_dir):\n",
    "    os.makedirs(tensorboard_dir)    \n",
    "checkPointPath = tensorboard_dir + '/best_weights.hdf5';\n",
    "\n",
    "####################################\n",
    "\n",
    "gpuName = '/device:GPU:1'\n",
    "tensorboardFlag = True;\n",
    "workers = 10;\n",
    "histogram_freq = 0;\n",
    "\n",
    "batchSize = 64;\n",
    "epochs = 100;\n",
    "validation_size=0.3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the csv's so we can see some more information on the filenames and breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training images: ', 10222)\n",
      "('Test images: ', 10357)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/labels.csv')\n",
    "df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "print('Training images: ',df_train.shape[0])\n",
    "print('Test images: ',df_test.shape[0])\n",
    "\n",
    "# reduce dimensionality\n",
    "#df_train = df_train.head(100)\n",
    "#df_test = df_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002a283a315af96eaea0e28e7163b21b</td>\n",
       "      <td>borzoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id               breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07         boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97               dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397            pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d            bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62    golden_retriever\n",
       "5  002211c81b498ef88e1b40b9abf84e1d  bedlington_terrier\n",
       "6  00290d3e1fdd27226ba27a8ce248ce85  bedlington_terrier\n",
       "7  002a283a315af96eaea0e28e7163b21b              borzoi\n",
       "8  003df8b8a8b05244b1d920bb6cf451f9             basenji\n",
       "9  0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the breed needs to be one-hot encoded for the final submission, so we will now do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_series = pd.Series(df_train['breed'])\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to, 90x90 px, you should play with this number to see how it affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:49<00:00, 206.11it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "for f, breed in tqdm(df_train.values):\n",
    "    img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "    label = one_hot_labels[i]\n",
    "    x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "    y_train.append(label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " #for f in tqdm(df_test['id'].values):\n",
    " #    img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    " #    x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = np.array(y_train, np.uint8)\n",
    "x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shape of the outputs to make sure everyting went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 90, 90, 3)\n",
      "(10222, 120)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of classes: ', 120)\n"
     ]
    }
   ],
   "source": [
    "num_class = y_train_raw.shape[1]\n",
    "print('Number of classes: ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to create a validation set so that you can gauge the performance of your model on independent data, unseen to the model in training. We do this by splitting the current training set (x_train_raw) and the corresponding labels (y_train_raw) so that we set aside 30 % of the data at random and put these in validation sets (X_valid and Y_valid).\n",
    "\n",
    "* This split needs to be improved so that it contains images from every class, with 120 separate classes some can not be represented and so the validation score is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the CNN architecture. Here we are using a pre-trained model VGG19 which has already been trained to identify many different dog breeds (as well as a lot of other objects from the imagenet dataset see here for more information: http://image-net.org/about-overview). Unfortunately it doesn't seem possible to downlod the weights from within this kernel so make sure you set the weights argument to 'imagenet' and not None, as it currently is below.\n",
    "\n",
    "We then remove the final layer and instead replace it with a single dense layer with the number of nodes corresponding to the number of breed classes we have (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tensorboard activated in directory: ', '../tb/catsdogs/try_64_dense90_64_90x2_120_drop05')\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 88, 88, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 88, 88, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 86, 86, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 41, 41, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 41, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 39, 39, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 39, 39, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 23104)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               11829760  \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 120)               61560     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 120)               0         \n",
      "=================================================================\n",
      "Total params: 11,956,888\n",
      "Trainable params: 11,956,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the base pre-trained model\n",
    "# Can't download weights in the kernel\n",
    "with tf.device(gpuName):\n",
    "    \n",
    "    dropout_rate = 0.5\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, im_size, im_size)\n",
    "    else:\n",
    "        input_shape = (im_size, im_size, 3)\n",
    "\n",
    "     \n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(im_size,im_size,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    Dropout(.3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer\n",
    "\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(120))\n",
    "\n",
    "    # model.add(Convolution2D(10,3,3, border_mode='same'))\n",
    "    # model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "   \n",
    "    ##### Mattia's model #####\n",
    "    # Add a new top layer\n",
    "    #x = base_model.output\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(1024,activation='relu')(x)\n",
    "    #x = Dense(512,activation='relu')(x)\n",
    "    #predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "    # This is the model we will train\n",
    "    #model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # First: train only the top layers (which were randomly initialized)\n",
    "    #for i in range(len(base_model.layers)-dontFreezeLast):\n",
    "        #base_model.layers[i].trainable = False\n",
    "\n",
    "    #if loadWeights:\n",
    "    #    model.load_weights(checkPointPath)\n",
    "    ##### Mattia's model #####\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks_list = [];\n",
    "    callbacks_list.append(keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=patience,\n",
    "        verbose=1));\n",
    "    if saveWeights:\n",
    "        callbacks_list.append(keras.callbacks.ModelCheckpoint(\n",
    "            checkPointPath,\n",
    "            monitor='val_acc',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            save_weights_only=True))\n",
    "    if tensorboardFlag:\n",
    "        callbacks_list.append(keras.callbacks.TensorBoard(\n",
    "                log_dir=tensorboard_dir,\n",
    "                histogram_freq=histogram_freq,\n",
    "                write_graph=False,\n",
    "                write_images=False));\n",
    "        print('Tensorboard activated in directory: ',tensorboard_dir)\n",
    "    else:\n",
    "        print('Tensorboard NOT activated')\n",
    "\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X,Y,batch_size):\n",
    "    batch_features = np.ndarray(shape=(batch_size,) + X.shape[1:],\n",
    "                                dtype=X.dtype);\n",
    "    batch_labels = np.ndarray(shape=(batch_size,) + Y.shape[1:],\n",
    "                                dtype=Y.dtype)\n",
    "    N = X.shape[0];\n",
    "    \n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index= np.random.choice(N,1)\n",
    "            batch_features[i] = X[index]\n",
    "            batch_labels[i] = Y[index]\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.7908 - acc: 0.0074 - val_loss: 4.7855 - val_acc: 0.0121\n",
      "Epoch 2/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.7841 - acc: 0.0106 - val_loss: 4.7740 - val_acc: 0.0166\n",
      "Epoch 3/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.7581 - acc: 0.0129 - val_loss: 4.7343 - val_acc: 0.0127\n",
      "Epoch 4/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.6878 - acc: 0.0177 - val_loss: 4.6437 - val_acc: 0.0215\n",
      "Epoch 5/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.6321 - acc: 0.0207 - val_loss: 4.6069 - val_acc: 0.0254\n",
      "Epoch 6/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.5855 - acc: 0.0252 - val_loss: 4.5731 - val_acc: 0.0316\n",
      "Epoch 7/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.5072 - acc: 0.0396 - val_loss: 4.5172 - val_acc: 0.0355\n",
      "Epoch 8/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 4.3713 - acc: 0.0531 - val_loss: 4.4577 - val_acc: 0.0430\n",
      "Epoch 9/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 3.5578 - acc: 0.1881 - val_loss: 4.4472 - val_acc: 0.0571\n",
      "Epoch 12/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 3.1502 - acc: 0.2531 - val_loss: 4.4999 - val_acc: 0.0545\n",
      "Epoch 13/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 2.7970 - acc: 0.3167 - val_loss: 4.6135 - val_acc: 0.0580\n",
      "Epoch 14/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 2.4682 - acc: 0.3911 - val_loss: 4.6471 - val_acc: 0.0515\n",
      "Epoch 15/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 2.1641 - acc: 0.4470 - val_loss: 4.9382 - val_acc: 0.0509\n",
      "Epoch 16/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.8979 - acc: 0.5068 - val_loss: 5.0294 - val_acc: 0.0571\n",
      "Epoch 17/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.6621 - acc: 0.5684 - val_loss: 5.2537 - val_acc: 0.0567\n",
      "Epoch 18/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.4787 - acc: 0.5972 - val_loss: 5.2045 - val_acc: 0.0545\n",
      "Epoch 19/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.3206 - acc: 0.6391 - val_loss: 5.3750 - val_acc: 0.0538\n",
      "Epoch 20/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.1925 - acc: 0.6704 - val_loss: 5.7211 - val_acc: 0.0531\n",
      "Epoch 21/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.0754 - acc: 0.6988 - val_loss: 6.0293 - val_acc: 0.0538\n",
      "Epoch 22/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 1.0093 - acc: 0.7108 - val_loss: 6.1894 - val_acc: 0.0580\n",
      "Epoch 23/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.9206 - acc: 0.7402 - val_loss: 6.2587 - val_acc: 0.0574\n",
      "Epoch 24/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.8565 - acc: 0.7579 - val_loss: 6.1915 - val_acc: 0.0567\n",
      "Epoch 25/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.8037 - acc: 0.7708 - val_loss: 6.4750 - val_acc: 0.0548\n",
      "Epoch 26/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.7599 - acc: 0.7804 - val_loss: 6.3714 - val_acc: 0.0505\n",
      "Epoch 27/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.7129 - acc: 0.7954 - val_loss: 6.5886 - val_acc: 0.0551\n",
      "Epoch 28/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.6848 - acc: 0.8020 - val_loss: 6.6003 - val_acc: 0.0571\n",
      "Epoch 29/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.6354 - acc: 0.8155 - val_loss: 6.6159 - val_acc: 0.0567\n",
      "Epoch 30/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.6202 - acc: 0.8169 - val_loss: 6.4435 - val_acc: 0.0525\n",
      "Epoch 31/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.5858 - acc: 0.8307 - val_loss: 6.5707 - val_acc: 0.0505\n",
      "Epoch 32/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.5738 - acc: 0.8314 - val_loss: 6.9390 - val_acc: 0.0525\n",
      "Epoch 33/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.5247 - acc: 0.8456 - val_loss: 7.1691 - val_acc: 0.0518\n",
      "Epoch 34/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.5074 - acc: 0.8520 - val_loss: 6.9415 - val_acc: 0.0528\n",
      "Epoch 35/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.5192 - acc: 0.8436 - val_loss: 6.8620 - val_acc: 0.0587\n",
      "Epoch 36/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.5092 - acc: 0.8453 - val_loss: 7.1855 - val_acc: 0.0577\n",
      "Epoch 37/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.4963 - acc: 0.8479 - val_loss: 7.0345 - val_acc: 0.0580\n",
      "Epoch 38/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.4403 - acc: 0.8681 - val_loss: 7.3118 - val_acc: 0.0545\n",
      "Epoch 39/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.4648 - acc: 0.8625 - val_loss: 7.2758 - val_acc: 0.0580\n",
      "Epoch 40/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.4387 - acc: 0.8692 - val_loss: 7.3361 - val_acc: 0.0522\n",
      "Epoch 41/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.4448 - acc: 0.8653 - val_loss: 7.1438 - val_acc: 0.0561\n",
      "Epoch 42/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3984 - acc: 0.8818 - val_loss: 7.2867 - val_acc: 0.0558\n",
      "Epoch 43/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.4155 - acc: 0.8766 - val_loss: 7.1888 - val_acc: 0.0531\n",
      "Epoch 44/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3945 - acc: 0.8798 - val_loss: 7.2994 - val_acc: 0.0571\n",
      "Epoch 45/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3796 - acc: 0.8837 - val_loss: 7.5345 - val_acc: 0.0545\n",
      "Epoch 46/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3802 - acc: 0.8858 - val_loss: 7.3072 - val_acc: 0.0538\n",
      "Epoch 47/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3703 - acc: 0.8850 - val_loss: 7.4384 - val_acc: 0.0561\n",
      "Epoch 48/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3857 - acc: 0.8827 - val_loss: 7.5341 - val_acc: 0.0593\n",
      "Epoch 49/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3852 - acc: 0.8777 - val_loss: 7.3972 - val_acc: 0.0538\n",
      "Epoch 50/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3510 - acc: 0.8927 - val_loss: 7.6214 - val_acc: 0.0580\n",
      "Epoch 51/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3731 - acc: 0.8848 - val_loss: 7.8286 - val_acc: 0.0525\n",
      "Epoch 52/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3315 - acc: 0.8978 - val_loss: 7.4626 - val_acc: 0.0587\n",
      "Epoch 53/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3241 - acc: 0.9003 - val_loss: 7.8543 - val_acc: 0.0551\n",
      "Epoch 54/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3302 - acc: 0.8980 - val_loss: 7.6900 - val_acc: 0.0554\n",
      "Epoch 55/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3165 - acc: 0.9027 - val_loss: 7.7509 - val_acc: 0.0558\n",
      "Epoch 56/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3216 - acc: 0.9003 - val_loss: 7.7433 - val_acc: 0.0538\n",
      "Epoch 57/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3057 - acc: 0.9093 - val_loss: 7.7103 - val_acc: 0.0554\n",
      "Epoch 58/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3178 - acc: 0.9019 - val_loss: 7.7595 - val_acc: 0.0535\n",
      "Epoch 59/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.3200 - acc: 0.9034 - val_loss: 7.9611 - val_acc: 0.0518\n",
      "Epoch 60/100\n",
      "7155/7155 [==============================] - 13s 2ms/step - loss: 0.2961 - acc: 0.9065 - val_loss: 7.8741 - val_acc: 0.0538\n",
      "Epoch 61/100\n",
      "3136/7155 [============>.................] - ETA: 6s - loss: 0.3011 - acc: 0.9066"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a9f1dc7045ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# steps_per_epoch = round(X_train.shape[0]/batchSize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paolot/venv-tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size = batchSize,\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          verbose=1,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "# steps_per_epoch = round(X_train.shape[0]/batchSize)\n",
    "# model.fit_generator(generator(X_train,Y_train,batchSize),\n",
    "#                    steps_per_epoch=steps_per_epoch,\n",
    "#                    epochs=epochs,\n",
    "#                    verbose=1,\n",
    "#                    callbacks=callbacks_list,\n",
    "#                    validation_data=(X_valid,Y_valid),\n",
    "#                    workers=workers,\n",
    "#                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #sub = pd.DataFrame(preds)\n",
    " ## Set column names to those generated by the one-hot encoding earlier\n",
    " #col_names = one_hot.columns.values\n",
    " #sub.columns = col_names\n",
    " ## Insert the column id from the sample_submission at the start of the data frame\n",
    " #sub.insert(0, 'id', df_test['id'])\n",
    " #sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
