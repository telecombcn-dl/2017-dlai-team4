{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# parameters #\n",
    "##############\n",
    "# dontFreezeLast = 0;\n",
    "\n",
    "# patience = 10;\n",
    "\n",
    "# gpuName = '/device:GPU:0'\n",
    "# workers = 2;\n",
    "# histogram_freq = 0;\n",
    "\n",
    "# epochs = 100;\n",
    "# validation_size=0.3;\n",
    "\n",
    "modelPath = '../models/NewModel_opt/';\n",
    "modelName = 'run1.h5';\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the csv's so we can see some more information on the filenames and breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('../input/labels.csv')\n",
    "# df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "# print('Training images: ',df_train.shape[0])\n",
    "# print('Test images: ',df_test.shape[0])\n",
    "\n",
    "# reduce dimensionality\n",
    "#df_train = df_train.head(100)\n",
    "#df_test = df_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the breed needs to be one-hot encoded for the final submission, so we will now do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_series = pd.Series(df_train['breed'])\n",
    "# one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to, 90x90 px, you should play with this number to see how it affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 \n",
    "# for f, breed in tqdm(df_train.values[:10]):\n",
    "#     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "#     label = one_hot_labels[i]\n",
    "#     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "#     y_train.append(label)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in tqdm(df_test['id'].values):\n",
    "#     img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    "#     x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_raw = np.array(y_train, np.uint8)\n",
    "# x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "# x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shape of the outputs to make sure everyting went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train_raw.shape)\n",
    "# print(y_train_raw.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = y_train_raw.shape[1]\n",
    "# print('Number of classes: ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to create a validation set so that you can gauge the performance of your model on independent data, unseen to the model in training. We do this by splitting the current training set (x_train_raw) and the corresponding labels (y_train_raw) so that we set aside 30 % of the data at random and put these in validation sets (X_valid and Y_valid).\n",
    "\n",
    "* This split needs to be improved so that it contains images from every class, with 120 separate classes some can not be represented and so the validation score is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the CNN architecture. Here we are using a pre-trained model VGG19 which has already been trained to identify many different dog breeds (as well as a lot of other objects from the imagenet dataset see here for more information: http://image-net.org/about-overview). Unfortunately it doesn't seem possible to downlod the weights from within this kernel so make sure you set the weights argument to 'imagenet' and not None, as it currently is below.\n",
    "\n",
    "We then remove the final layer and instead replace it with a single dense layer with the number of nodes corresponding to the number of breed classes we have (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('Getting data')\n",
    "    df_train = pd.read_csv('../input/labels.csv')\n",
    "    df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "    \n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "    \n",
    "    im_size = 90;\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "    \n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    print('Splitting into training/validation')\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and model for hyperas\n",
    "\n",
    "def model(X_train,Y_train,X_valid,Y_valid):\n",
    "    print('Creating model')\n",
    "     #with tf.device('/device:GPU:0'):\n",
    "    batchSize = 64;\n",
    "    \n",
    "    dropout = {{uniform(0.4,0.9)}};\n",
    "    Ndrop = {{choice([1,2,3])}};\n",
    "    \n",
    "    print()\n",
    "    print('dropout=',dropout)\n",
    "    print('Ndrop=',Ndrop)\n",
    "    print()\n",
    "    \n",
    "    stepsPerEpoch = round( len(X_train)/batchSize );\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(im_size,im_size,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) # after batch norm\n",
    "    model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "    model.add(BatchNormalization())\n",
    "    if Ndrop>=1:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) # after batch norm\n",
    "    model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    if Ndrop>=2:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    if Ndrop==3:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(120,activation='softmax'))\n",
    "    #model.add(Conv2D(10,(3,3)))\n",
    "    #model.add(GlobalAveragePooling2D('none'))\n",
    "    \n",
    "    \n",
    "    #predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "    # This is the model we will train\n",
    "    #model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # First: train only the top layers (which were randomly initialized)\n",
    "    #for i in range(len(base_model.layers)):\n",
    "    #    base_model.layers[i].trainable = False\n",
    "\n",
    "    # predetermined optimizer\n",
    "    lr=0.00020389590556056983;\n",
    "    beta_1=0.9453158868247398;\n",
    "    beta_2=0.9925872692991417;\n",
    "    decay=0.000821336141287018;\n",
    "    adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks_list = [];\n",
    "    callbacks_list.append(keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=1));\n",
    "\n",
    "\n",
    "    # data augmentation & fitting\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True);\n",
    "    \n",
    "    model.fit_generator(\n",
    "        datagen.flow(X_train,Y_train,batch_size=batchSize),\n",
    "        steps_per_epoch=stepsPerEpoch,\n",
    "        epochs=150,\n",
    "        verbose=1,\n",
    "        validation_data=(X_valid,Y_valid),\n",
    "        workers=2,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks_list)\n",
    "#     model.fit(X_train, Y_train,\n",
    "#       epochs=100,\n",
    "#       batch_size = batchSize,\n",
    "#       validation_data=(X_valid, Y_valid),\n",
    "#       verbose=1,\n",
    "#       callbacks=callbacks_list)\n",
    "\n",
    "    score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.applications import VGG19\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model, Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from subprocess import check_output\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'dropout': hp.uniform('dropout', 0.4,0.9),\n",
      "        'Ndrop': hp.choice('Ndrop', [1,2,3]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: print('Getting data')\n",
      "  3: df_train = pd.read_csv('../input/labels.csv')\n",
      "  4: df_test = pd.read_csv('../input/sample_submission.csv')\n",
      "  5: \n",
      "  6: targets_series = pd.Series(df_train['breed'])\n",
      "  7: one_hot = pd.get_dummies(targets_series, sparse = True)\n",
      "  8: one_hot_labels = np.asarray(one_hot)\n",
      "  9: \n",
      " 10: im_size = 90;\n",
      " 11: x_train = []\n",
      " 12: y_train = []\n",
      " 13: x_test = []\n",
      " 14: \n",
      " 15: i = 0 \n",
      " 16: for f, breed in tqdm(df_train.values):\n",
      " 17:     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
      " 18:     label = one_hot_labels[i]\n",
      " 19:     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
      " 20:     y_train.append(label)\n",
      " 21:     i += 1\n",
      " 22: \n",
      " 23: y_train_raw = np.array(y_train, np.uint8)\n",
      " 24: x_train_raw = np.array(x_train, np.float32) / 255.\n",
      " 25: num_class = y_train_raw.shape[1]\n",
      " 26: \n",
      " 27: print('Splitting into training/validation')\n",
      " 28: X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
      " 29: \n",
      " 30: \n",
      " 31: \n",
      " 32: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print('Creating model')\n",
      "   4:      #with tf.device('/device:GPU:0'):\n",
      "   5:     batchSize = 64;\n",
      "   6:     \n",
      "   7:     dropout = space['dropout'];\n",
      "   8:     Ndrop = space['Ndrop'];\n",
      "   9:     \n",
      "  10:     print()\n",
      "  11:     print('dropout=',dropout)\n",
      "  12:     print('Ndrop=',Ndrop)\n",
      "  13:     print()\n",
      "  14:     \n",
      "  15:     stepsPerEpoch = round( len(X_train)/batchSize );\n",
      "  16:     \n",
      "  17:     model = Sequential()\n",
      "  18: \n",
      "  19:     model.add(Conv2D(32, (3, 3), input_shape=(im_size,im_size,3)))\n",
      "  20:     model.add(BatchNormalization())\n",
      "  21:     model.add(Activation('relu')) # after batch norm\n",
      "  22:     model.add(Conv2D(32, (3, 3),activation='relu'))\n",
      "  23:     model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  24:  \n",
      "  25:     model.add(BatchNormalization())\n",
      "  26:     if Ndrop>=1:\n",
      "  27:         model.add(Dropout(dropout))\n",
      "  28:     model.add(Conv2D(64,(3, 3)))\n",
      "  29:     model.add(BatchNormalization())\n",
      "  30:     model.add(Activation('relu')) # after batch norm\n",
      "  31:     model.add(Conv2D(64, (3, 3),activation='relu'))\n",
      "  32:     model.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  33: \n",
      "  34:     model.add(Flatten())\n",
      "  35:     # Fully connected layer\n",
      "  36: \n",
      "  37:     model.add(BatchNormalization())\n",
      "  38:     if Ndrop>=2:\n",
      "  39:         model.add(Dropout(dropout))\n",
      "  40:     model.add(Dense(512))\n",
      "  41:     model.add(BatchNormalization())\n",
      "  42:     model.add(Activation('relu'))\n",
      "  43:     if Ndrop==3:\n",
      "  44:         model.add(Dropout(dropout))\n",
      "  45:     model.add(Dense(120,activation='softmax'))\n",
      "  46:     #model.add(Conv2D(10,(3,3)))\n",
      "  47:     #model.add(GlobalAveragePooling2D('none'))\n",
      "  48:     \n",
      "  49:     \n",
      "  50:     #predictions = Dense(num_class, activation='softmax')(x)\n",
      "  51: \n",
      "  52:     # This is the model we will train\n",
      "  53:     #model = Model(inputs=base_model.input, outputs=predictions)\n",
      "  54: \n",
      "  55:     # First: train only the top layers (which were randomly initialized)\n",
      "  56:     #for i in range(len(base_model.layers)):\n",
      "  57:     #    base_model.layers[i].trainable = False\n",
      "  58: \n",
      "  59:     # predetermined optimizer\n",
      "  60:     lr=0.00020389590556056983;\n",
      "  61:     beta_1=0.9453158868247398;\n",
      "  62:     beta_2=0.9925872692991417;\n",
      "  63:     decay=0.000821336141287018;\n",
      "  64:     adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
      "  65:     model.compile(loss='categorical_crossentropy', \n",
      "  66:                   optimizer=adam, \n",
      "  67:                   metrics=['accuracy'])\n",
      "  68: \n",
      "  69:     callbacks_list = [];\n",
      "  70:     callbacks_list.append(keras.callbacks.EarlyStopping(\n",
      "  71:         monitor='val_acc',\n",
      "  72:         patience=10,\n",
      "  73:         verbose=1));\n",
      "  74: \n",
      "  75: \n",
      "  76:     # data augmentation & fitting\n",
      "  77:     datagen = ImageDataGenerator(\n",
      "  78:         rotation_range=30,\n",
      "  79:         width_shift_range=0.1,\n",
      "  80:         height_shift_range=0.1,\n",
      "  81:         shear_range=0.5,\n",
      "  82:         zoom_range=0.5,\n",
      "  83:         horizontal_flip=True,\n",
      "  84:         vertical_flip=True);\n",
      "  85:     \n",
      "  86:     model.fit_generator(\n",
      "  87:         datagen.flow(X_train,Y_train,batch_size=batchSize),\n",
      "  88:         steps_per_epoch=stepsPerEpoch,\n",
      "  89:         epochs=150,\n",
      "  90:         verbose=1,\n",
      "  91:         validation_data=(X_valid,Y_valid),\n",
      "  92:         workers=2,\n",
      "  93:         shuffle=True,\n",
      "  94:         callbacks=callbacks_list)\n",
      "  95: #     model.fit(X_train, Y_train,\n",
      "  96: #       epochs=100,\n",
      "  97: #       batch_size = batchSize,\n",
      "  98: #       validation_data=(X_valid, Y_valid),\n",
      "  99: #       verbose=1,\n",
      " 100: #       callbacks=callbacks_list)\n",
      " 101: \n",
      " 102:     score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
      " 103:     print('Test accuracy:', acc)\n",
      " 104:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      " 105: \n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:30<00:00, 338.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "Creating model\n",
      "\n",
      "dropout= 0.6185581297159211\n",
      "Ndrop= 1\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 4.8537 - acc: 0.0223 - val_loss: 5.6346 - val_acc: 0.0091\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.5180 - acc: 0.0352 - val_loss: 5.7979 - val_acc: 0.0160\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.3800 - acc: 0.0530 - val_loss: 5.7888 - val_acc: 0.0130\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 4.2931 - acc: 0.0654 - val_loss: 5.5353 - val_acc: 0.0300\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 4.2321 - acc: 0.0681 - val_loss: 5.3637 - val_acc: 0.0316\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.1808 - acc: 0.0722 - val_loss: 5.3780 - val_acc: 0.0339\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.1290 - acc: 0.0820 - val_loss: 5.5860 - val_acc: 0.0300\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.0778 - acc: 0.0937 - val_loss: 5.5881 - val_acc: 0.0300\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.0453 - acc: 0.0913 - val_loss: 5.7058 - val_acc: 0.0297\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 4.0104 - acc: 0.0989 - val_loss: 5.6812 - val_acc: 0.0320\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 3.9681 - acc: 0.1041 - val_loss: 5.6311 - val_acc: 0.0346\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.9220 - acc: 0.1122 - val_loss: 5.6081 - val_acc: 0.0401\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.9066 - acc: 0.1164 - val_loss: 5.6811 - val_acc: 0.0385\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 3.8638 - acc: 0.1268 - val_loss: 5.6317 - val_acc: 0.0349\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 3.8652 - acc: 0.1204 - val_loss: 5.5811 - val_acc: 0.0391\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.8237 - acc: 0.1312 - val_loss: 5.5590 - val_acc: 0.0375\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 3.8098 - acc: 0.1283 - val_loss: 5.6409 - val_acc: 0.0372\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.7672 - acc: 0.1395 - val_loss: 5.6065 - val_acc: 0.0391\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.7573 - acc: 0.1405 - val_loss: 5.8225 - val_acc: 0.0362\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.7318 - acc: 0.1526 - val_loss: 5.6856 - val_acc: 0.0368\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 3.7195 - acc: 0.1448 - val_loss: 5.6802 - val_acc: 0.0359\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 19s 171ms/step - loss: 3.7225 - acc: 0.1480 - val_loss: 5.6375 - val_acc: 0.0385\n",
      "Epoch 00022: early stopping\n",
      "Test accuracy: 0.0384740789069\n",
      "Creating model\n",
      "\n",
      "dropout= 0.5919044302149167\n",
      "Ndrop= 2\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 21s 186ms/step - loss: 4.9172 - acc: 0.0178 - val_loss: 5.5728 - val_acc: 0.0065\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.6017 - acc: 0.0308 - val_loss: 5.9920 - val_acc: 0.0078\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.4970 - acc: 0.0402 - val_loss: 5.8101 - val_acc: 0.0130\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.4028 - acc: 0.0471 - val_loss: 5.4420 - val_acc: 0.0290\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.3348 - acc: 0.0563 - val_loss: 5.1153 - val_acc: 0.0212\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 20s 174ms/step - loss: 4.2864 - acc: 0.0600 - val_loss: 4.9672 - val_acc: 0.0300\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 19s 174ms/step - loss: 4.2411 - acc: 0.0663 - val_loss: 4.8664 - val_acc: 0.0323\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 19s 174ms/step - loss: 4.2029 - acc: 0.0695 - val_loss: 4.9071 - val_acc: 0.0300\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.1595 - acc: 0.0770 - val_loss: 4.8952 - val_acc: 0.0284\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.1327 - acc: 0.0759 - val_loss: 4.9644 - val_acc: 0.0297\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.0991 - acc: 0.0894 - val_loss: 4.9025 - val_acc: 0.0375\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 4.0738 - acc: 0.0905 - val_loss: 4.8650 - val_acc: 0.0352\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.0261 - acc: 0.1007 - val_loss: 4.8403 - val_acc: 0.0398\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 4.0215 - acc: 0.1016 - val_loss: 4.8787 - val_acc: 0.0346\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.9891 - acc: 0.1030 - val_loss: 4.9104 - val_acc: 0.0375\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 19s 172ms/step - loss: 3.9571 - acc: 0.1047 - val_loss: 4.8555 - val_acc: 0.0385\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.9550 - acc: 0.1090 - val_loss: 4.9042 - val_acc: 0.0388\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.9312 - acc: 0.1100 - val_loss: 5.0432 - val_acc: 0.0339\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.9228 - acc: 0.1108 - val_loss: 5.1010 - val_acc: 0.0346\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.9109 - acc: 0.1146 - val_loss: 5.1998 - val_acc: 0.0336\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.8869 - acc: 0.1166 - val_loss: 5.0645 - val_acc: 0.0372\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.8737 - acc: 0.1204 - val_loss: 4.9342 - val_acc: 0.0427\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.8541 - acc: 0.1229 - val_loss: 4.8609 - val_acc: 0.0479\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 19s 174ms/step - loss: 3.8393 - acc: 0.1266 - val_loss: 5.0229 - val_acc: 0.0430\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.8078 - acc: 0.1297 - val_loss: 4.8713 - val_acc: 0.0470\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 19s 174ms/step - loss: 3.8185 - acc: 0.1305 - val_loss: 4.8635 - val_acc: 0.0483\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 20s 178ms/step - loss: 3.8037 - acc: 0.1297 - val_loss: 4.9604 - val_acc: 0.0476\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 19s 174ms/step - loss: 3.7835 - acc: 0.1363 - val_loss: 4.8536 - val_acc: 0.0515\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 20s 175ms/step - loss: 3.7790 - acc: 0.1365 - val_loss: 4.8147 - val_acc: 0.0522\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 20s 175ms/step - loss: 3.7764 - acc: 0.1383 - val_loss: 4.7700 - val_acc: 0.0561\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 20s 175ms/step - loss: 3.7692 - acc: 0.1411 - val_loss: 4.8395 - val_acc: 0.0551\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.7561 - acc: 0.1410 - val_loss: 4.7840 - val_acc: 0.0548\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.7450 - acc: 0.1413 - val_loss: 4.8827 - val_acc: 0.0489\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 19s 173ms/step - loss: 3.7286 - acc: 0.1467 - val_loss: 4.7234 - val_acc: 0.0577\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 20s 174ms/step - loss: 3.7321 - acc: 0.1461 - val_loss: 4.8464 - val_acc: 0.0518\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 20s 176ms/step - loss: 3.7266 - acc: 0.1385 - val_loss: 4.7626 - val_acc: 0.0545\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 20s 175ms/step - loss: 3.6867 - acc: 0.1523 - val_loss: 4.7204 - val_acc: 0.0551\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 20s 174ms/step - loss: 3.6922 - acc: 0.1533 - val_loss: 4.7121 - val_acc: 0.0577\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 20s 175ms/step - loss: 3.6853 - acc: 0.1489 - val_loss: 4.7548 - val_acc: 0.0567\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 20s 175ms/step - loss: 3.6813 - acc: 0.1510 - val_loss: 4.7455 - val_acc: 0.0561\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 3.6758 - acc: 0.1545 - val_loss: 4.7078 - val_acc: 0.0587\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.6649 - acc: 0.1567 - val_loss: 4.8056 - val_acc: 0.0558\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.6642 - acc: 0.1546 - val_loss: 4.7746 - val_acc: 0.0558\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 3.6631 - acc: 0.1547 - val_loss: 4.7042 - val_acc: 0.0619\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 3.6444 - acc: 0.1589 - val_loss: 4.7257 - val_acc: 0.0597\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.6291 - acc: 0.1617 - val_loss: 4.7021 - val_acc: 0.0600\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.6272 - acc: 0.1584 - val_loss: 4.7118 - val_acc: 0.0577\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.6351 - acc: 0.1542 - val_loss: 4.6874 - val_acc: 0.0606\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.6160 - acc: 0.1638 - val_loss: 4.7285 - val_acc: 0.0613\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.6003 - acc: 0.1671 - val_loss: 4.7458 - val_acc: 0.0564\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 3.6181 - acc: 0.1608 - val_loss: 4.6629 - val_acc: 0.0603\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.5874 - acc: 0.1669 - val_loss: 4.7280 - val_acc: 0.0571\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.5942 - acc: 0.1682 - val_loss: 4.7350 - val_acc: 0.0590\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 3.5895 - acc: 0.1632 - val_loss: 4.6939 - val_acc: 0.0590\n",
      "Epoch 00054: early stopping\n",
      "Test accuracy: 0.0590153244261\n",
      "Creating model\n",
      "\n",
      "dropout= 0.5688131904706821\n",
      "Ndrop= 3\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 5.4623 - acc: 0.0145 - val_loss: 5.2518 - val_acc: 0.0082\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 5.1309 - acc: 0.0202 - val_loss: 5.6776 - val_acc: 0.0134\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.9945 - acc: 0.0221 - val_loss: 5.4964 - val_acc: 0.0124\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.8874 - acc: 0.0266 - val_loss: 5.2069 - val_acc: 0.0134\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 4.8079 - acc: 0.0292 - val_loss: 5.0992 - val_acc: 0.0147\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 4.7500 - acc: 0.0343 - val_loss: 4.8342 - val_acc: 0.0245\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.6737 - acc: 0.0376 - val_loss: 4.7809 - val_acc: 0.0251\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.6413 - acc: 0.0365 - val_loss: 4.7663 - val_acc: 0.0290\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.5950 - acc: 0.0390 - val_loss: 4.7850 - val_acc: 0.0284\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.5754 - acc: 0.0416 - val_loss: 4.7932 - val_acc: 0.0251\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 4.5401 - acc: 0.0406 - val_loss: 4.8366 - val_acc: 0.0280\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 4.5307 - acc: 0.0452 - val_loss: 4.7568 - val_acc: 0.0313\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.4868 - acc: 0.0443 - val_loss: 4.8944 - val_acc: 0.0284\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.4668 - acc: 0.0479 - val_loss: 4.7280 - val_acc: 0.0313\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 4.4584 - acc: 0.0524 - val_loss: 4.8281 - val_acc: 0.0293\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 4.4503 - acc: 0.0537 - val_loss: 4.7942 - val_acc: 0.0310\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.4143 - acc: 0.0525 - val_loss: 4.7194 - val_acc: 0.0333\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.4118 - acc: 0.0516 - val_loss: 4.7763 - val_acc: 0.0303\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 4.4135 - acc: 0.0504 - val_loss: 4.8052 - val_acc: 0.0303\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.3621 - acc: 0.0582 - val_loss: 4.9144 - val_acc: 0.0303\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.3616 - acc: 0.0600 - val_loss: 4.8951 - val_acc: 0.0323\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 4.3323 - acc: 0.0605 - val_loss: 4.7874 - val_acc: 0.0359\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.3163 - acc: 0.0604 - val_loss: 4.8205 - val_acc: 0.0320\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 4.3223 - acc: 0.0599 - val_loss: 4.8291 - val_acc: 0.0362\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.2988 - acc: 0.0640 - val_loss: 4.8472 - val_acc: 0.0372\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.2994 - acc: 0.0596 - val_loss: 4.8153 - val_acc: 0.0401\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.2953 - acc: 0.0646 - val_loss: 4.7366 - val_acc: 0.0427\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 4.2727 - acc: 0.0675 - val_loss: 4.7466 - val_acc: 0.0434\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.2454 - acc: 0.0675 - val_loss: 4.7902 - val_acc: 0.0443\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 4.2506 - acc: 0.0716 - val_loss: 4.7749 - val_acc: 0.0437\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 4.2425 - acc: 0.0709 - val_loss: 4.7795 - val_acc: 0.0414\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.2246 - acc: 0.0696 - val_loss: 4.8860 - val_acc: 0.0414\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 4.2156 - acc: 0.0738 - val_loss: 4.8711 - val_acc: 0.0408\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.2237 - acc: 0.0693 - val_loss: 4.6831 - val_acc: 0.0476\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 4.1973 - acc: 0.0698 - val_loss: 4.8532 - val_acc: 0.0430\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 4.2016 - acc: 0.0772 - val_loss: 4.8502 - val_acc: 0.0456\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 4.1900 - acc: 0.0811 - val_loss: 4.7618 - val_acc: 0.0476\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.2047 - acc: 0.0735 - val_loss: 4.9516 - val_acc: 0.0414\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 4.1707 - acc: 0.0794 - val_loss: 4.7568 - val_acc: 0.0502\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.1708 - acc: 0.0769 - val_loss: 4.8288 - val_acc: 0.0466\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.1466 - acc: 0.0792 - val_loss: 4.8488 - val_acc: 0.0463\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 26s 236ms/step - loss: 4.1748 - acc: 0.0743 - val_loss: 4.7202 - val_acc: 0.0538\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.1495 - acc: 0.0753 - val_loss: 4.7987 - val_acc: 0.0483\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.1585 - acc: 0.0797 - val_loss: 4.7559 - val_acc: 0.0518\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 4.1345 - acc: 0.0832 - val_loss: 4.8174 - val_acc: 0.0476\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 4.1185 - acc: 0.0840 - val_loss: 4.9189 - val_acc: 0.0466\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 4.1272 - acc: 0.0828 - val_loss: 4.8215 - val_acc: 0.0483\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 4.1223 - acc: 0.0856 - val_loss: 4.7884 - val_acc: 0.0492\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.1193 - acc: 0.0784 - val_loss: 4.7747 - val_acc: 0.0486\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.1182 - acc: 0.0867 - val_loss: 4.7769 - val_acc: 0.0522\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 4.1060 - acc: 0.0849 - val_loss: 4.7549 - val_acc: 0.0525\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 4.0916 - acc: 0.0801 - val_loss: 4.7805 - val_acc: 0.0512\n",
      "Epoch 00052: early stopping\n",
      "Test accuracy: 0.0511900880412\n",
      "Creating model\n",
      "\n",
      "dropout= 0.4130399015559423\n",
      "Ndrop= 2\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 4.8401 - acc: 0.0226 - val_loss: 5.1619 - val_acc: 0.0124\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.4956 - acc: 0.0397 - val_loss: 5.5489 - val_acc: 0.0108\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 4.3768 - acc: 0.0573 - val_loss: 5.3829 - val_acc: 0.0134\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.2980 - acc: 0.0614 - val_loss: 4.9933 - val_acc: 0.0267\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.2270 - acc: 0.0650 - val_loss: 4.9599 - val_acc: 0.0290\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.1689 - acc: 0.0778 - val_loss: 4.7097 - val_acc: 0.0385\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.1248 - acc: 0.0829 - val_loss: 4.7703 - val_acc: 0.0368\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 4.0802 - acc: 0.0901 - val_loss: 4.7364 - val_acc: 0.0417\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.0364 - acc: 0.0975 - val_loss: 4.8210 - val_acc: 0.0434\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 25s 228ms/step - loss: 4.0041 - acc: 0.1017 - val_loss: 4.7268 - val_acc: 0.0460\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.9799 - acc: 0.0994 - val_loss: 4.7411 - val_acc: 0.0466\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.9248 - acc: 0.1114 - val_loss: 4.7189 - val_acc: 0.0470\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.9060 - acc: 0.1169 - val_loss: 4.7603 - val_acc: 0.0470\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 3.8706 - acc: 0.1192 - val_loss: 4.6855 - val_acc: 0.0502\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 3.8527 - acc: 0.1221 - val_loss: 4.6757 - val_acc: 0.0574\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.8331 - acc: 0.1270 - val_loss: 4.7578 - val_acc: 0.0538\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.7976 - acc: 0.1316 - val_loss: 4.6294 - val_acc: 0.0603\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.7788 - acc: 0.1301 - val_loss: 4.6249 - val_acc: 0.0584\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.7506 - acc: 0.1466 - val_loss: 4.7046 - val_acc: 0.0558\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.7517 - acc: 0.1406 - val_loss: 4.7753 - val_acc: 0.0554\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.7333 - acc: 0.1444 - val_loss: 4.5346 - val_acc: 0.0619\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.7094 - acc: 0.1482 - val_loss: 4.5691 - val_acc: 0.0623\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 3.6908 - acc: 0.1512 - val_loss: 4.6859 - val_acc: 0.0564\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.6812 - acc: 0.1498 - val_loss: 4.6065 - val_acc: 0.0623\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.6600 - acc: 0.1608 - val_loss: 4.6318 - val_acc: 0.0619\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.6512 - acc: 0.1606 - val_loss: 4.6545 - val_acc: 0.0603\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.6342 - acc: 0.1634 - val_loss: 4.6326 - val_acc: 0.0639\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.6190 - acc: 0.1596 - val_loss: 4.6103 - val_acc: 0.0633\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 3.6051 - acc: 0.1634 - val_loss: 4.5403 - val_acc: 0.0675\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.5923 - acc: 0.1683 - val_loss: 4.6399 - val_acc: 0.0633\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.5841 - acc: 0.1725 - val_loss: 4.6193 - val_acc: 0.0633\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.5589 - acc: 0.1767 - val_loss: 4.6627 - val_acc: 0.0649\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.5451 - acc: 0.1814 - val_loss: 4.5076 - val_acc: 0.0698\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 3.5542 - acc: 0.1808 - val_loss: 4.6479 - val_acc: 0.0678\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.5313 - acc: 0.1790 - val_loss: 4.5943 - val_acc: 0.0708\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.5267 - acc: 0.1836 - val_loss: 4.6900 - val_acc: 0.0629\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.5007 - acc: 0.1884 - val_loss: 4.6102 - val_acc: 0.0704\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 3.4842 - acc: 0.1836 - val_loss: 4.5970 - val_acc: 0.0694\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.4990 - acc: 0.1898 - val_loss: 4.6264 - val_acc: 0.0691\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.4718 - acc: 0.1877 - val_loss: 4.6090 - val_acc: 0.0678\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.4702 - acc: 0.1905 - val_loss: 4.6226 - val_acc: 0.0665\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.4615 - acc: 0.1950 - val_loss: 4.5647 - val_acc: 0.0685\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.4689 - acc: 0.1873 - val_loss: 4.4666 - val_acc: 0.0769\n",
      "Epoch 44/150\n",
      "100/112 [=========================>....] - ETA: 2s - loss: 3.4359 - acc: 0.1915"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-43118546d7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                           notebook_name='NewModelOptimization_1')\n\u001b[0m",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                      verbose=verbose)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2017-dlai-team4/code/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2081\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_project/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='NewModelOptimization_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "val_loss, val_acc = best_model.evaluate(X_test, Y_test);\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(\"Validation loss: \", val_loss)\n",
    "print(\"Validation accuracy: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(modelPath+modelName);\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame(preds)\n",
    "# # Set column names to those generated by the one-hot encoding earlier\n",
    "# col_names = one_hot.columns.values\n",
    "# sub.columns = col_names\n",
    "# # Insert the column id from the sample_submission at the start of the data frame\n",
    "# sub.insert(0, 'id', df_test['id'])\n",
    "# sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
