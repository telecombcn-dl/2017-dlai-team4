{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# parameters #\n",
    "##############\n",
    "# dontFreezeLast = 0;\n",
    "\n",
    "# patience = 10;\n",
    "\n",
    "# gpuName = '/device:GPU:0'\n",
    "# workers = 2;\n",
    "# histogram_freq = 0;\n",
    "\n",
    "# epochs = 100;\n",
    "# validation_size=0.3;\n",
    "\n",
    "modelPath = '../models/VGG16_opt/';\n",
    "modelName = 'run3.h5';\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will read in the csv's so we can see some more information on the filenames and breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('../input/labels.csv')\n",
    "# df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "# print('Training images: ',df_train.shape[0])\n",
    "# print('Test images: ',df_test.shape[0])\n",
    "\n",
    "# reduce dimensionality\n",
    "#df_train = df_train.head(100)\n",
    "#df_test = df_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the breed needs to be one-hot encoded for the final submission, so we will now do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_series = pd.Series(df_train['breed'])\n",
    "# one_hot = pd.get_dummies(targets_series, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the images for test and train, using a for loop through the values of the csv files. I have also set an im_size variable which sets the size for the image to be re-sized to, 90x90 px, you should play with this number to see how it affects accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0 \n",
    "# for f, breed in tqdm(df_train.values[:10]):\n",
    "#     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "#     label = one_hot_labels[i]\n",
    "#     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "#     y_train.append(label)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in tqdm(df_test['id'].values):\n",
    "#     img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    "#     x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_raw = np.array(y_train, np.uint8)\n",
    "# x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "# x_test  = np.array(x_test, np.float32) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the shape of the outputs to make sure everyting went as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train_raw.shape)\n",
    "# print(y_train_raw.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 120 different breeds. We can put this in a num_class variable below that can then be used when creating the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = y_train_raw.shape[1]\n",
    "# print('Number of classes: ', num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to create a validation set so that you can gauge the performance of your model on independent data, unseen to the model in training. We do this by splitting the current training set (x_train_raw) and the corresponding labels (y_train_raw) so that we set aside 30 % of the data at random and put these in validation sets (X_valid and Y_valid).\n",
    "\n",
    "* This split needs to be improved so that it contains images from every class, with 120 separate classes some can not be represented and so the validation score is not informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the CNN architecture. Here we are using a pre-trained model VGG19 which has already been trained to identify many different dog breeds (as well as a lot of other objects from the imagenet dataset see here for more information: http://image-net.org/about-overview). Unfortunately it doesn't seem possible to downlod the weights from within this kernel so make sure you set the weights argument to 'imagenet' and not None, as it currently is below.\n",
    "\n",
    "We then remove the final layer and instead replace it with a single dense layer with the number of nodes corresponding to the number of breed classes we have (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('Getting data')\n",
    "    df_train = pd.read_csv('../input/labels.csv')\n",
    "    df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "    \n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "    \n",
    "    im_size = 90;\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    i = 0 \n",
    "    for f, breed in tqdm(df_train.values):\n",
    "        img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
    "        label = one_hot_labels[i]\n",
    "        x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "        y_train.append(label)\n",
    "        i += 1\n",
    "    \n",
    "    y_train_raw = np.array(y_train, np.uint8)\n",
    "    x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "    num_class = y_train_raw.shape[1]\n",
    "    \n",
    "    print('Splitting into training/validation')\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and model for hyperas\n",
    "\n",
    "def model(X_train,Y_train,X_valid,Y_valid):\n",
    "    print('Creating model')\n",
    "    base_model = VGG16(weights = 'imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(im_size, im_size, 3))\n",
    "\n",
    "    dropout=0.6;\n",
    "    dontFreeze = 3;\n",
    "    batchSize = 64;\n",
    "    momentum=0.99;\n",
    "    #\n",
    "    lambda_l2 = {{uniform(0.000001,0.1)}};\n",
    "    bottleneckFlag = {{choice([True,False])}};\n",
    "    \n",
    "    print()\n",
    "    print('lambda_l2=',lambda_l2)\n",
    "    print('bottleneckFlag=',bottleneckFlag)\n",
    "    print()\n",
    "    \n",
    "    stepsPerEpoch = round( len(X_train)/batchSize );\n",
    "    \n",
    "    # Add a new top layer\n",
    "    x = base_model.output\n",
    "    x = BatchNormalization(axis=1,momentum=momentum)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Dense(2048,activation='relu',kernel_regularizer=l2(lambda_l2))(x)\n",
    "    if bottleneckFlag:\n",
    "        x = Dense(100,activation='relu')(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "    x = Dense(512,activation='relu')(x)\n",
    "    # in any case:\n",
    "    predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "    # This is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # First: train only the top layers (which were randomly initialized)\n",
    "    for i in range(len(base_model.layers)-dontFreeze):\n",
    "        base_model.layers[i].trainable = False\n",
    "\n",
    "    # predetermined optimizer\n",
    "    lr=0.00020389590556056983;\n",
    "    beta_1=0.9453158868247398;\n",
    "    beta_2=0.9925872692991417;\n",
    "    decay=0.000821336141287018;\n",
    "    adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks_list = [];\n",
    "    callbacks_list.append(keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=10,\n",
    "        verbose=1));\n",
    "\n",
    "\n",
    "    # data augmentation & fitting\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True);\n",
    "    \n",
    "    model.fit_generator(\n",
    "        datagen.flow(X_train,Y_train,batch_size=batchSize),\n",
    "        steps_per_epoch=stepsPerEpoch,\n",
    "        epochs=150,\n",
    "        verbose=1,\n",
    "        validation_data=(X_valid,Y_valid),\n",
    "        workers=2,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks_list)\n",
    "#     model.fit(X_train, Y_train,\n",
    "#       epochs=100,\n",
    "#       batch_size = batchSize,\n",
    "#       validation_data=(X_valid, Y_valid),\n",
    "#       verbose=1,\n",
    "#       callbacks=callbacks_list)\n",
    "\n",
    "    score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.applications import VGG16\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from subprocess import check_output\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'lambda_l2': hp.uniform('lambda_l2', 0.000001,0.1),\n",
      "        'bottleneckFlag': hp.choice('bottleneckFlag', [True,False]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: print('Getting data')\n",
      "  3: df_train = pd.read_csv('../input/labels.csv')\n",
      "  4: df_test = pd.read_csv('../input/sample_submission.csv')\n",
      "  5: \n",
      "  6: targets_series = pd.Series(df_train['breed'])\n",
      "  7: one_hot = pd.get_dummies(targets_series, sparse = True)\n",
      "  8: one_hot_labels = np.asarray(one_hot)\n",
      "  9: \n",
      " 10: im_size = 90;\n",
      " 11: x_train = []\n",
      " 12: y_train = []\n",
      " 13: x_test = []\n",
      " 14: \n",
      " 15: i = 0 \n",
      " 16: for f, breed in tqdm(df_train.values):\n",
      " 17:     img = cv2.imread('../input/train/{}.jpg'.format(f))\n",
      " 18:     label = one_hot_labels[i]\n",
      " 19:     x_train.append(cv2.resize(img, (im_size, im_size)))\n",
      " 20:     y_train.append(label)\n",
      " 21:     i += 1\n",
      " 22: \n",
      " 23: y_train_raw = np.array(y_train, np.uint8)\n",
      " 24: x_train_raw = np.array(x_train, np.float32) / 255.\n",
      " 25: num_class = y_train_raw.shape[1]\n",
      " 26: \n",
      " 27: print('Splitting into training/validation')\n",
      " 28: X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
      " 29: \n",
      " 30: \n",
      " 31: \n",
      " 32: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print('Creating model')\n",
      "   4:     base_model = VGG16(weights = 'imagenet',\n",
      "   5:                        include_top=False,\n",
      "   6:                        input_shape=(im_size, im_size, 3))\n",
      "   7: \n",
      "   8:     dropout=0.6;\n",
      "   9:     dontFreeze = 3;\n",
      "  10:     batchSize = 64;\n",
      "  11:     momentum=0.99;\n",
      "  12:     #\n",
      "  13:     lambda_l2 = space['lambda_l2'];\n",
      "  14:     bottleneckFlag = space['bottleneckFlag'];\n",
      "  15:     \n",
      "  16:     print()\n",
      "  17:     print('lambda_l2=',lambda_l2)\n",
      "  18:     print('bottleneckFlag=',bottleneckFlag)\n",
      "  19:     print()\n",
      "  20:     \n",
      "  21:     stepsPerEpoch = round( len(X_train)/batchSize );\n",
      "  22:     \n",
      "  23:     # Add a new top layer\n",
      "  24:     x = base_model.output\n",
      "  25:     x = BatchNormalization(axis=1,momentum=momentum)(x)\n",
      "  26:     x = Flatten()(x)\n",
      "  27:     x = Dropout(dropout)(x)\n",
      "  28:     \n",
      "  29:     x = Dense(2048,activation='relu',kernel_regularizer=l2(lambda_l2))(x)\n",
      "  30:     if bottleneckFlag:\n",
      "  31:         x = Dense(100,activation='relu')(x)\n",
      "  32:     x = Dense(1024,activation='relu')(x)\n",
      "  33:     x = Dense(512,activation='relu')(x)\n",
      "  34:     # in any case:\n",
      "  35:     predictions = Dense(num_class, activation='softmax')(x)\n",
      "  36: \n",
      "  37:     # This is the model we will train\n",
      "  38:     model = Model(inputs=base_model.input, outputs=predictions)\n",
      "  39: \n",
      "  40:     # First: train only the top layers (which were randomly initialized)\n",
      "  41:     for i in range(len(base_model.layers)-dontFreeze):\n",
      "  42:         base_model.layers[i].trainable = False\n",
      "  43: \n",
      "  44:     # predetermined optimizer\n",
      "  45:     lr=0.00020389590556056983;\n",
      "  46:     beta_1=0.9453158868247398;\n",
      "  47:     beta_2=0.9925872692991417;\n",
      "  48:     decay=0.000821336141287018;\n",
      "  49:     adam = keras.optimizers.Adam(lr=lr,beta_1=beta_1,beta_2=beta_2,decay=decay)\n",
      "  50:     model.compile(loss='categorical_crossentropy', \n",
      "  51:                   optimizer=adam, \n",
      "  52:                   metrics=['accuracy'])\n",
      "  53: \n",
      "  54:     callbacks_list = [];\n",
      "  55:     callbacks_list.append(keras.callbacks.EarlyStopping(\n",
      "  56:         monitor='val_acc',\n",
      "  57:         patience=10,\n",
      "  58:         verbose=1));\n",
      "  59: \n",
      "  60: \n",
      "  61:     # data augmentation & fitting\n",
      "  62:     datagen = ImageDataGenerator(\n",
      "  63:         rotation_range=30,\n",
      "  64:         width_shift_range=0.1,\n",
      "  65:         height_shift_range=0.1,\n",
      "  66:         shear_range=0.5,\n",
      "  67:         zoom_range=0.5,\n",
      "  68:         horizontal_flip=True,\n",
      "  69:         vertical_flip=True);\n",
      "  70:     \n",
      "  71:     model.fit_generator(\n",
      "  72:         datagen.flow(X_train,Y_train,batch_size=batchSize),\n",
      "  73:         steps_per_epoch=stepsPerEpoch,\n",
      "  74:         epochs=150,\n",
      "  75:         verbose=1,\n",
      "  76:         validation_data=(X_valid,Y_valid),\n",
      "  77:         workers=2,\n",
      "  78:         shuffle=True,\n",
      "  79:         callbacks=callbacks_list)\n",
      "  80: #     model.fit(X_train, Y_train,\n",
      "  81: #       epochs=100,\n",
      "  82: #       batch_size = batchSize,\n",
      "  83: #       validation_data=(X_valid, Y_valid),\n",
      "  84: #       verbose=1,\n",
      "  85: #       callbacks=callbacks_list)\n",
      "  86: \n",
      "  87:     score, acc = model.evaluate(X_valid, Y_valid, verbose=0)\n",
      "  88:     print('Test accuracy:', acc)\n",
      "  89:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  90: \n",
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:59<00:00, 173.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training/validation\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.04371218882692479\n",
      "bottleneckFlag= True\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 45.5597 - acc: 0.0088 - val_loss: 16.4873 - val_acc: 0.0095\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 9.1804 - acc: 0.0102 - val_loss: 5.6495 - val_acc: 0.0098\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 5.0736 - acc: 0.0115 - val_loss: 4.8472 - val_acc: 0.0098\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.8119 - acc: 0.0121 - val_loss: 4.7795 - val_acc: 0.0153\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.7130 - acc: 0.0206 - val_loss: 4.6292 - val_acc: 0.0235\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 4.6083 - acc: 0.0269 - val_loss: 4.5212 - val_acc: 0.0271\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.5617 - acc: 0.0323 - val_loss: 4.4699 - val_acc: 0.0359\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 4.4637 - acc: 0.0358 - val_loss: 4.3509 - val_acc: 0.0408\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 4.4282 - acc: 0.0359 - val_loss: 4.3191 - val_acc: 0.0411\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.3903 - acc: 0.0390 - val_loss: 4.2812 - val_acc: 0.0437\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 4.3587 - acc: 0.0405 - val_loss: 4.2686 - val_acc: 0.0518\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.3392 - acc: 0.0481 - val_loss: 4.2402 - val_acc: 0.0541\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 4.2943 - acc: 0.0494 - val_loss: 4.1795 - val_acc: 0.0574\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.2576 - acc: 0.0567 - val_loss: 4.1502 - val_acc: 0.0593\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 4.2274 - acc: 0.0578 - val_loss: 4.1156 - val_acc: 0.0646\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 4.1887 - acc: 0.0611 - val_loss: 4.0813 - val_acc: 0.0760\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.1750 - acc: 0.0635 - val_loss: 4.0269 - val_acc: 0.0714\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 4.1134 - acc: 0.0684 - val_loss: 3.9750 - val_acc: 0.0789\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 4.0766 - acc: 0.0744 - val_loss: 3.9581 - val_acc: 0.0861\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 4.0472 - acc: 0.0781 - val_loss: 3.9209 - val_acc: 0.0910\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.0362 - acc: 0.0839 - val_loss: 3.8923 - val_acc: 0.0933\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.9769 - acc: 0.0886 - val_loss: 3.8458 - val_acc: 0.1056\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.9580 - acc: 0.0873 - val_loss: 3.8469 - val_acc: 0.1037\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 3.9606 - acc: 0.0909 - val_loss: 3.8374 - val_acc: 0.1004\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.9265 - acc: 0.0912 - val_loss: 3.8548 - val_acc: 0.1043\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.9225 - acc: 0.0920 - val_loss: 3.8033 - val_acc: 0.1144\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.9139 - acc: 0.0901 - val_loss: 3.7701 - val_acc: 0.1154\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.8665 - acc: 0.1063 - val_loss: 3.7679 - val_acc: 0.1154\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.8576 - acc: 0.1077 - val_loss: 3.7496 - val_acc: 0.1232\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.8446 - acc: 0.1108 - val_loss: 3.7221 - val_acc: 0.1275\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.8258 - acc: 0.1110 - val_loss: 3.7523 - val_acc: 0.1144\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.8137 - acc: 0.1151 - val_loss: 3.7100 - val_acc: 0.1307\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.8043 - acc: 0.1117 - val_loss: 3.7046 - val_acc: 0.1216\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.7970 - acc: 0.1160 - val_loss: 3.7152 - val_acc: 0.1236\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.7760 - acc: 0.1175 - val_loss: 3.7328 - val_acc: 0.1213\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.7545 - acc: 0.1242 - val_loss: 3.6779 - val_acc: 0.1259\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.7452 - acc: 0.1208 - val_loss: 3.6773 - val_acc: 0.1288\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.7279 - acc: 0.1216 - val_loss: 3.6544 - val_acc: 0.1396\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.7371 - acc: 0.1208 - val_loss: 3.6842 - val_acc: 0.1343\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.7203 - acc: 0.1272 - val_loss: 3.6830 - val_acc: 0.1376\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.6810 - acc: 0.1382 - val_loss: 3.6343 - val_acc: 0.1454\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.6965 - acc: 0.1358 - val_loss: 3.6444 - val_acc: 0.1457\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.6727 - acc: 0.1366 - val_loss: 3.6231 - val_acc: 0.1461\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.6652 - acc: 0.1429 - val_loss: 3.6188 - val_acc: 0.1477\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.6386 - acc: 0.1446 - val_loss: 3.6181 - val_acc: 0.1441\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.6499 - acc: 0.1404 - val_loss: 3.6234 - val_acc: 0.1396\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.6603 - acc: 0.1320 - val_loss: 3.6179 - val_acc: 0.1454\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.6198 - acc: 0.1466 - val_loss: 3.5737 - val_acc: 0.1536\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.6208 - acc: 0.1501 - val_loss: 3.6063 - val_acc: 0.1539\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.6165 - acc: 0.1431 - val_loss: 3.5852 - val_acc: 0.1484\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.5748 - acc: 0.1510 - val_loss: 3.5839 - val_acc: 0.1604\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.5776 - acc: 0.1520 - val_loss: 3.5778 - val_acc: 0.1467\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5777 - acc: 0.1556 - val_loss: 3.5889 - val_acc: 0.1565\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.5538 - acc: 0.1557 - val_loss: 3.5485 - val_acc: 0.1634\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.5408 - acc: 0.1614 - val_loss: 3.5456 - val_acc: 0.1653\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.5398 - acc: 0.1543 - val_loss: 3.5458 - val_acc: 0.1637\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.5441 - acc: 0.1624 - val_loss: 3.5480 - val_acc: 0.1692\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.5321 - acc: 0.1628 - val_loss: 3.5145 - val_acc: 0.1702\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.5048 - acc: 0.1676 - val_loss: 3.5430 - val_acc: 0.1738\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 29s 255ms/step - loss: 3.4969 - acc: 0.1660 - val_loss: 3.5138 - val_acc: 0.1692\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.4922 - acc: 0.1685 - val_loss: 3.5112 - val_acc: 0.1777\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.5076 - acc: 0.1697 - val_loss: 3.5106 - val_acc: 0.1793\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5004 - acc: 0.1643 - val_loss: 3.5187 - val_acc: 0.1705\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 3.4696 - acc: 0.1715 - val_loss: 3.5322 - val_acc: 0.1722\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.4577 - acc: 0.1751 - val_loss: 3.5098 - val_acc: 0.1718\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4773 - acc: 0.1695 - val_loss: 3.5245 - val_acc: 0.1787\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.4655 - acc: 0.1775 - val_loss: 3.4722 - val_acc: 0.1790\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.4479 - acc: 0.1738 - val_loss: 3.4994 - val_acc: 0.1774\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.4387 - acc: 0.1748 - val_loss: 3.5044 - val_acc: 0.1770\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.4452 - acc: 0.1726 - val_loss: 3.4925 - val_acc: 0.1842\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.4349 - acc: 0.1816 - val_loss: 3.4811 - val_acc: 0.1832\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.4237 - acc: 0.1798 - val_loss: 3.4794 - val_acc: 0.1813\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.4119 - acc: 0.1842 - val_loss: 3.4555 - val_acc: 0.1865\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.4059 - acc: 0.1827 - val_loss: 3.4652 - val_acc: 0.1937\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.4077 - acc: 0.1882 - val_loss: 3.4520 - val_acc: 0.1810\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.3961 - acc: 0.1859 - val_loss: 3.4431 - val_acc: 0.1868\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.3920 - acc: 0.1861 - val_loss: 3.4346 - val_acc: 0.1888\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3900 - acc: 0.1879 - val_loss: 3.4464 - val_acc: 0.1937\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.3613 - acc: 0.1926 - val_loss: 3.4447 - val_acc: 0.1881\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.3620 - acc: 0.1932 - val_loss: 3.4289 - val_acc: 0.1960\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3677 - acc: 0.1924 - val_loss: 3.4647 - val_acc: 0.1956\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.3698 - acc: 0.1900 - val_loss: 3.4444 - val_acc: 0.1960\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.3518 - acc: 0.1927 - val_loss: 3.4552 - val_acc: 0.1904\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.3498 - acc: 0.1937 - val_loss: 3.4498 - val_acc: 0.2012\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.3409 - acc: 0.1963 - val_loss: 3.4316 - val_acc: 0.1953\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.3290 - acc: 0.1949 - val_loss: 3.4691 - val_acc: 0.1904\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.3330 - acc: 0.1919 - val_loss: 3.4778 - val_acc: 0.1956\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.3372 - acc: 0.1944 - val_loss: 3.4146 - val_acc: 0.2015\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.3104 - acc: 0.1988 - val_loss: 3.4413 - val_acc: 0.1911\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 3.3053 - acc: 0.1958 - val_loss: 3.4330 - val_acc: 0.1999\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.3005 - acc: 0.2038 - val_loss: 3.4077 - val_acc: 0.1989\n",
      "Epoch 92/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.3039 - acc: 0.2012 - val_loss: 3.3979 - val_acc: 0.2044\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.2843 - acc: 0.2094 - val_loss: 3.4154 - val_acc: 0.2025\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.2984 - acc: 0.1997 - val_loss: 3.4387 - val_acc: 0.1992\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2835 - acc: 0.2035 - val_loss: 3.4447 - val_acc: 0.1989\n",
      "Epoch 96/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.2740 - acc: 0.2082 - val_loss: 3.4123 - val_acc: 0.2048\n",
      "Epoch 97/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2866 - acc: 0.2091 - val_loss: 3.4128 - val_acc: 0.2005\n",
      "Epoch 98/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2674 - acc: 0.2046 - val_loss: 3.3934 - val_acc: 0.2041\n",
      "Epoch 99/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.2734 - acc: 0.2005 - val_loss: 3.3760 - val_acc: 0.2103\n",
      "Epoch 100/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.2658 - acc: 0.2048 - val_loss: 3.3844 - val_acc: 0.2103\n",
      "Epoch 101/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.2645 - acc: 0.2039 - val_loss: 3.4110 - val_acc: 0.1963\n",
      "Epoch 102/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2638 - acc: 0.2084 - val_loss: 3.3979 - val_acc: 0.2031\n",
      "Epoch 103/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.2288 - acc: 0.2086 - val_loss: 3.4078 - val_acc: 0.2015\n",
      "Epoch 104/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.2528 - acc: 0.2101 - val_loss: 3.4115 - val_acc: 0.2057\n",
      "Epoch 105/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.2375 - acc: 0.2120 - val_loss: 3.3716 - val_acc: 0.2097\n",
      "Epoch 106/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.2458 - acc: 0.2124 - val_loss: 3.4019 - val_acc: 0.2070\n",
      "Epoch 107/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.2283 - acc: 0.2176 - val_loss: 3.4042 - val_acc: 0.2106\n",
      "Epoch 108/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.2108 - acc: 0.2232 - val_loss: 3.3859 - val_acc: 0.2132\n",
      "Epoch 109/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.2230 - acc: 0.2206 - val_loss: 3.4121 - val_acc: 0.2077\n",
      "Epoch 110/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.1988 - acc: 0.2194 - val_loss: 3.4049 - val_acc: 0.2136\n",
      "Epoch 111/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.2117 - acc: 0.2182 - val_loss: 3.3957 - val_acc: 0.2048\n",
      "Epoch 112/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.1723 - acc: 0.2274 - val_loss: 3.3987 - val_acc: 0.2035\n",
      "Epoch 113/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.1885 - acc: 0.2278 - val_loss: 3.4009 - val_acc: 0.2097\n",
      "Epoch 114/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.1920 - acc: 0.2210 - val_loss: 3.3656 - val_acc: 0.2175\n",
      "Epoch 115/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.1884 - acc: 0.2295 - val_loss: 3.3922 - val_acc: 0.2087\n",
      "Epoch 116/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.1778 - acc: 0.2267 - val_loss: 3.3911 - val_acc: 0.2097\n",
      "Epoch 117/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.1842 - acc: 0.2240 - val_loss: 3.3707 - val_acc: 0.2139\n",
      "Epoch 118/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.1747 - acc: 0.2232 - val_loss: 3.3869 - val_acc: 0.2113\n",
      "Epoch 119/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.1780 - acc: 0.2188 - val_loss: 3.3686 - val_acc: 0.2142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.1674 - acc: 0.2318 - val_loss: 3.4094 - val_acc: 0.2031\n",
      "Epoch 121/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.1731 - acc: 0.2231 - val_loss: 3.3559 - val_acc: 0.2155\n",
      "Epoch 122/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.1783 - acc: 0.2262 - val_loss: 3.3844 - val_acc: 0.2113\n",
      "Epoch 123/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.1524 - acc: 0.2253 - val_loss: 3.3625 - val_acc: 0.2145\n",
      "Epoch 124/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.1646 - acc: 0.2338 - val_loss: 3.3680 - val_acc: 0.2152\n",
      "Epoch 00124: early stopping\n",
      "Test accuracy: 0.215194000657\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.038381502234122906\n",
      "bottleneckFlag= False\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 44.1257 - acc: 0.0098 - val_loss: 18.6486 - val_acc: 0.0072\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 10.8983 - acc: 0.0125 - val_loss: 6.7333 - val_acc: 0.0114\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 5.7111 - acc: 0.0163 - val_loss: 5.1298 - val_acc: 0.0306\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 4.9408 - acc: 0.0246 - val_loss: 4.6954 - val_acc: 0.0417\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.6817 - acc: 0.0365 - val_loss: 4.5379 - val_acc: 0.0391\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.5092 - acc: 0.0472 - val_loss: 4.3138 - val_acc: 0.0639\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.3750 - acc: 0.0552 - val_loss: 4.2044 - val_acc: 0.0701\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 4.3008 - acc: 0.0715 - val_loss: 4.0941 - val_acc: 0.0844\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 4.2075 - acc: 0.0808 - val_loss: 4.0794 - val_acc: 0.0841\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 4.1399 - acc: 0.0883 - val_loss: 3.9726 - val_acc: 0.1092\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.1111 - acc: 0.0905 - val_loss: 3.9784 - val_acc: 0.1115\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.0580 - acc: 0.0985 - val_loss: 3.8614 - val_acc: 0.1216\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.9955 - acc: 0.1074 - val_loss: 3.8804 - val_acc: 0.1317\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.9760 - acc: 0.1085 - val_loss: 3.8097 - val_acc: 0.1340\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.9302 - acc: 0.1157 - val_loss: 3.7820 - val_acc: 0.1409\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.9162 - acc: 0.1198 - val_loss: 3.7864 - val_acc: 0.1431\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.8701 - acc: 0.1293 - val_loss: 3.7768 - val_acc: 0.1415\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.8498 - acc: 0.1350 - val_loss: 3.7271 - val_acc: 0.1454\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.8122 - acc: 0.1272 - val_loss: 3.6959 - val_acc: 0.1572\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.7870 - acc: 0.1403 - val_loss: 3.6708 - val_acc: 0.1598\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.7696 - acc: 0.1416 - val_loss: 3.7136 - val_acc: 0.1523\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.7415 - acc: 0.1437 - val_loss: 3.6502 - val_acc: 0.1709\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.7304 - acc: 0.1527 - val_loss: 3.6134 - val_acc: 0.1699\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.6940 - acc: 0.1530 - val_loss: 3.6007 - val_acc: 0.1624\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 3.6833 - acc: 0.1580 - val_loss: 3.6412 - val_acc: 0.1699\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.6599 - acc: 0.1641 - val_loss: 3.5909 - val_acc: 0.1761\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.6501 - acc: 0.1635 - val_loss: 3.5598 - val_acc: 0.1735\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.6300 - acc: 0.1650 - val_loss: 3.5477 - val_acc: 0.1826\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.5849 - acc: 0.1709 - val_loss: 3.5306 - val_acc: 0.1842\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.6022 - acc: 0.1661 - val_loss: 3.5472 - val_acc: 0.1816\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.5669 - acc: 0.1783 - val_loss: 3.5552 - val_acc: 0.1800\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.5621 - acc: 0.1740 - val_loss: 3.4902 - val_acc: 0.1875\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.5273 - acc: 0.1831 - val_loss: 3.5053 - val_acc: 0.2002\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.5115 - acc: 0.1898 - val_loss: 3.4847 - val_acc: 0.1930\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.5189 - acc: 0.1861 - val_loss: 3.5187 - val_acc: 0.1904\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.5020 - acc: 0.1868 - val_loss: 3.4688 - val_acc: 0.1989\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.4872 - acc: 0.1927 - val_loss: 3.4579 - val_acc: 0.2080\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.4668 - acc: 0.1977 - val_loss: 3.4744 - val_acc: 0.2038\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.4363 - acc: 0.2010 - val_loss: 3.4850 - val_acc: 0.2018\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.4406 - acc: 0.1984 - val_loss: 3.4714 - val_acc: 0.2106\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.4233 - acc: 0.1986 - val_loss: 3.4736 - val_acc: 0.2018\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.4169 - acc: 0.2060 - val_loss: 3.4145 - val_acc: 0.2106\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.3872 - acc: 0.2056 - val_loss: 3.4420 - val_acc: 0.2083\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.3960 - acc: 0.2075 - val_loss: 3.4572 - val_acc: 0.1995\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.3764 - acc: 0.2137 - val_loss: 3.4076 - val_acc: 0.2100\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.3678 - acc: 0.2079 - val_loss: 3.4455 - val_acc: 0.2090\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.3349 - acc: 0.2125 - val_loss: 3.4068 - val_acc: 0.2149\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.3374 - acc: 0.2176 - val_loss: 3.4031 - val_acc: 0.2158\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.3119 - acc: 0.2258 - val_loss: 3.4032 - val_acc: 0.2110\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 3.3098 - acc: 0.2245 - val_loss: 3.4260 - val_acc: 0.2175\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.3204 - acc: 0.2162 - val_loss: 3.3820 - val_acc: 0.2282\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.2919 - acc: 0.2244 - val_loss: 3.3586 - val_acc: 0.2292\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.3003 - acc: 0.2249 - val_loss: 3.4551 - val_acc: 0.2116\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 29s 257ms/step - loss: 3.2842 - acc: 0.2283 - val_loss: 3.3733 - val_acc: 0.2198\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.2587 - acc: 0.2235 - val_loss: 3.3909 - val_acc: 0.2211\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.2550 - acc: 0.2332 - val_loss: 3.3728 - val_acc: 0.2207\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.2485 - acc: 0.2282 - val_loss: 3.3965 - val_acc: 0.2243\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 3.2390 - acc: 0.2341 - val_loss: 3.3468 - val_acc: 0.2256\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.2269 - acc: 0.2377 - val_loss: 3.3918 - val_acc: 0.2286\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2056 - acc: 0.2416 - val_loss: 3.3579 - val_acc: 0.2312\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.2166 - acc: 0.2444 - val_loss: 3.4100 - val_acc: 0.2256\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.2067 - acc: 0.2391 - val_loss: 3.3610 - val_acc: 0.2321\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.1882 - acc: 0.2426 - val_loss: 3.3712 - val_acc: 0.2328\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.1856 - acc: 0.2429 - val_loss: 3.3830 - val_acc: 0.2273\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.1718 - acc: 0.2489 - val_loss: 3.3829 - val_acc: 0.2282\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.1604 - acc: 0.2491 - val_loss: 3.3713 - val_acc: 0.2292\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.1577 - acc: 0.2556 - val_loss: 3.3599 - val_acc: 0.2377\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.1630 - acc: 0.2506 - val_loss: 3.3933 - val_acc: 0.2207\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 3.1479 - acc: 0.2569 - val_loss: 3.3424 - val_acc: 0.2364\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.1335 - acc: 0.2524 - val_loss: 3.3661 - val_acc: 0.2344\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.1287 - acc: 0.2549 - val_loss: 3.3464 - val_acc: 0.2331\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.1209 - acc: 0.2620 - val_loss: 3.3449 - val_acc: 0.2406\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.1186 - acc: 0.2586 - val_loss: 3.3647 - val_acc: 0.2374\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.1231 - acc: 0.2537 - val_loss: 3.3560 - val_acc: 0.2361\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.1115 - acc: 0.2571 - val_loss: 3.3557 - val_acc: 0.2348\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.0859 - acc: 0.2559 - val_loss: 3.3795 - val_acc: 0.2315\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.1028 - acc: 0.2619 - val_loss: 3.3253 - val_acc: 0.2390\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.0801 - acc: 0.2680 - val_loss: 3.3344 - val_acc: 0.2400\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.0727 - acc: 0.2671 - val_loss: 3.3442 - val_acc: 0.2331\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.0542 - acc: 0.2663 - val_loss: 3.3467 - val_acc: 0.2354\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.0645 - acc: 0.2587 - val_loss: 3.3252 - val_acc: 0.2442\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.0501 - acc: 0.2734 - val_loss: 3.3302 - val_acc: 0.2370\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.0296 - acc: 0.2744 - val_loss: 3.3586 - val_acc: 0.2338\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.0251 - acc: 0.2713 - val_loss: 3.3459 - val_acc: 0.2400\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.0203 - acc: 0.2775 - val_loss: 3.3092 - val_acc: 0.2436\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.0073 - acc: 0.2765 - val_loss: 3.3378 - val_acc: 0.2452\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.0216 - acc: 0.2770 - val_loss: 3.3455 - val_acc: 0.2419\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.0024 - acc: 0.2797 - val_loss: 3.3168 - val_acc: 0.2403\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.0270 - acc: 0.2790 - val_loss: 3.2946 - val_acc: 0.2475\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 2.9986 - acc: 0.2809 - val_loss: 3.3296 - val_acc: 0.2432\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 2.9856 - acc: 0.2806 - val_loss: 3.3106 - val_acc: 0.2488\n",
      "Epoch 92/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 2.9943 - acc: 0.2804 - val_loss: 3.2997 - val_acc: 0.2462\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 2.9810 - acc: 0.2871 - val_loss: 3.3085 - val_acc: 0.2514\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 2.9823 - acc: 0.2832 - val_loss: 3.3325 - val_acc: 0.2406\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 2.9675 - acc: 0.2813 - val_loss: 3.3481 - val_acc: 0.2393\n",
      "Epoch 96/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 2.9604 - acc: 0.2912 - val_loss: 3.3397 - val_acc: 0.2419\n",
      "Epoch 97/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 2.9594 - acc: 0.2876 - val_loss: 3.3367 - val_acc: 0.2445\n",
      "Epoch 98/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 2.9566 - acc: 0.2965 - val_loss: 3.3348 - val_acc: 0.2475\n",
      "Epoch 99/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 2.9482 - acc: 0.2896 - val_loss: 3.3365 - val_acc: 0.2465\n",
      "Epoch 100/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 2.9599 - acc: 0.2871 - val_loss: 3.2956 - val_acc: 0.2485\n",
      "Epoch 101/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 2.9317 - acc: 0.2891 - val_loss: 3.3157 - val_acc: 0.2465\n",
      "Epoch 102/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 2.9277 - acc: 0.2948 - val_loss: 3.3456 - val_acc: 0.2445\n",
      "Epoch 103/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 2.9296 - acc: 0.2888 - val_loss: 3.3471 - val_acc: 0.2432\n",
      "Epoch 00103: early stopping\n",
      "Test accuracy: 0.24323443105\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.03376330046775549\n",
      "bottleneckFlag= True\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 36.4167 - acc: 0.0121 - val_loss: 13.9977 - val_acc: 0.0098\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 8.2945 - acc: 0.0119 - val_loss: 5.5160 - val_acc: 0.0098\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 5.0306 - acc: 0.0142 - val_loss: 4.7846 - val_acc: 0.0287\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 4.7212 - acc: 0.0180 - val_loss: 4.6257 - val_acc: 0.0173\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.6349 - acc: 0.0186 - val_loss: 4.5415 - val_acc: 0.0183\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 4.6021 - acc: 0.0212 - val_loss: 4.5369 - val_acc: 0.0205\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.5596 - acc: 0.0237 - val_loss: 4.4782 - val_acc: 0.0310\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.5088 - acc: 0.0295 - val_loss: 4.4278 - val_acc: 0.0359\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 4.4682 - acc: 0.0324 - val_loss: 4.3787 - val_acc: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.4225 - acc: 0.0367 - val_loss: 4.3153 - val_acc: 0.0463\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 4.3731 - acc: 0.0412 - val_loss: 4.2589 - val_acc: 0.0528\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 4.3349 - acc: 0.0486 - val_loss: 4.1917 - val_acc: 0.0593\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.2568 - acc: 0.0605 - val_loss: 4.1082 - val_acc: 0.0737\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 4.2022 - acc: 0.0603 - val_loss: 4.0757 - val_acc: 0.0727\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 4.1518 - acc: 0.0651 - val_loss: 4.0041 - val_acc: 0.0760\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 4.1040 - acc: 0.0722 - val_loss: 4.0058 - val_acc: 0.0711\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 4.0621 - acc: 0.0759 - val_loss: 3.9579 - val_acc: 0.0897\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.0317 - acc: 0.0788 - val_loss: 3.9119 - val_acc: 0.0959\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.9953 - acc: 0.0803 - val_loss: 3.8928 - val_acc: 0.1024\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 3.9902 - acc: 0.0861 - val_loss: 3.9294 - val_acc: 0.0900\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.9571 - acc: 0.0914 - val_loss: 3.8589 - val_acc: 0.0959\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.9396 - acc: 0.0917 - val_loss: 3.8534 - val_acc: 0.0975\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.9183 - acc: 0.0922 - val_loss: 3.8610 - val_acc: 0.1007\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.8976 - acc: 0.1001 - val_loss: 3.7647 - val_acc: 0.1092\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.8908 - acc: 0.0990 - val_loss: 3.7651 - val_acc: 0.1138\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.8582 - acc: 0.1055 - val_loss: 3.7632 - val_acc: 0.1177\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.8411 - acc: 0.1067 - val_loss: 3.7540 - val_acc: 0.1167\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 3.8274 - acc: 0.1081 - val_loss: 3.7546 - val_acc: 0.1249\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.8228 - acc: 0.1084 - val_loss: 3.7527 - val_acc: 0.1125\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.8250 - acc: 0.1133 - val_loss: 3.7237 - val_acc: 0.1187\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.7894 - acc: 0.1141 - val_loss: 3.7126 - val_acc: 0.1249\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.7636 - acc: 0.1204 - val_loss: 3.7754 - val_acc: 0.1118\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 3.7731 - acc: 0.1158 - val_loss: 3.7007 - val_acc: 0.1236\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.7440 - acc: 0.1227 - val_loss: 3.6703 - val_acc: 0.1350\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.7412 - acc: 0.1219 - val_loss: 3.6882 - val_acc: 0.1285\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.7345 - acc: 0.1258 - val_loss: 3.6701 - val_acc: 0.1226\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.7084 - acc: 0.1239 - val_loss: 3.6722 - val_acc: 0.1304\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.7168 - acc: 0.1267 - val_loss: 3.6936 - val_acc: 0.1321\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.6779 - acc: 0.1332 - val_loss: 3.6552 - val_acc: 0.1386\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.7013 - acc: 0.1301 - val_loss: 3.6329 - val_acc: 0.1415\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.6812 - acc: 0.1344 - val_loss: 3.6817 - val_acc: 0.1373\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.6844 - acc: 0.1344 - val_loss: 3.6250 - val_acc: 0.1431\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6367 - acc: 0.1382 - val_loss: 3.6713 - val_acc: 0.1327\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.6386 - acc: 0.1518 - val_loss: 3.6275 - val_acc: 0.1386\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.6365 - acc: 0.1383 - val_loss: 3.6438 - val_acc: 0.1379\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.6227 - acc: 0.1458 - val_loss: 3.6225 - val_acc: 0.1392\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 3.6057 - acc: 0.1494 - val_loss: 3.6511 - val_acc: 0.1438\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.6037 - acc: 0.1484 - val_loss: 3.5760 - val_acc: 0.1484\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.5966 - acc: 0.1462 - val_loss: 3.5707 - val_acc: 0.1601\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.5742 - acc: 0.1507 - val_loss: 3.6004 - val_acc: 0.1474\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.5617 - acc: 0.1504 - val_loss: 3.5686 - val_acc: 0.1510\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.5585 - acc: 0.1516 - val_loss: 3.5738 - val_acc: 0.1532\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.5584 - acc: 0.1550 - val_loss: 3.5998 - val_acc: 0.1497\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.5529 - acc: 0.1580 - val_loss: 3.5725 - val_acc: 0.1559\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.5304 - acc: 0.1591 - val_loss: 3.5739 - val_acc: 0.1588\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.5282 - acc: 0.1534 - val_loss: 3.6293 - val_acc: 0.1454\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.5273 - acc: 0.1611 - val_loss: 3.5652 - val_acc: 0.1601\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.4994 - acc: 0.1626 - val_loss: 3.5437 - val_acc: 0.1601\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.5017 - acc: 0.1634 - val_loss: 3.5800 - val_acc: 0.1627\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.4930 - acc: 0.1676 - val_loss: 3.6298 - val_acc: 0.1506\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.4782 - acc: 0.1665 - val_loss: 3.5409 - val_acc: 0.1666\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.4833 - acc: 0.1649 - val_loss: 3.5666 - val_acc: 0.1607\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 25s 228ms/step - loss: 3.4912 - acc: 0.1671 - val_loss: 3.5708 - val_acc: 0.1643\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.4705 - acc: 0.1695 - val_loss: 3.5137 - val_acc: 0.1702\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.4623 - acc: 0.1723 - val_loss: 3.5832 - val_acc: 0.1627\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.4316 - acc: 0.1735 - val_loss: 3.5386 - val_acc: 0.1614\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.4571 - acc: 0.1690 - val_loss: 3.5996 - val_acc: 0.1588\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.4387 - acc: 0.1790 - val_loss: 3.5273 - val_acc: 0.1669\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.4452 - acc: 0.1716 - val_loss: 3.5031 - val_acc: 0.1731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.4419 - acc: 0.1747 - val_loss: 3.4934 - val_acc: 0.1770\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.4085 - acc: 0.1794 - val_loss: 3.5188 - val_acc: 0.1699\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.4350 - acc: 0.1773 - val_loss: 3.4806 - val_acc: 0.1790\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.4125 - acc: 0.1783 - val_loss: 3.4836 - val_acc: 0.1806\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.4122 - acc: 0.1799 - val_loss: 3.5134 - val_acc: 0.1800\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.4025 - acc: 0.1857 - val_loss: 3.4625 - val_acc: 0.1832\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 30s 263ms/step - loss: 3.3844 - acc: 0.1908 - val_loss: 3.4756 - val_acc: 0.1800\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.3908 - acc: 0.1809 - val_loss: 3.5003 - val_acc: 0.1793\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.3719 - acc: 0.1846 - val_loss: 3.4962 - val_acc: 0.1770\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.3756 - acc: 0.1841 - val_loss: 3.5087 - val_acc: 0.1823\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3800 - acc: 0.1912 - val_loss: 3.4758 - val_acc: 0.1826\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.3790 - acc: 0.1868 - val_loss: 3.4448 - val_acc: 0.1845\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.3503 - acc: 0.1958 - val_loss: 3.4467 - val_acc: 0.1858\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 3.3545 - acc: 0.1920 - val_loss: 3.4602 - val_acc: 0.1829\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.3249 - acc: 0.1966 - val_loss: 3.4569 - val_acc: 0.1829\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.3325 - acc: 0.1982 - val_loss: 3.4578 - val_acc: 0.1927\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.3093 - acc: 0.1955 - val_loss: 3.4573 - val_acc: 0.1930\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 30s 263ms/step - loss: 3.3150 - acc: 0.1937 - val_loss: 3.4591 - val_acc: 0.1868\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.3129 - acc: 0.1996 - val_loss: 3.4760 - val_acc: 0.1842\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.3012 - acc: 0.2070 - val_loss: 3.5053 - val_acc: 0.1806\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.3360 - acc: 0.1912 - val_loss: 3.5021 - val_acc: 0.1757\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.3159 - acc: 0.1920 - val_loss: 3.4564 - val_acc: 0.1865\n",
      "Epoch 92/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.2966 - acc: 0.2026 - val_loss: 3.4542 - val_acc: 0.1979\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.2948 - acc: 0.1981 - val_loss: 3.5174 - val_acc: 0.1790\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.3051 - acc: 0.1999 - val_loss: 3.4252 - val_acc: 0.1937\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.2968 - acc: 0.2053 - val_loss: 3.4467 - val_acc: 0.1894\n",
      "Epoch 96/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.2862 - acc: 0.1982 - val_loss: 3.4584 - val_acc: 0.1872\n",
      "Epoch 97/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.2927 - acc: 0.2032 - val_loss: 3.4309 - val_acc: 0.1911\n",
      "Epoch 98/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.2642 - acc: 0.2079 - val_loss: 3.4730 - val_acc: 0.1865\n",
      "Epoch 99/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.2745 - acc: 0.2003 - val_loss: 3.4967 - val_acc: 0.1855\n",
      "Epoch 100/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.2657 - acc: 0.2068 - val_loss: 3.4345 - val_acc: 0.1904\n",
      "Epoch 101/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.2486 - acc: 0.2091 - val_loss: 3.4411 - val_acc: 0.1956\n",
      "Epoch 102/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2592 - acc: 0.2018 - val_loss: 3.4244 - val_acc: 0.1953\n",
      "Epoch 00102: early stopping\n",
      "Test accuracy: 0.195304858175\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.00260895423138534\n",
      "bottleneckFlag= False\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 9.4282 - acc: 0.0077 - val_loss: 8.4957 - val_acc: 0.0075\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 7.7287 - acc: 0.0116 - val_loss: 7.0207 - val_acc: 0.0150\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 6.5321 - acc: 0.0118 - val_loss: 6.0684 - val_acc: 0.0245\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 5.7612 - acc: 0.0203 - val_loss: 5.4133 - val_acc: 0.0333\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 5.2827 - acc: 0.0285 - val_loss: 5.0318 - val_acc: 0.0421\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 4.9653 - acc: 0.0437 - val_loss: 4.7348 - val_acc: 0.0567\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 4.7551 - acc: 0.0466 - val_loss: 4.5429 - val_acc: 0.0714\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.5872 - acc: 0.0635 - val_loss: 4.3920 - val_acc: 0.0864\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 4.4581 - acc: 0.0721 - val_loss: 4.3293 - val_acc: 0.0871\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.3728 - acc: 0.0750 - val_loss: 4.1944 - val_acc: 0.0919\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 4.2786 - acc: 0.0885 - val_loss: 4.1207 - val_acc: 0.1082\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.1867 - acc: 0.0999 - val_loss: 4.0531 - val_acc: 0.1197\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.1297 - acc: 0.1062 - val_loss: 3.9756 - val_acc: 0.1259\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 4.0674 - acc: 0.1160 - val_loss: 3.9573 - val_acc: 0.1272\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 4.0107 - acc: 0.1219 - val_loss: 3.8762 - val_acc: 0.1369\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.9791 - acc: 0.1261 - val_loss: 3.8870 - val_acc: 0.1435\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.9390 - acc: 0.1319 - val_loss: 3.8880 - val_acc: 0.1327\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.8949 - acc: 0.1310 - val_loss: 3.8253 - val_acc: 0.1389\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.8577 - acc: 0.1438 - val_loss: 3.7199 - val_acc: 0.1637\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.8222 - acc: 0.1490 - val_loss: 3.7502 - val_acc: 0.1562\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.7637 - acc: 0.1519 - val_loss: 3.7166 - val_acc: 0.1647\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.7380 - acc: 0.1595 - val_loss: 3.7295 - val_acc: 0.1585\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.7002 - acc: 0.1647 - val_loss: 3.6470 - val_acc: 0.1715\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.6754 - acc: 0.1675 - val_loss: 3.6793 - val_acc: 0.1666\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.6553 - acc: 0.1706 - val_loss: 3.6052 - val_acc: 0.1823\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.6130 - acc: 0.1743 - val_loss: 3.5734 - val_acc: 0.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.6022 - acc: 0.1734 - val_loss: 3.5761 - val_acc: 0.1842\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.5775 - acc: 0.1822 - val_loss: 3.5979 - val_acc: 0.1751\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.5328 - acc: 0.1913 - val_loss: 3.5598 - val_acc: 0.1885\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.5306 - acc: 0.1900 - val_loss: 3.6296 - val_acc: 0.1823\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.5049 - acc: 0.1991 - val_loss: 3.5747 - val_acc: 0.1842\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.4826 - acc: 0.2018 - val_loss: 3.6033 - val_acc: 0.1858\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.4479 - acc: 0.1997 - val_loss: 3.5014 - val_acc: 0.2015\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.4420 - acc: 0.1989 - val_loss: 3.4817 - val_acc: 0.2048\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.3856 - acc: 0.2180 - val_loss: 3.4629 - val_acc: 0.2057\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.3648 - acc: 0.2139 - val_loss: 3.4926 - val_acc: 0.1963\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.3722 - acc: 0.2139 - val_loss: 3.5320 - val_acc: 0.1953\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.3670 - acc: 0.2137 - val_loss: 3.5199 - val_acc: 0.1976\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3365 - acc: 0.2217 - val_loss: 3.5138 - val_acc: 0.1966\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.3051 - acc: 0.2343 - val_loss: 3.4908 - val_acc: 0.2067\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.3141 - acc: 0.2266 - val_loss: 3.5254 - val_acc: 0.2025\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2855 - acc: 0.2310 - val_loss: 3.4695 - val_acc: 0.2038\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.2681 - acc: 0.2275 - val_loss: 3.4892 - val_acc: 0.2087\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.2541 - acc: 0.2405 - val_loss: 3.4373 - val_acc: 0.2155\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.2354 - acc: 0.2342 - val_loss: 3.4737 - val_acc: 0.2106\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.2347 - acc: 0.2407 - val_loss: 3.4169 - val_acc: 0.2158\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.2057 - acc: 0.2466 - val_loss: 3.4374 - val_acc: 0.2162\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.2000 - acc: 0.2452 - val_loss: 3.4197 - val_acc: 0.2162\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.1876 - acc: 0.2470 - val_loss: 3.4466 - val_acc: 0.2093\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.1724 - acc: 0.2504 - val_loss: 3.4995 - val_acc: 0.2097\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.1421 - acc: 0.2573 - val_loss: 3.4258 - val_acc: 0.2207\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.1388 - acc: 0.2587 - val_loss: 3.4052 - val_acc: 0.2211\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.1028 - acc: 0.2627 - val_loss: 3.4236 - val_acc: 0.2201\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.1032 - acc: 0.2610 - val_loss: 3.4302 - val_acc: 0.2204\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.0859 - acc: 0.2747 - val_loss: 3.4522 - val_acc: 0.2194\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.0717 - acc: 0.2692 - val_loss: 3.4281 - val_acc: 0.2217\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.0596 - acc: 0.2705 - val_loss: 3.4386 - val_acc: 0.2250\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 3.0342 - acc: 0.2793 - val_loss: 3.3898 - val_acc: 0.2282\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.0626 - acc: 0.2693 - val_loss: 3.4245 - val_acc: 0.2263\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.0411 - acc: 0.2761 - val_loss: 3.3785 - val_acc: 0.2266\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.0477 - acc: 0.2721 - val_loss: 3.3667 - val_acc: 0.2302\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.0240 - acc: 0.2804 - val_loss: 3.4236 - val_acc: 0.2181\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 2.9762 - acc: 0.2884 - val_loss: 3.4733 - val_acc: 0.2129\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.0060 - acc: 0.2776 - val_loss: 3.3906 - val_acc: 0.2325\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 2.9655 - acc: 0.2905 - val_loss: 3.3851 - val_acc: 0.2292\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 2.9825 - acc: 0.2819 - val_loss: 3.3812 - val_acc: 0.2361\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 2.9699 - acc: 0.2843 - val_loss: 3.4249 - val_acc: 0.2243\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 2.9470 - acc: 0.2994 - val_loss: 3.3925 - val_acc: 0.2299\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 2.9301 - acc: 0.2943 - val_loss: 3.4245 - val_acc: 0.2295\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 2.9412 - acc: 0.2915 - val_loss: 3.4133 - val_acc: 0.2295\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 2.9481 - acc: 0.2914 - val_loss: 3.3996 - val_acc: 0.2338\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 2.8997 - acc: 0.2999 - val_loss: 3.3692 - val_acc: 0.2344\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 2.9060 - acc: 0.2990 - val_loss: 3.3691 - val_acc: 0.2344\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 2.8903 - acc: 0.3103 - val_loss: 3.3865 - val_acc: 0.2442\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 2.8745 - acc: 0.3054 - val_loss: 3.3811 - val_acc: 0.2328\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 2.8766 - acc: 0.3086 - val_loss: 3.3653 - val_acc: 0.2367\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 2.8878 - acc: 0.3085 - val_loss: 3.3705 - val_acc: 0.2416\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 2.8621 - acc: 0.3076 - val_loss: 3.4215 - val_acc: 0.2338\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 2.8445 - acc: 0.3074 - val_loss: 3.3856 - val_acc: 0.2439\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 2.8376 - acc: 0.3173 - val_loss: 3.3870 - val_acc: 0.2361\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 2.8288 - acc: 0.3117 - val_loss: 3.3781 - val_acc: 0.2400\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 2.8175 - acc: 0.3120 - val_loss: 3.4240 - val_acc: 0.2292\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 2.8098 - acc: 0.3249 - val_loss: 3.3714 - val_acc: 0.2380\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 2.7992 - acc: 0.3201 - val_loss: 3.3965 - val_acc: 0.2410\n",
      "Epoch 00084: early stopping\n",
      "Test accuracy: 0.240952070437\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.08713154765397157\n",
      "bottleneckFlag= False\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 88.2248 - acc: 0.0077 - val_loss: 30.0258 - val_acc: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 14.6494 - acc: 0.0103 - val_loss: 6.9827 - val_acc: 0.0127\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 5.5693 - acc: 0.0180 - val_loss: 4.9109 - val_acc: 0.0251\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.7935 - acc: 0.0283 - val_loss: 4.6672 - val_acc: 0.0313\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.6309 - acc: 0.0354 - val_loss: 4.4449 - val_acc: 0.0483\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.5240 - acc: 0.0485 - val_loss: 4.3648 - val_acc: 0.0597\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.4200 - acc: 0.0540 - val_loss: 4.2129 - val_acc: 0.0685\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 4.3277 - acc: 0.0637 - val_loss: 4.2027 - val_acc: 0.0773\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 4.2572 - acc: 0.0666 - val_loss: 4.0597 - val_acc: 0.0900\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 4.2186 - acc: 0.0666 - val_loss: 4.0307 - val_acc: 0.0919\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.1536 - acc: 0.0819 - val_loss: 4.0883 - val_acc: 0.0887\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 4.1235 - acc: 0.0862 - val_loss: 3.9424 - val_acc: 0.1037\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 4.0673 - acc: 0.0977 - val_loss: 3.8991 - val_acc: 0.1219\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 4.0371 - acc: 0.1028 - val_loss: 3.9120 - val_acc: 0.1232\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.9995 - acc: 0.1119 - val_loss: 3.8881 - val_acc: 0.1151\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.9739 - acc: 0.1038 - val_loss: 3.8108 - val_acc: 0.1304\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.9472 - acc: 0.1110 - val_loss: 3.8564 - val_acc: 0.1265\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.9270 - acc: 0.1190 - val_loss: 3.7893 - val_acc: 0.1363\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.9053 - acc: 0.1186 - val_loss: 3.7568 - val_acc: 0.1461\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.8719 - acc: 0.1260 - val_loss: 3.7892 - val_acc: 0.1314\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.8561 - acc: 0.1252 - val_loss: 3.7374 - val_acc: 0.1457\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.8214 - acc: 0.1312 - val_loss: 3.7531 - val_acc: 0.1396\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.8181 - acc: 0.1367 - val_loss: 3.7201 - val_acc: 0.1454\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.7893 - acc: 0.1375 - val_loss: 3.6636 - val_acc: 0.1568\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.7396 - acc: 0.1440 - val_loss: 3.6467 - val_acc: 0.1728\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.7420 - acc: 0.1397 - val_loss: 3.6933 - val_acc: 0.1503\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.7200 - acc: 0.1511 - val_loss: 3.6401 - val_acc: 0.1643\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.7235 - acc: 0.1535 - val_loss: 3.6512 - val_acc: 0.1562\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.7027 - acc: 0.1489 - val_loss: 3.6108 - val_acc: 0.1624\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.6720 - acc: 0.1515 - val_loss: 3.6275 - val_acc: 0.1634\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.6429 - acc: 0.1620 - val_loss: 3.6308 - val_acc: 0.1588\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.6331 - acc: 0.1618 - val_loss: 3.5751 - val_acc: 0.1725\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.6404 - acc: 0.1596 - val_loss: 3.6301 - val_acc: 0.1656\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.6037 - acc: 0.1699 - val_loss: 3.5768 - val_acc: 0.1780\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.6098 - acc: 0.1758 - val_loss: 3.5410 - val_acc: 0.1777\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.5788 - acc: 0.1735 - val_loss: 3.5645 - val_acc: 0.1744\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.5677 - acc: 0.1772 - val_loss: 3.5342 - val_acc: 0.1826\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.5652 - acc: 0.1725 - val_loss: 3.5366 - val_acc: 0.1810\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.5348 - acc: 0.1801 - val_loss: 3.5369 - val_acc: 0.1839\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.5262 - acc: 0.1812 - val_loss: 3.4924 - val_acc: 0.1862\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.5216 - acc: 0.1791 - val_loss: 3.5406 - val_acc: 0.1813\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 3.4935 - acc: 0.1846 - val_loss: 3.4581 - val_acc: 0.1950\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.5098 - acc: 0.1898 - val_loss: 3.4673 - val_acc: 0.2005\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.4640 - acc: 0.1928 - val_loss: 3.5240 - val_acc: 0.1858\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.4618 - acc: 0.1922 - val_loss: 3.5255 - val_acc: 0.1872\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.4630 - acc: 0.1983 - val_loss: 3.4519 - val_acc: 0.1973\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4381 - acc: 0.1971 - val_loss: 3.4333 - val_acc: 0.2005\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.4341 - acc: 0.1980 - val_loss: 3.4674 - val_acc: 0.1953\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.4118 - acc: 0.1985 - val_loss: 3.4397 - val_acc: 0.2015\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 3.4234 - acc: 0.2013 - val_loss: 3.4301 - val_acc: 0.2012\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.3911 - acc: 0.2057 - val_loss: 3.4449 - val_acc: 0.1999\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.3920 - acc: 0.2095 - val_loss: 3.4544 - val_acc: 0.2041\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.3756 - acc: 0.2094 - val_loss: 3.3993 - val_acc: 0.2018\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.3655 - acc: 0.2071 - val_loss: 3.4252 - val_acc: 0.2015\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.3527 - acc: 0.2081 - val_loss: 3.4392 - val_acc: 0.2070\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.3497 - acc: 0.2163 - val_loss: 3.4670 - val_acc: 0.1973\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.3582 - acc: 0.2085 - val_loss: 3.4406 - val_acc: 0.2005\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.3221 - acc: 0.2188 - val_loss: 3.4049 - val_acc: 0.2067\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.3249 - acc: 0.2162 - val_loss: 3.4159 - val_acc: 0.2044\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.3046 - acc: 0.2195 - val_loss: 3.4011 - val_acc: 0.2106\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.2972 - acc: 0.2205 - val_loss: 3.4414 - val_acc: 0.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.3060 - acc: 0.2160 - val_loss: 3.3943 - val_acc: 0.2175\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 3.2971 - acc: 0.2242 - val_loss: 3.3724 - val_acc: 0.2214\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.2853 - acc: 0.2210 - val_loss: 3.4090 - val_acc: 0.2129\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.2912 - acc: 0.2272 - val_loss: 3.3881 - val_acc: 0.2093\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.2617 - acc: 0.2288 - val_loss: 3.4011 - val_acc: 0.2185\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2460 - acc: 0.2288 - val_loss: 3.4249 - val_acc: 0.2162\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 3.2491 - acc: 0.2297 - val_loss: 3.3766 - val_acc: 0.2185\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2248 - acc: 0.2351 - val_loss: 3.3579 - val_acc: 0.2214\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.2148 - acc: 0.2332 - val_loss: 3.3861 - val_acc: 0.2136\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.2382 - acc: 0.2356 - val_loss: 3.3718 - val_acc: 0.2191\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 3.2239 - acc: 0.2371 - val_loss: 3.3545 - val_acc: 0.2230\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.2183 - acc: 0.2362 - val_loss: 3.3595 - val_acc: 0.2181\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.2098 - acc: 0.2387 - val_loss: 3.3893 - val_acc: 0.2136\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.1933 - acc: 0.2390 - val_loss: 3.3534 - val_acc: 0.2233\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.1917 - acc: 0.2378 - val_loss: 3.3740 - val_acc: 0.2194\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.1852 - acc: 0.2456 - val_loss: 3.3580 - val_acc: 0.2201\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.1799 - acc: 0.2463 - val_loss: 3.3597 - val_acc: 0.2207\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.1839 - acc: 0.2506 - val_loss: 3.3344 - val_acc: 0.2273\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.1697 - acc: 0.2402 - val_loss: 3.3648 - val_acc: 0.2162\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.1594 - acc: 0.2443 - val_loss: 3.3063 - val_acc: 0.2250\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.1429 - acc: 0.2506 - val_loss: 3.3408 - val_acc: 0.2237\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.1449 - acc: 0.2559 - val_loss: 3.3351 - val_acc: 0.2266\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.1506 - acc: 0.2452 - val_loss: 3.3488 - val_acc: 0.2253\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.1275 - acc: 0.2577 - val_loss: 3.3559 - val_acc: 0.2237\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.1267 - acc: 0.2531 - val_loss: 3.3713 - val_acc: 0.2204\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.1358 - acc: 0.2467 - val_loss: 3.3617 - val_acc: 0.2230\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 3.1182 - acc: 0.2539 - val_loss: 3.3321 - val_acc: 0.2237\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 3.1364 - acc: 0.2489 - val_loss: 3.3457 - val_acc: 0.2207\n",
      "Epoch 00089: early stopping\n",
      "Test accuracy: 0.220736876436\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.042535919277377585\n",
      "bottleneckFlag= True\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 44.7792 - acc: 0.0093 - val_loss: 16.3650 - val_acc: 0.0121\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 9.1282 - acc: 0.0099 - val_loss: 5.6245 - val_acc: 0.0108\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 5.0337 - acc: 0.0165 - val_loss: 4.7696 - val_acc: 0.0163\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 4.7044 - acc: 0.0181 - val_loss: 4.6073 - val_acc: 0.0231\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 4.6348 - acc: 0.0237 - val_loss: 4.5664 - val_acc: 0.0218\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 4.6051 - acc: 0.0213 - val_loss: 4.5235 - val_acc: 0.0290\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 4.5555 - acc: 0.0287 - val_loss: 4.4382 - val_acc: 0.0349\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.4965 - acc: 0.0328 - val_loss: 4.3596 - val_acc: 0.0434\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 4.4313 - acc: 0.0432 - val_loss: 4.3242 - val_acc: 0.0531\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 4.3720 - acc: 0.0478 - val_loss: 4.2444 - val_acc: 0.0564\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 4.3264 - acc: 0.0488 - val_loss: 4.2117 - val_acc: 0.0619\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 4.2399 - acc: 0.0553 - val_loss: 4.0949 - val_acc: 0.0678\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 4.2175 - acc: 0.0580 - val_loss: 4.0585 - val_acc: 0.0760\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 4.1602 - acc: 0.0661 - val_loss: 4.0378 - val_acc: 0.0858\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 4.1235 - acc: 0.0717 - val_loss: 4.0251 - val_acc: 0.0818\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 4.0880 - acc: 0.0742 - val_loss: 3.9388 - val_acc: 0.0871\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 4.0516 - acc: 0.0757 - val_loss: 3.9333 - val_acc: 0.0955\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 4.0094 - acc: 0.0832 - val_loss: 3.8893 - val_acc: 0.0975\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.9941 - acc: 0.0860 - val_loss: 3.8955 - val_acc: 0.0965\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.9674 - acc: 0.0905 - val_loss: 3.8406 - val_acc: 0.1047\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 3.9517 - acc: 0.0880 - val_loss: 3.8425 - val_acc: 0.1096\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.9092 - acc: 0.0949 - val_loss: 3.8555 - val_acc: 0.1001\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.9047 - acc: 0.1013 - val_loss: 3.8221 - val_acc: 0.1154\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.8918 - acc: 0.1016 - val_loss: 3.8188 - val_acc: 0.1086\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.8662 - acc: 0.1041 - val_loss: 3.7726 - val_acc: 0.1151\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.8623 - acc: 0.1055 - val_loss: 3.7551 - val_acc: 0.1229\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.8332 - acc: 0.1127 - val_loss: 3.7715 - val_acc: 0.1144\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.8295 - acc: 0.1055 - val_loss: 3.7858 - val_acc: 0.1135\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.8015 - acc: 0.1169 - val_loss: 3.7559 - val_acc: 0.1079\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.7789 - acc: 0.1201 - val_loss: 3.7572 - val_acc: 0.1223\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.7780 - acc: 0.1168 - val_loss: 3.7285 - val_acc: 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.7685 - acc: 0.1202 - val_loss: 3.7332 - val_acc: 0.1262\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.7262 - acc: 0.1228 - val_loss: 3.6947 - val_acc: 0.1324\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.7332 - acc: 0.1246 - val_loss: 3.6895 - val_acc: 0.1317\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.7289 - acc: 0.1268 - val_loss: 3.7051 - val_acc: 0.1360\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.7097 - acc: 0.1312 - val_loss: 3.6647 - val_acc: 0.1321\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.6803 - acc: 0.1306 - val_loss: 3.6584 - val_acc: 0.1441\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.6853 - acc: 0.1314 - val_loss: 3.6487 - val_acc: 0.1415\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.6517 - acc: 0.1378 - val_loss: 3.7031 - val_acc: 0.1405\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.6513 - acc: 0.1393 - val_loss: 3.6613 - val_acc: 0.1415\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.6365 - acc: 0.1391 - val_loss: 3.6433 - val_acc: 0.1444\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.6488 - acc: 0.1393 - val_loss: 3.6622 - val_acc: 0.1405\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.6346 - acc: 0.1428 - val_loss: 3.6133 - val_acc: 0.1441\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.5993 - acc: 0.1493 - val_loss: 3.6329 - val_acc: 0.1454\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.5943 - acc: 0.1522 - val_loss: 3.6014 - val_acc: 0.1542\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.5822 - acc: 0.1549 - val_loss: 3.5930 - val_acc: 0.1526\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.5680 - acc: 0.1523 - val_loss: 3.6143 - val_acc: 0.1474\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.5857 - acc: 0.1557 - val_loss: 3.6156 - val_acc: 0.1510\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5593 - acc: 0.1517 - val_loss: 3.5958 - val_acc: 0.1480\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.5417 - acc: 0.1589 - val_loss: 3.6518 - val_acc: 0.1487\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.5294 - acc: 0.1579 - val_loss: 3.5899 - val_acc: 0.1585\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.5259 - acc: 0.1615 - val_loss: 3.5811 - val_acc: 0.1572\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.5425 - acc: 0.1596 - val_loss: 3.5670 - val_acc: 0.1617\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.5206 - acc: 0.1684 - val_loss: 3.5364 - val_acc: 0.1676\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.4996 - acc: 0.1682 - val_loss: 3.5375 - val_acc: 0.1682\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.4896 - acc: 0.1671 - val_loss: 3.5295 - val_acc: 0.1663\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4894 - acc: 0.1654 - val_loss: 3.5578 - val_acc: 0.1653\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.4871 - acc: 0.1678 - val_loss: 3.5116 - val_acc: 0.1784\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.4715 - acc: 0.1744 - val_loss: 3.5318 - val_acc: 0.1709\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.4802 - acc: 0.1722 - val_loss: 3.5373 - val_acc: 0.1673\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.4534 - acc: 0.1791 - val_loss: 3.5670 - val_acc: 0.1699\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.4482 - acc: 0.1767 - val_loss: 3.5081 - val_acc: 0.1764\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.4346 - acc: 0.1773 - val_loss: 3.5288 - val_acc: 0.1793\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.4397 - acc: 0.1833 - val_loss: 3.4730 - val_acc: 0.1797\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.4306 - acc: 0.1804 - val_loss: 3.4725 - val_acc: 0.1761\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.4373 - acc: 0.1794 - val_loss: 3.5111 - val_acc: 0.1780\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.4135 - acc: 0.1819 - val_loss: 3.5098 - val_acc: 0.1777\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.4092 - acc: 0.1845 - val_loss: 3.4966 - val_acc: 0.1757\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.3833 - acc: 0.1849 - val_loss: 3.5170 - val_acc: 0.1787\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 3.3814 - acc: 0.1835 - val_loss: 3.5198 - val_acc: 0.1757\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 31s 272ms/step - loss: 3.3977 - acc: 0.1846 - val_loss: 3.4948 - val_acc: 0.1757\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.3794 - acc: 0.1880 - val_loss: 3.4597 - val_acc: 0.1829\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.3474 - acc: 0.1965 - val_loss: 3.4786 - val_acc: 0.1862\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.3610 - acc: 0.1922 - val_loss: 3.5015 - val_acc: 0.1774\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.3601 - acc: 0.1901 - val_loss: 3.4786 - val_acc: 0.1881\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.3635 - acc: 0.1882 - val_loss: 3.4769 - val_acc: 0.1872\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.3365 - acc: 0.1942 - val_loss: 3.4386 - val_acc: 0.1888\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.3441 - acc: 0.1973 - val_loss: 3.4926 - val_acc: 0.1823\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.3414 - acc: 0.1990 - val_loss: 3.4350 - val_acc: 0.1924\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.3356 - acc: 0.1923 - val_loss: 3.4774 - val_acc: 0.1868\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.3160 - acc: 0.2001 - val_loss: 3.4523 - val_acc: 0.1872\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.3093 - acc: 0.1967 - val_loss: 3.4631 - val_acc: 0.1907\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.2871 - acc: 0.1993 - val_loss: 3.4588 - val_acc: 0.1839\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.3071 - acc: 0.1963 - val_loss: 3.4265 - val_acc: 0.1969\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.3190 - acc: 0.1957 - val_loss: 3.4468 - val_acc: 0.1937\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.3068 - acc: 0.2015 - val_loss: 3.4219 - val_acc: 0.1979\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.2896 - acc: 0.2104 - val_loss: 3.4331 - val_acc: 0.1865\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 3.2846 - acc: 0.2034 - val_loss: 3.3966 - val_acc: 0.1950\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.2861 - acc: 0.2089 - val_loss: 3.3926 - val_acc: 0.2064\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.2675 - acc: 0.2136 - val_loss: 3.4184 - val_acc: 0.1999\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2692 - acc: 0.2064 - val_loss: 3.4175 - val_acc: 0.1960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 3.2551 - acc: 0.2045 - val_loss: 3.4053 - val_acc: 0.1989\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.2552 - acc: 0.2092 - val_loss: 3.4498 - val_acc: 0.1950\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2437 - acc: 0.2143 - val_loss: 3.4354 - val_acc: 0.1966\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.2534 - acc: 0.2115 - val_loss: 3.4241 - val_acc: 0.2022\n",
      "Epoch 96/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.2407 - acc: 0.2203 - val_loss: 3.4568 - val_acc: 0.1973\n",
      "Epoch 97/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.2440 - acc: 0.2155 - val_loss: 3.4537 - val_acc: 0.1953\n",
      "Epoch 98/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.2314 - acc: 0.2220 - val_loss: 3.4370 - val_acc: 0.1937\n",
      "Epoch 99/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.2295 - acc: 0.2142 - val_loss: 3.4664 - val_acc: 0.1960\n",
      "Epoch 00099: early stopping\n",
      "Test accuracy: 0.195956961202\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.04646895103826017\n",
      "bottleneckFlag= True\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 47.9277 - acc: 0.0088 - val_loss: 17.0454 - val_acc: 0.0098\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 9.3463 - acc: 0.0099 - val_loss: 5.6480 - val_acc: 0.0104\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 5.0442 - acc: 0.0086 - val_loss: 4.7989 - val_acc: 0.0143\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 4.7281 - acc: 0.0165 - val_loss: 4.6556 - val_acc: 0.0176\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 4.6546 - acc: 0.0171 - val_loss: 4.5717 - val_acc: 0.0222\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 4.6083 - acc: 0.0202 - val_loss: 4.5587 - val_acc: 0.0202\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.5904 - acc: 0.0216 - val_loss: 4.5140 - val_acc: 0.0205\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 4.5548 - acc: 0.0245 - val_loss: 4.4906 - val_acc: 0.0254\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 4.5188 - acc: 0.0269 - val_loss: 4.4444 - val_acc: 0.0254\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 4.4927 - acc: 0.0320 - val_loss: 4.3912 - val_acc: 0.0381\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 4.4370 - acc: 0.0398 - val_loss: 4.3975 - val_acc: 0.0456\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 4.3810 - acc: 0.0477 - val_loss: 4.2867 - val_acc: 0.0476\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 4.3159 - acc: 0.0509 - val_loss: 4.2105 - val_acc: 0.0593\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 4.2726 - acc: 0.0585 - val_loss: 4.1331 - val_acc: 0.0629\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.2071 - acc: 0.0649 - val_loss: 4.1100 - val_acc: 0.0665\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 4.1521 - acc: 0.0698 - val_loss: 4.0263 - val_acc: 0.0835\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.1141 - acc: 0.0772 - val_loss: 3.9938 - val_acc: 0.0861\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 4.0751 - acc: 0.0835 - val_loss: 3.9578 - val_acc: 0.0952\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 30s 263ms/step - loss: 4.0238 - acc: 0.0840 - val_loss: 3.9369 - val_acc: 0.0835\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 4.0207 - acc: 0.0849 - val_loss: 3.8989 - val_acc: 0.0978\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.9753 - acc: 0.0889 - val_loss: 3.8571 - val_acc: 0.1030\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.9490 - acc: 0.0946 - val_loss: 3.8856 - val_acc: 0.1047\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.9412 - acc: 0.0901 - val_loss: 3.8112 - val_acc: 0.1122\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.8987 - acc: 0.1043 - val_loss: 3.8069 - val_acc: 0.1063\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.9026 - acc: 0.0993 - val_loss: 3.7740 - val_acc: 0.1219\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.8857 - acc: 0.1087 - val_loss: 3.7597 - val_acc: 0.1131\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.8632 - acc: 0.1015 - val_loss: 3.7808 - val_acc: 0.1187\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.8468 - acc: 0.1093 - val_loss: 3.7607 - val_acc: 0.1151\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.8433 - acc: 0.1087 - val_loss: 3.7419 - val_acc: 0.1213\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.8118 - acc: 0.1164 - val_loss: 3.7309 - val_acc: 0.1285\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.8262 - acc: 0.1143 - val_loss: 3.7263 - val_acc: 0.1223\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.7814 - acc: 0.1157 - val_loss: 3.7139 - val_acc: 0.1197\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.7686 - acc: 0.1210 - val_loss: 3.7256 - val_acc: 0.1219\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.7774 - acc: 0.1200 - val_loss: 3.6802 - val_acc: 0.1321\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 30s 263ms/step - loss: 3.7506 - acc: 0.1220 - val_loss: 3.6966 - val_acc: 0.1317\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.7385 - acc: 0.1252 - val_loss: 3.7204 - val_acc: 0.1275\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.7256 - acc: 0.1276 - val_loss: 3.6857 - val_acc: 0.1304\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.7289 - acc: 0.1300 - val_loss: 3.6568 - val_acc: 0.1278\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.6829 - acc: 0.1319 - val_loss: 3.6968 - val_acc: 0.1294\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.6890 - acc: 0.1331 - val_loss: 3.6580 - val_acc: 0.1360\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 3.6888 - acc: 0.1309 - val_loss: 3.6804 - val_acc: 0.1294\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.6656 - acc: 0.1384 - val_loss: 3.6293 - val_acc: 0.1415\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.6533 - acc: 0.1399 - val_loss: 3.6146 - val_acc: 0.1399\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.6394 - acc: 0.1475 - val_loss: 3.6163 - val_acc: 0.1366\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.6485 - acc: 0.1443 - val_loss: 3.6350 - val_acc: 0.1343\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.6497 - acc: 0.1461 - val_loss: 3.6935 - val_acc: 0.1353\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.6114 - acc: 0.1476 - val_loss: 3.6481 - val_acc: 0.1448\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.6039 - acc: 0.1471 - val_loss: 3.6245 - val_acc: 0.1454\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.5977 - acc: 0.1460 - val_loss: 3.5684 - val_acc: 0.1572\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 3.5968 - acc: 0.1495 - val_loss: 3.5931 - val_acc: 0.1438\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.5780 - acc: 0.1643 - val_loss: 3.6109 - val_acc: 0.1490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.5767 - acc: 0.1577 - val_loss: 3.6003 - val_acc: 0.1519\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.5597 - acc: 0.1544 - val_loss: 3.5680 - val_acc: 0.1572\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.5714 - acc: 0.1485 - val_loss: 3.5903 - val_acc: 0.1585\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.5651 - acc: 0.1592 - val_loss: 3.5567 - val_acc: 0.1627\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.5421 - acc: 0.1610 - val_loss: 3.5278 - val_acc: 0.1731\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.5374 - acc: 0.1582 - val_loss: 3.5599 - val_acc: 0.1653\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.5192 - acc: 0.1635 - val_loss: 3.5486 - val_acc: 0.1611\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.5272 - acc: 0.1688 - val_loss: 3.5447 - val_acc: 0.1712\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.5124 - acc: 0.1665 - val_loss: 3.5228 - val_acc: 0.1731\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 3.4783 - acc: 0.1645 - val_loss: 3.5279 - val_acc: 0.1695\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.4964 - acc: 0.1641 - val_loss: 3.5182 - val_acc: 0.1748\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.4709 - acc: 0.1693 - val_loss: 3.5280 - val_acc: 0.1712\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.4733 - acc: 0.1731 - val_loss: 3.5339 - val_acc: 0.1682\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 3.4676 - acc: 0.1750 - val_loss: 3.5118 - val_acc: 0.1715\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.4499 - acc: 0.1711 - val_loss: 3.5041 - val_acc: 0.1725\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 3.4308 - acc: 0.1799 - val_loss: 3.4799 - val_acc: 0.1806\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.4079 - acc: 0.1846 - val_loss: 3.5275 - val_acc: 0.1712\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.4248 - acc: 0.1806 - val_loss: 3.4934 - val_acc: 0.1836\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.4242 - acc: 0.1823 - val_loss: 3.4964 - val_acc: 0.1770\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.4269 - acc: 0.1891 - val_loss: 3.4868 - val_acc: 0.1810\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.3977 - acc: 0.1903 - val_loss: 3.4564 - val_acc: 0.1858\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.4057 - acc: 0.1857 - val_loss: 3.4797 - val_acc: 0.1800\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.3899 - acc: 0.1866 - val_loss: 3.4791 - val_acc: 0.1813\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 3.3973 - acc: 0.1872 - val_loss: 3.4303 - val_acc: 0.1888\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.3735 - acc: 0.1927 - val_loss: 3.4616 - val_acc: 0.1852\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3861 - acc: 0.1867 - val_loss: 3.4584 - val_acc: 0.1764\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.3531 - acc: 0.1934 - val_loss: 3.4616 - val_acc: 0.1904\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.3738 - acc: 0.1940 - val_loss: 3.4981 - val_acc: 0.1819\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.3673 - acc: 0.1922 - val_loss: 3.4419 - val_acc: 0.1885\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.3431 - acc: 0.1962 - val_loss: 3.4336 - val_acc: 0.1875\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.3692 - acc: 0.1913 - val_loss: 3.4247 - val_acc: 0.1875\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.3277 - acc: 0.1913 - val_loss: 3.4472 - val_acc: 0.1849\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 3.3467 - acc: 0.1966 - val_loss: 3.4482 - val_acc: 0.1881\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.3416 - acc: 0.2005 - val_loss: 3.4542 - val_acc: 0.1901\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.3297 - acc: 0.1953 - val_loss: 3.4407 - val_acc: 0.1878\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.3289 - acc: 0.2060 - val_loss: 3.3996 - val_acc: 0.1950\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.3111 - acc: 0.1976 - val_loss: 3.4327 - val_acc: 0.1894\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.2911 - acc: 0.2064 - val_loss: 3.4033 - val_acc: 0.1943\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3068 - acc: 0.2045 - val_loss: 3.4135 - val_acc: 0.1911\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.3003 - acc: 0.1992 - val_loss: 3.4156 - val_acc: 0.1881\n",
      "Epoch 92/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2847 - acc: 0.2046 - val_loss: 3.4364 - val_acc: 0.1894\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.2963 - acc: 0.2040 - val_loss: 3.4221 - val_acc: 0.1937\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.2836 - acc: 0.2099 - val_loss: 3.4404 - val_acc: 0.1911\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2906 - acc: 0.1960 - val_loss: 3.3928 - val_acc: 0.1963\n",
      "Epoch 96/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.2775 - acc: 0.2080 - val_loss: 3.4128 - val_acc: 0.1992\n",
      "Epoch 97/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.2474 - acc: 0.2113 - val_loss: 3.4215 - val_acc: 0.1966\n",
      "Epoch 98/150\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 3.2671 - acc: 0.2084 - val_loss: 3.3833 - val_acc: 0.2012\n",
      "Epoch 99/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2580 - acc: 0.2103 - val_loss: 3.4178 - val_acc: 0.2005\n",
      "Epoch 100/150\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 3.2326 - acc: 0.2106 - val_loss: 3.3796 - val_acc: 0.2041\n",
      "Epoch 101/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.2292 - acc: 0.2181 - val_loss: 3.3949 - val_acc: 0.2022\n",
      "Epoch 102/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.2456 - acc: 0.2112 - val_loss: 3.3828 - val_acc: 0.2008\n",
      "Epoch 103/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.2489 - acc: 0.2146 - val_loss: 3.4196 - val_acc: 0.2035\n",
      "Epoch 104/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.2393 - acc: 0.2132 - val_loss: 3.4165 - val_acc: 0.2005\n",
      "Epoch 105/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 3.2317 - acc: 0.2192 - val_loss: 3.3922 - val_acc: 0.2070\n",
      "Epoch 106/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.2298 - acc: 0.2193 - val_loss: 3.4270 - val_acc: 0.1989\n",
      "Epoch 107/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2268 - acc: 0.2180 - val_loss: 3.3823 - val_acc: 0.2106\n",
      "Epoch 108/150\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 3.2156 - acc: 0.2205 - val_loss: 3.3912 - val_acc: 0.2038\n",
      "Epoch 109/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.2037 - acc: 0.2189 - val_loss: 3.3876 - val_acc: 0.2035\n",
      "Epoch 110/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.2013 - acc: 0.2196 - val_loss: 3.3528 - val_acc: 0.2152\n",
      "Epoch 111/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 3.1948 - acc: 0.2202 - val_loss: 3.3563 - val_acc: 0.2129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 3.1763 - acc: 0.2192 - val_loss: 3.3780 - val_acc: 0.2103\n",
      "Epoch 113/150\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 3.1643 - acc: 0.2248 - val_loss: 3.4229 - val_acc: 0.2041\n",
      "Epoch 114/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.1724 - acc: 0.2249 - val_loss: 3.3672 - val_acc: 0.2083\n",
      "Epoch 115/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.1982 - acc: 0.2265 - val_loss: 3.3813 - val_acc: 0.2061\n",
      "Epoch 116/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 3.1632 - acc: 0.2233 - val_loss: 3.3582 - val_acc: 0.2083\n",
      "Epoch 117/150\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 3.1811 - acc: 0.2268 - val_loss: 3.3749 - val_acc: 0.2018\n",
      "Epoch 118/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.1683 - acc: 0.2238 - val_loss: 3.3812 - val_acc: 0.2064\n",
      "Epoch 119/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.1775 - acc: 0.2185 - val_loss: 3.3560 - val_acc: 0.2041\n",
      "Epoch 120/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.1542 - acc: 0.2282 - val_loss: 3.3561 - val_acc: 0.2064\n",
      "Epoch 00120: early stopping\n",
      "Test accuracy: 0.206390609726\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.0019418805465617039\n",
      "bottleneckFlag= False\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 8.4469 - acc: 0.0088 - val_loss: 7.9483 - val_acc: 0.0098\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 7.5226 - acc: 0.0103 - val_loss: 7.0745 - val_acc: 0.0160\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 6.6897 - acc: 0.0173 - val_loss: 6.2797 - val_acc: 0.0209\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 6.0398 - acc: 0.0236 - val_loss: 5.7985 - val_acc: 0.0235\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 5.5916 - acc: 0.0306 - val_loss: 5.3123 - val_acc: 0.0476\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 5.2405 - acc: 0.0472 - val_loss: 4.9789 - val_acc: 0.0619\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 4.9517 - acc: 0.0619 - val_loss: 4.7476 - val_acc: 0.0753\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 4.7422 - acc: 0.0680 - val_loss: 4.5220 - val_acc: 0.0916\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 4.5748 - acc: 0.0867 - val_loss: 4.3774 - val_acc: 0.1053\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 4.4489 - acc: 0.0987 - val_loss: 4.2822 - val_acc: 0.1232\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 4.3571 - acc: 0.1007 - val_loss: 4.2014 - val_acc: 0.1232\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 4.2731 - acc: 0.1180 - val_loss: 4.1359 - val_acc: 0.1360\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 4.2219 - acc: 0.1195 - val_loss: 4.0570 - val_acc: 0.1396\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 4.1336 - acc: 0.1329 - val_loss: 4.0182 - val_acc: 0.1448\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 4.0465 - acc: 0.1375 - val_loss: 3.9744 - val_acc: 0.1464\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 4.0348 - acc: 0.1318 - val_loss: 3.9311 - val_acc: 0.1575\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 3.9808 - acc: 0.1423 - val_loss: 3.9436 - val_acc: 0.1464\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.9157 - acc: 0.1451 - val_loss: 3.8395 - val_acc: 0.1578\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 3.8973 - acc: 0.1529 - val_loss: 3.8563 - val_acc: 0.1572\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.8286 - acc: 0.1656 - val_loss: 3.8451 - val_acc: 0.1585\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 3.8032 - acc: 0.1661 - val_loss: 3.8122 - val_acc: 0.1656\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.7746 - acc: 0.1698 - val_loss: 3.7747 - val_acc: 0.1640\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.7530 - acc: 0.1702 - val_loss: 3.7980 - val_acc: 0.1630\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.7279 - acc: 0.1753 - val_loss: 3.7188 - val_acc: 0.1699\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.6499 - acc: 0.1891 - val_loss: 3.7435 - val_acc: 0.1777\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 3.6291 - acc: 0.1886 - val_loss: 3.6996 - val_acc: 0.1813\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 3.6077 - acc: 0.1913 - val_loss: 3.7437 - val_acc: 0.1819\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.5766 - acc: 0.1947 - val_loss: 3.6616 - val_acc: 0.1842\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 3.5705 - acc: 0.1996 - val_loss: 3.6910 - val_acc: 0.1849\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 3.5371 - acc: 0.1977 - val_loss: 3.6516 - val_acc: 0.1943\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 3.5136 - acc: 0.2053 - val_loss: 3.6924 - val_acc: 0.1862\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.4801 - acc: 0.2086 - val_loss: 3.6622 - val_acc: 0.1852\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 3.4562 - acc: 0.2113 - val_loss: 3.6401 - val_acc: 0.1875\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 3.4518 - acc: 0.2162 - val_loss: 3.5971 - val_acc: 0.1963\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 3.4091 - acc: 0.2264 - val_loss: 3.5869 - val_acc: 0.2002\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.3926 - acc: 0.2259 - val_loss: 3.5499 - val_acc: 0.2093\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 3.3595 - acc: 0.2337 - val_loss: 3.5703 - val_acc: 0.2064\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.3534 - acc: 0.2334 - val_loss: 3.5437 - val_acc: 0.2074\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 3.3345 - acc: 0.2357 - val_loss: 3.5452 - val_acc: 0.2048\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 3.3271 - acc: 0.2408 - val_loss: 3.5865 - val_acc: 0.2005\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 3.2985 - acc: 0.2356 - val_loss: 3.5499 - val_acc: 0.2028\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 3.2951 - acc: 0.2453 - val_loss: 3.5699 - val_acc: 0.2038\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 3.2551 - acc: 0.2458 - val_loss: 3.5239 - val_acc: 0.2093\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 3.2321 - acc: 0.2485 - val_loss: 3.5222 - val_acc: 0.2106\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 3.2568 - acc: 0.2425 - val_loss: 3.5245 - val_acc: 0.2097\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2269 - acc: 0.2522 - val_loss: 3.5079 - val_acc: 0.2126\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 3.2006 - acc: 0.2593 - val_loss: 3.4989 - val_acc: 0.2123\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.1925 - acc: 0.2670 - val_loss: 3.4922 - val_acc: 0.2201\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 3.1650 - acc: 0.2601 - val_loss: 3.4700 - val_acc: 0.2214\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.1420 - acc: 0.2663 - val_loss: 3.4818 - val_acc: 0.2214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.1608 - acc: 0.2696 - val_loss: 3.4905 - val_acc: 0.2172\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 3.0925 - acc: 0.2737 - val_loss: 3.5001 - val_acc: 0.2185\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.1068 - acc: 0.2711 - val_loss: 3.4566 - val_acc: 0.2227\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0999 - acc: 0.2689 - val_loss: 3.4817 - val_acc: 0.2233\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0691 - acc: 0.2838 - val_loss: 3.4963 - val_acc: 0.2276\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0500 - acc: 0.2822 - val_loss: 3.4639 - val_acc: 0.2273\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0507 - acc: 0.2892 - val_loss: 3.4713 - val_acc: 0.2227\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0259 - acc: 0.2842 - val_loss: 3.4783 - val_acc: 0.2220\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0300 - acc: 0.2902 - val_loss: 3.4768 - val_acc: 0.2341\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0274 - acc: 0.2924 - val_loss: 3.4708 - val_acc: 0.2295\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9911 - acc: 0.2995 - val_loss: 3.4431 - val_acc: 0.2348\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9947 - acc: 0.2954 - val_loss: 3.4478 - val_acc: 0.2328\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.9590 - acc: 0.3047 - val_loss: 3.4671 - val_acc: 0.2318\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9800 - acc: 0.2983 - val_loss: 3.4788 - val_acc: 0.2266\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.9381 - acc: 0.2990 - val_loss: 3.4326 - val_acc: 0.2325\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9359 - acc: 0.3086 - val_loss: 3.4720 - val_acc: 0.2305\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9365 - acc: 0.3011 - val_loss: 3.4310 - val_acc: 0.2380\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9179 - acc: 0.3053 - val_loss: 3.4531 - val_acc: 0.2289\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9119 - acc: 0.3175 - val_loss: 3.4818 - val_acc: 0.2299\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9301 - acc: 0.3068 - val_loss: 3.4498 - val_acc: 0.2282\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8602 - acc: 0.3162 - val_loss: 3.4728 - val_acc: 0.2335\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8693 - acc: 0.3188 - val_loss: 3.4367 - val_acc: 0.2406\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8727 - acc: 0.3228 - val_loss: 3.4330 - val_acc: 0.2413\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8696 - acc: 0.3176 - val_loss: 3.4857 - val_acc: 0.2325\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 2.8542 - acc: 0.3232 - val_loss: 3.4571 - val_acc: 0.2377\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8427 - acc: 0.3243 - val_loss: 3.4459 - val_acc: 0.2364\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8466 - acc: 0.3213 - val_loss: 3.4439 - val_acc: 0.2374\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 2.8259 - acc: 0.3252 - val_loss: 3.4529 - val_acc: 0.2396\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8157 - acc: 0.3295 - val_loss: 3.4644 - val_acc: 0.2426\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.7702 - acc: 0.3406 - val_loss: 3.4423 - val_acc: 0.2468\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8044 - acc: 0.3308 - val_loss: 3.4562 - val_acc: 0.2396\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7808 - acc: 0.3353 - val_loss: 3.4838 - val_acc: 0.2419\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7687 - acc: 0.3310 - val_loss: 3.4605 - val_acc: 0.2348\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7571 - acc: 0.3415 - val_loss: 3.4609 - val_acc: 0.2321\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7498 - acc: 0.3418 - val_loss: 3.4549 - val_acc: 0.2380\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 2.7489 - acc: 0.3421 - val_loss: 3.4646 - val_acc: 0.2354\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7536 - acc: 0.3371 - val_loss: 3.5239 - val_acc: 0.2321\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7280 - acc: 0.3496 - val_loss: 3.4878 - val_acc: 0.2419\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7316 - acc: 0.3417 - val_loss: 3.4487 - val_acc: 0.2416\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7184 - acc: 0.3473 - val_loss: 3.4731 - val_acc: 0.2383\n",
      "Epoch 00090: early stopping\n",
      "Test accuracy: 0.238343658245\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.022572752376655788\n",
      "bottleneckFlag= False\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 30.4009 - acc: 0.0086 - val_loss: 15.6515 - val_acc: 0.0117\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 10.2865 - acc: 0.0123 - val_loss: 7.1034 - val_acc: 0.0088\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 6.0965 - acc: 0.0109 - val_loss: 5.4671 - val_acc: 0.0166\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 5.2163 - acc: 0.0176 - val_loss: 4.9878 - val_acc: 0.0209\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.8963 - acc: 0.0295 - val_loss: 4.7255 - val_acc: 0.0421\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.6573 - acc: 0.0407 - val_loss: 4.5025 - val_acc: 0.0574\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 4.4782 - acc: 0.0634 - val_loss: 4.3257 - val_acc: 0.0698\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.3445 - acc: 0.0659 - val_loss: 4.1929 - val_acc: 0.0796\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 4.2277 - acc: 0.0800 - val_loss: 4.0652 - val_acc: 0.0933\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 4.1544 - acc: 0.0882 - val_loss: 4.0713 - val_acc: 0.0910\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.0900 - acc: 0.0953 - val_loss: 4.0030 - val_acc: 0.1007\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.0520 - acc: 0.1096 - val_loss: 3.9407 - val_acc: 0.1102\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.0003 - acc: 0.1121 - val_loss: 3.8395 - val_acc: 0.1288\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.9567 - acc: 0.1218 - val_loss: 3.8394 - val_acc: 0.1343\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.8998 - acc: 0.1256 - val_loss: 3.8110 - val_acc: 0.1363\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.8831 - acc: 0.1263 - val_loss: 3.7475 - val_acc: 0.1497\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.8408 - acc: 0.1340 - val_loss: 3.7389 - val_acc: 0.1510\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.8283 - acc: 0.1330 - val_loss: 3.7250 - val_acc: 0.1477\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 3.7944 - acc: 0.1391 - val_loss: 3.8063 - val_acc: 0.1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7496 - acc: 0.1478 - val_loss: 3.6638 - val_acc: 0.1637\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.7479 - acc: 0.1487 - val_loss: 3.6890 - val_acc: 0.1673\n",
      "Epoch 22/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7077 - acc: 0.1560 - val_loss: 3.6086 - val_acc: 0.1679\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6920 - acc: 0.1607 - val_loss: 3.6130 - val_acc: 0.1784\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6822 - acc: 0.1606 - val_loss: 3.5998 - val_acc: 0.1780\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6389 - acc: 0.1648 - val_loss: 3.6324 - val_acc: 0.1738\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6036 - acc: 0.1761 - val_loss: 3.5949 - val_acc: 0.1819\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.6105 - acc: 0.1660 - val_loss: 3.5848 - val_acc: 0.1810\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5856 - acc: 0.1743 - val_loss: 3.5589 - val_acc: 0.1849\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5472 - acc: 0.1841 - val_loss: 3.5660 - val_acc: 0.1888\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5298 - acc: 0.1789 - val_loss: 3.5311 - val_acc: 0.1904\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5192 - acc: 0.1792 - val_loss: 3.4912 - val_acc: 0.2022\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4977 - acc: 0.1895 - val_loss: 3.5303 - val_acc: 0.1992\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.4740 - acc: 0.1899 - val_loss: 3.4886 - val_acc: 0.1966\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4741 - acc: 0.1930 - val_loss: 3.4840 - val_acc: 0.1950\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4476 - acc: 0.1970 - val_loss: 3.4832 - val_acc: 0.1989\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4098 - acc: 0.2094 - val_loss: 3.5046 - val_acc: 0.2002\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4232 - acc: 0.2026 - val_loss: 3.4393 - val_acc: 0.2119\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4010 - acc: 0.2109 - val_loss: 3.4849 - val_acc: 0.2051\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3811 - acc: 0.2076 - val_loss: 3.4459 - val_acc: 0.2064\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3811 - acc: 0.2167 - val_loss: 3.4370 - val_acc: 0.2165\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3578 - acc: 0.2105 - val_loss: 3.4174 - val_acc: 0.2070\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3599 - acc: 0.2104 - val_loss: 3.4192 - val_acc: 0.2136\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3324 - acc: 0.2242 - val_loss: 3.4330 - val_acc: 0.2067\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3269 - acc: 0.2294 - val_loss: 3.4116 - val_acc: 0.2145\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3003 - acc: 0.2293 - val_loss: 3.4957 - val_acc: 0.2044\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2779 - acc: 0.2296 - val_loss: 3.3719 - val_acc: 0.2282\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2916 - acc: 0.2220 - val_loss: 3.3613 - val_acc: 0.2253\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.2764 - acc: 0.2301 - val_loss: 3.3926 - val_acc: 0.2211\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.2494 - acc: 0.2365 - val_loss: 3.3710 - val_acc: 0.2220\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2422 - acc: 0.2332 - val_loss: 3.3643 - val_acc: 0.2175\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2559 - acc: 0.2338 - val_loss: 3.3565 - val_acc: 0.2269\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.2177 - acc: 0.2447 - val_loss: 3.3488 - val_acc: 0.2273\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2089 - acc: 0.2441 - val_loss: 3.3461 - val_acc: 0.2276\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2071 - acc: 0.2466 - val_loss: 3.3602 - val_acc: 0.2273\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.2137 - acc: 0.2330 - val_loss: 3.3808 - val_acc: 0.2292\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1821 - acc: 0.2553 - val_loss: 3.3996 - val_acc: 0.2224\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1926 - acc: 0.2461 - val_loss: 3.3578 - val_acc: 0.2263\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1557 - acc: 0.2545 - val_loss: 3.4110 - val_acc: 0.2250\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1547 - acc: 0.2563 - val_loss: 3.3447 - val_acc: 0.2318\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1275 - acc: 0.2578 - val_loss: 3.3825 - val_acc: 0.2214\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1412 - acc: 0.2560 - val_loss: 3.3404 - val_acc: 0.2292\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.1174 - acc: 0.2592 - val_loss: 3.3666 - val_acc: 0.2305\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.1146 - acc: 0.2560 - val_loss: 3.3509 - val_acc: 0.2335\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0931 - acc: 0.2610 - val_loss: 3.3163 - val_acc: 0.2341\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1010 - acc: 0.2670 - val_loss: 3.3502 - val_acc: 0.2380\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0780 - acc: 0.2666 - val_loss: 3.3530 - val_acc: 0.2348\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0817 - acc: 0.2720 - val_loss: 3.3328 - val_acc: 0.2312\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0636 - acc: 0.2687 - val_loss: 3.3146 - val_acc: 0.2439\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0521 - acc: 0.2727 - val_loss: 3.3843 - val_acc: 0.2328\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0602 - acc: 0.2770 - val_loss: 3.3436 - val_acc: 0.2377\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0230 - acc: 0.2817 - val_loss: 3.3045 - val_acc: 0.2449\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0396 - acc: 0.2771 - val_loss: 3.3229 - val_acc: 0.2426\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0269 - acc: 0.2819 - val_loss: 3.3171 - val_acc: 0.2429\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0090 - acc: 0.2741 - val_loss: 3.3444 - val_acc: 0.2351\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0237 - acc: 0.2735 - val_loss: 3.2836 - val_acc: 0.2478\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.9917 - acc: 0.2883 - val_loss: 3.2832 - val_acc: 0.2475\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9908 - acc: 0.2916 - val_loss: 3.2945 - val_acc: 0.2485\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9804 - acc: 0.2905 - val_loss: 3.3169 - val_acc: 0.2504\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9802 - acc: 0.2882 - val_loss: 3.3217 - val_acc: 0.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9895 - acc: 0.2876 - val_loss: 3.3026 - val_acc: 0.2491\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9586 - acc: 0.2950 - val_loss: 3.2979 - val_acc: 0.2468\n",
      "Epoch 82/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9895 - acc: 0.2836 - val_loss: 3.3148 - val_acc: 0.2426\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9448 - acc: 0.2962 - val_loss: 3.3094 - val_acc: 0.2416\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9581 - acc: 0.2891 - val_loss: 3.3455 - val_acc: 0.2370\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9183 - acc: 0.3014 - val_loss: 3.3246 - val_acc: 0.2426\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9207 - acc: 0.3007 - val_loss: 3.3157 - val_acc: 0.2478\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9269 - acc: 0.2963 - val_loss: 3.3408 - val_acc: 0.2416\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9118 - acc: 0.3053 - val_loss: 3.2986 - val_acc: 0.2511\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.9064 - acc: 0.2948 - val_loss: 3.3321 - val_acc: 0.2455\n",
      "Epoch 90/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 2.8985 - acc: 0.3049 - val_loss: 3.3360 - val_acc: 0.2445\n",
      "Epoch 91/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8923 - acc: 0.3034 - val_loss: 3.3224 - val_acc: 0.2478\n",
      "Epoch 92/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8952 - acc: 0.3052 - val_loss: 3.2958 - val_acc: 0.2537\n",
      "Epoch 93/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8855 - acc: 0.3062 - val_loss: 3.2943 - val_acc: 0.2563\n",
      "Epoch 94/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8602 - acc: 0.3142 - val_loss: 3.3142 - val_acc: 0.2540\n",
      "Epoch 95/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8616 - acc: 0.3115 - val_loss: 3.3067 - val_acc: 0.2507\n",
      "Epoch 96/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 2.8542 - acc: 0.3105 - val_loss: 3.3585 - val_acc: 0.2501\n",
      "Epoch 97/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8825 - acc: 0.3028 - val_loss: 3.3135 - val_acc: 0.2485\n",
      "Epoch 98/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8572 - acc: 0.3175 - val_loss: 3.3314 - val_acc: 0.2504\n",
      "Epoch 99/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8243 - acc: 0.3155 - val_loss: 3.3066 - val_acc: 0.2543\n",
      "Epoch 100/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8341 - acc: 0.3149 - val_loss: 3.3089 - val_acc: 0.2517\n",
      "Epoch 101/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8250 - acc: 0.3198 - val_loss: 3.3117 - val_acc: 0.2563\n",
      "Epoch 102/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8098 - acc: 0.3168 - val_loss: 3.2964 - val_acc: 0.2602\n",
      "Epoch 103/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8460 - acc: 0.3159 - val_loss: 3.3376 - val_acc: 0.2498\n",
      "Epoch 104/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8273 - acc: 0.3159 - val_loss: 3.3084 - val_acc: 0.2543\n",
      "Epoch 105/150\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 2.8220 - acc: 0.3220 - val_loss: 3.3122 - val_acc: 0.2560\n",
      "Epoch 106/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 2.8062 - acc: 0.3283 - val_loss: 3.2934 - val_acc: 0.2546\n",
      "Epoch 107/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8354 - acc: 0.3213 - val_loss: 3.2813 - val_acc: 0.2608\n",
      "Epoch 108/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.8082 - acc: 0.3242 - val_loss: 3.2888 - val_acc: 0.2520\n",
      "Epoch 109/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7879 - acc: 0.3225 - val_loss: 3.3103 - val_acc: 0.2573\n",
      "Epoch 110/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7909 - acc: 0.3288 - val_loss: 3.3176 - val_acc: 0.2527\n",
      "Epoch 111/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7826 - acc: 0.3206 - val_loss: 3.2949 - val_acc: 0.2491\n",
      "Epoch 112/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7632 - acc: 0.3316 - val_loss: 3.3142 - val_acc: 0.2498\n",
      "Epoch 113/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 2.7539 - acc: 0.3379 - val_loss: 3.2796 - val_acc: 0.2595\n",
      "Epoch 114/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7710 - acc: 0.3309 - val_loss: 3.3156 - val_acc: 0.2533\n",
      "Epoch 115/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7536 - acc: 0.3313 - val_loss: 3.3264 - val_acc: 0.2524\n",
      "Epoch 116/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7593 - acc: 0.3323 - val_loss: 3.3203 - val_acc: 0.2494\n",
      "Epoch 117/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 2.7503 - acc: 0.3306 - val_loss: 3.3187 - val_acc: 0.2582\n",
      "Epoch 00117: early stopping\n",
      "Test accuracy: 0.258232800729\n",
      "Creating model\n",
      "\n",
      "lambda_l2= 0.056619182587488104\n",
      "bottleneckFlag= False\n",
      "\n",
      "Epoch 1/150\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 60.6206 - acc: 0.0081 - val_loss: 22.9199 - val_acc: 0.0085\n",
      "Epoch 2/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 12.3591 - acc: 0.0104 - val_loss: 6.8697 - val_acc: 0.0098\n",
      "Epoch 3/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 5.6762 - acc: 0.0120 - val_loss: 5.0569 - val_acc: 0.0225\n",
      "Epoch 4/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 4.8717 - acc: 0.0234 - val_loss: 4.7165 - val_acc: 0.0346\n",
      "Epoch 5/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.6430 - acc: 0.0392 - val_loss: 4.4969 - val_acc: 0.0554\n",
      "Epoch 6/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.4809 - acc: 0.0544 - val_loss: 4.3129 - val_acc: 0.0616\n",
      "Epoch 7/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.3610 - acc: 0.0642 - val_loss: 4.1749 - val_acc: 0.0714\n",
      "Epoch 8/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.2642 - acc: 0.0699 - val_loss: 4.0999 - val_acc: 0.0877\n",
      "Epoch 9/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.2146 - acc: 0.0737 - val_loss: 4.0645 - val_acc: 0.0877\n",
      "Epoch 10/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 4.1643 - acc: 0.0866 - val_loss: 3.9863 - val_acc: 0.1043\n",
      "Epoch 11/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.1076 - acc: 0.0880 - val_loss: 4.0320 - val_acc: 0.0939\n",
      "Epoch 12/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 4.0522 - acc: 0.0933 - val_loss: 3.8815 - val_acc: 0.1210\n",
      "Epoch 13/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 4.0440 - acc: 0.0980 - val_loss: 3.9020 - val_acc: 0.1219\n",
      "Epoch 14/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.9956 - acc: 0.1032 - val_loss: 3.8395 - val_acc: 0.1167\n",
      "Epoch 15/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.9692 - acc: 0.1087 - val_loss: 3.8602 - val_acc: 0.1278\n",
      "Epoch 16/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.9437 - acc: 0.1131 - val_loss: 3.8163 - val_acc: 0.1262\n",
      "Epoch 17/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.9088 - acc: 0.1217 - val_loss: 3.7530 - val_acc: 0.1425\n",
      "Epoch 18/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.8914 - acc: 0.1202 - val_loss: 3.7342 - val_acc: 0.1435\n",
      "Epoch 19/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.8577 - acc: 0.1247 - val_loss: 3.7400 - val_acc: 0.1376\n",
      "Epoch 20/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.8501 - acc: 0.1321 - val_loss: 3.7187 - val_acc: 0.1415\n",
      "Epoch 21/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.8015 - acc: 0.1388 - val_loss: 3.7118 - val_acc: 0.1523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7851 - acc: 0.1382 - val_loss: 3.6822 - val_acc: 0.1588\n",
      "Epoch 23/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7615 - acc: 0.1392 - val_loss: 3.6523 - val_acc: 0.1640\n",
      "Epoch 24/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7591 - acc: 0.1397 - val_loss: 3.6626 - val_acc: 0.1620\n",
      "Epoch 25/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7344 - acc: 0.1493 - val_loss: 3.6260 - val_acc: 0.1718\n",
      "Epoch 26/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.7217 - acc: 0.1439 - val_loss: 3.6790 - val_acc: 0.1549\n",
      "Epoch 27/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6882 - acc: 0.1547 - val_loss: 3.6143 - val_acc: 0.1647\n",
      "Epoch 28/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.6866 - acc: 0.1515 - val_loss: 3.5714 - val_acc: 0.1777\n",
      "Epoch 29/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6447 - acc: 0.1680 - val_loss: 3.6481 - val_acc: 0.1689\n",
      "Epoch 30/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6249 - acc: 0.1647 - val_loss: 3.6122 - val_acc: 0.1754\n",
      "Epoch 31/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.6136 - acc: 0.1721 - val_loss: 3.5635 - val_acc: 0.1881\n",
      "Epoch 32/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5961 - acc: 0.1674 - val_loss: 3.5656 - val_acc: 0.1819\n",
      "Epoch 33/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.5638 - acc: 0.1748 - val_loss: 3.5467 - val_acc: 0.1842\n",
      "Epoch 34/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5674 - acc: 0.1691 - val_loss: 3.5243 - val_acc: 0.1823\n",
      "Epoch 35/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5662 - acc: 0.1767 - val_loss: 3.5439 - val_acc: 0.1849\n",
      "Epoch 36/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5437 - acc: 0.1798 - val_loss: 3.4997 - val_acc: 0.1904\n",
      "Epoch 37/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5325 - acc: 0.1848 - val_loss: 3.4696 - val_acc: 0.1914\n",
      "Epoch 38/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5218 - acc: 0.1864 - val_loss: 3.4857 - val_acc: 0.1940\n",
      "Epoch 39/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4811 - acc: 0.1896 - val_loss: 3.4548 - val_acc: 0.1940\n",
      "Epoch 40/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.5020 - acc: 0.1836 - val_loss: 3.4765 - val_acc: 0.1894\n",
      "Epoch 41/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.4752 - acc: 0.1906 - val_loss: 3.4877 - val_acc: 0.1881\n",
      "Epoch 42/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4470 - acc: 0.1987 - val_loss: 3.4654 - val_acc: 0.1917\n",
      "Epoch 43/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.4566 - acc: 0.1942 - val_loss: 3.4469 - val_acc: 0.2015\n",
      "Epoch 44/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4256 - acc: 0.2025 - val_loss: 3.4763 - val_acc: 0.2077\n",
      "Epoch 45/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4043 - acc: 0.2059 - val_loss: 3.4395 - val_acc: 0.1982\n",
      "Epoch 46/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.4292 - acc: 0.1959 - val_loss: 3.4522 - val_acc: 0.1953\n",
      "Epoch 47/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.3944 - acc: 0.2074 - val_loss: 3.4190 - val_acc: 0.2113\n",
      "Epoch 48/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3771 - acc: 0.2049 - val_loss: 3.4298 - val_acc: 0.2090\n",
      "Epoch 49/150\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 3.3637 - acc: 0.2063 - val_loss: 3.4038 - val_acc: 0.2054\n",
      "Epoch 50/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3573 - acc: 0.2081 - val_loss: 3.4144 - val_acc: 0.2158\n",
      "Epoch 51/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3433 - acc: 0.2144 - val_loss: 3.4089 - val_acc: 0.2083\n",
      "Epoch 52/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3571 - acc: 0.2131 - val_loss: 3.4051 - val_acc: 0.2139\n",
      "Epoch 53/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3562 - acc: 0.2151 - val_loss: 3.4279 - val_acc: 0.2080\n",
      "Epoch 54/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3304 - acc: 0.2156 - val_loss: 3.3682 - val_acc: 0.2214\n",
      "Epoch 55/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3149 - acc: 0.2165 - val_loss: 3.3823 - val_acc: 0.2113\n",
      "Epoch 56/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2909 - acc: 0.2216 - val_loss: 3.3527 - val_acc: 0.2220\n",
      "Epoch 57/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.3150 - acc: 0.2202 - val_loss: 3.3697 - val_acc: 0.2139\n",
      "Epoch 58/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2757 - acc: 0.2226 - val_loss: 3.3749 - val_acc: 0.2145\n",
      "Epoch 59/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2613 - acc: 0.2256 - val_loss: 3.3729 - val_acc: 0.2110\n",
      "Epoch 60/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2808 - acc: 0.2238 - val_loss: 3.3981 - val_acc: 0.2178\n",
      "Epoch 61/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.2614 - acc: 0.2269 - val_loss: 3.3691 - val_acc: 0.2191\n",
      "Epoch 62/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2727 - acc: 0.2296 - val_loss: 3.3606 - val_acc: 0.2263\n",
      "Epoch 63/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.2462 - acc: 0.2270 - val_loss: 3.3731 - val_acc: 0.2240\n",
      "Epoch 64/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2489 - acc: 0.2314 - val_loss: 3.3527 - val_acc: 0.2250\n",
      "Epoch 65/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2094 - acc: 0.2362 - val_loss: 3.3204 - val_acc: 0.2233\n",
      "Epoch 66/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.2286 - acc: 0.2357 - val_loss: 3.3289 - val_acc: 0.2308\n",
      "Epoch 67/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2300 - acc: 0.2403 - val_loss: 3.3639 - val_acc: 0.2152\n",
      "Epoch 68/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1863 - acc: 0.2374 - val_loss: 3.4061 - val_acc: 0.2152\n",
      "Epoch 69/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.2115 - acc: 0.2408 - val_loss: 3.3279 - val_acc: 0.2266\n",
      "Epoch 70/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.1935 - acc: 0.2411 - val_loss: 3.3244 - val_acc: 0.2207\n",
      "Epoch 71/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1709 - acc: 0.2445 - val_loss: 3.3590 - val_acc: 0.2172\n",
      "Epoch 72/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1757 - acc: 0.2495 - val_loss: 3.3355 - val_acc: 0.2273\n",
      "Epoch 73/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1706 - acc: 0.2430 - val_loss: 3.3499 - val_acc: 0.2312\n",
      "Epoch 74/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.1498 - acc: 0.2489 - val_loss: 3.3409 - val_acc: 0.2276\n",
      "Epoch 75/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1602 - acc: 0.2485 - val_loss: 3.3397 - val_acc: 0.2299\n",
      "Epoch 76/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1503 - acc: 0.2538 - val_loss: 3.3567 - val_acc: 0.2194\n",
      "Epoch 77/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1397 - acc: 0.2428 - val_loss: 3.3387 - val_acc: 0.2312\n",
      "Epoch 78/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1187 - acc: 0.2537 - val_loss: 3.3080 - val_acc: 0.2305\n",
      "Epoch 79/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1368 - acc: 0.2518 - val_loss: 3.3017 - val_acc: 0.2380\n",
      "Epoch 80/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1287 - acc: 0.2548 - val_loss: 3.3324 - val_acc: 0.2374\n",
      "Epoch 81/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1192 - acc: 0.2575 - val_loss: 3.3679 - val_acc: 0.2276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.1191 - acc: 0.2580 - val_loss: 3.3553 - val_acc: 0.2266\n",
      "Epoch 83/150\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 3.0816 - acc: 0.2584 - val_loss: 3.3391 - val_acc: 0.2233\n",
      "Epoch 84/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.1175 - acc: 0.2547 - val_loss: 3.3237 - val_acc: 0.2237\n",
      "Epoch 85/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0912 - acc: 0.2576 - val_loss: 3.3294 - val_acc: 0.2302\n",
      "Epoch 86/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0640 - acc: 0.2699 - val_loss: 3.3657 - val_acc: 0.2253\n",
      "Epoch 87/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0665 - acc: 0.2646 - val_loss: 3.3278 - val_acc: 0.2246\n",
      "Epoch 88/150\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 3.0876 - acc: 0.2564 - val_loss: 3.3337 - val_acc: 0.2240\n",
      "Epoch 89/150\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 3.0773 - acc: 0.2698 - val_loss: 3.2998 - val_acc: 0.2348\n",
      "Epoch 00089: early stopping\n",
      "Test accuracy: 0.234757091567\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='VGG16Optimization_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4908/10222 [00:25<00:27, 194.64it/s]"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "val_loss, val_acc = best_model.evaluate(X_test, Y_test);\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(\"Validation loss: \", val_loss)\n",
    "print(\"Validation accuracy: \", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(modelPath+modelName);\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame(preds)\n",
    "# # Set column names to those generated by the one-hot encoding earlier\n",
    "# col_names = one_hot.columns.values\n",
    "# sub.columns = col_names\n",
    "# # Insert the column id from the sample_submission at the start of the data frame\n",
    "# sub.insert(0, 'id', df_test['id'])\n",
    "# sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
